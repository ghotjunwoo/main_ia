\documentclass[10pt, a4paper, twoside]{report}
\usepackage{wooreport}
\renewcommand\labelenumi{(\theenumi)}
% \fancyhead[RO, LE]{Junwoo Lee}
% \fancyhead[LO, RE]{Lecture Notes}
\title{\LARGE{\textsc{Lecture Notes}}}
\author{Junwoo Lee}
\date{}


\begin{document}
\begin{titlepage}
  \begingroup % University of Liege
  \def\drop{0.1\textheight}
  \vspace*{\drop}
  \begin{center}
  {\LARGE\textsc{Transcribed and edited by WOO}}\\[\drop]
  % University logo
  % {\LARGE \plogo}\\[\drop]
  \rule{\textwidth}{1pt}\par
  \vspace{0.5\baselineskip}
  {\huge\bfseries Part IA\\
   \large Cambridge Mathematical Tripos}\\[0.5\baselineskip]
  \rule{\textwidth}{1pt}\par
  \vfill
  {\Large\textsc{Lee, Junwoo}}
  \vfill
  Trinity College, Cambridge
  \vfill
  {\large 2024 Summer}
  \end{center}
  \endgroup
\end{titlepage}
% \setcounter{tocdepth}{1}
\tableofcontents
\chapter*{Preface}
These are what I studied during the 2024 long vacation for transfer into part IB mathematical tripos. I guess nobody can tell if it was valuable, or if this was a right decision. Nevertheless, I do not want to study beam bending. Since it is more mathematics-oriented document, I will use the usual conventions, such as definition, lemma, etc.

\noindent\hrulefill\hspace{0.2cm} \floweroneleft\floweroneright \hspace{0.2cm} \hrulefill
\chapter{Numbers and Sets}
\chapterauthor{Lecture given by 
Professor Julia Wolf, Michaelmas Term 2023.
}
\section{Elementary Number Theory}
\subsection{Natural Number}
Intuitively speaking, the natural numbers consists of
\[1,1+1,1+1+1,\ldots\]
But we cannot be sure if the list above contains all of the natural numbers, or if there are no duplicate numbes. Hence, for more rigorous understanding, we assume the natural numbers, \(\mathbb{N}\), is a set containing ``\(1\)'', with an operation ``\(+\)'' satisfying
\begin{enumerate}
    \item \(\forall n\in\mathbb{N}\), \(n+1\neq 1\).
    \item \(\forall m,n\in\mathbb{N}\), if \(m\neq n\), then \(m+1\neq n+1\).
    \item For any property \(P(n)\), if \(P(1)\) is true and \(\forall n\in\mathbb{N}\), \(P(n)\Rightarrow P(n+1)\), then \(P(n)\) is true for all natural numbers.
\end{enumerate}
(1), (2), and (3) are known as the \emph{Peano axioms}, and (3) is called the \emph{induction axiom}.
(1) and (2) capture the idea that any two natural numbers are distinct; (3) captures our intuition that the list is complete.\footnote{Take \(P(n)=\text{``\(n\) is on this list''}\).} Now we can write \(2\) for \(1+1\), \(3\) for \(1+1+1\) etc. and we can define ``\(+k\)'' for any natural number \(k\):
\begin{definition}
    For every natural number \(n\),
    \[n+(k+1)=(n+k)+1\]
\end{definition}
It can be thought from induction, taking \(P(k)=\text{``\(+k\) is defined''}\). Similarly, we can define multiplication, powers etc. satisfying
\begin{enumerate}
    \item \(\forall a,b\), \(a+b=b+a\) \space   (\(+\) is commutative).
    \item \(\forall a,b\), \(ab=ba\) \space   (\(\cdot\) is commutative).
    \item \(\forall a,b,c\), \(a+(b+c)=(a+b)+c\)  \space  (\(+\) is associative).
    \item \(\forall a,b,c\), \(a(bc)=(ab)c\)   \space (\(\cdot\) is associative).
    \item \(\forall a,b,c\), \(a(b+c)=ab+ac\) \space (multiplication is distributive over addition).
\end{enumerate}
We define ``\(a<b\)'' if \(a+c=b\) for some \(c\in\mathbb{N}\), satisfying
\begin{enumerate}
    \setcounter{enumi}{5}
    \item \(\forall a,b,c\), \(a<b\Rightarrow a+c<b+c\).
    \item \(\forall a,b,c\), \(a<b\Rightarrow ac<bc\).
    \item \(\forall a,b,c\), \(a<b\) and \(b<c\Rightarrow a<c\).
    \item \(\forall a\), \(\neg(a<a)\).
\end{enumerate}

The induction axiom is also known as the \emph{weak principle of induction} (WPI). Equivalent form of this is the strong principle of induction (SPI):
\begin{theorem}
    (\emph{Strong Principle of Induction}) If
    \begin{enumerate}
        \item \(P(1)\) holds, and
        \item \(\forall n\in\mathbb{N}\), we have \((P(m)\:\forall m\leq n)\Rightarrow P(n+1)\), 
    \end{enumerate}
    then \(P(n)\) holds \(\forall n\in\mathbb{N}\).
\end{theorem}
Clearly, \(\text{SPI}\Rightarrow\text{WPI}\). To see that \(\text{WPI}\Rightarrow\text{SPI}\), apply the former to
\[Q(n)=\text{``\(P(m)\) holds \(\forall m\leq n\)''}\]
\begin{theorem}
    (\emph{Well-Ordering Principle} (WOP)) If \(P(n)\) holds for some \(n\in\mathbb{N}\), then there is a least \(n\in\mathbb{N}\) such that \(P(n)\) holds. ``\emph{Every non-empty subset of \(\mathbb{N}\) has a minimal element}.''
\end{theorem}
\begin{theorem}
    SPI is equivalent to WOP.
\end{theorem}
\begin{proof}
    First we show that WOP implies SPI. We assume (1) and (2) of SPI, and show that \(P(n)\) holds \(\forall n\in\mathbb{N}\), using WOP. Suppose, on the contrary, that \(P(n)\) is not true for all \(n\in\mathbb{N}\). Then,
    \[C=\{n\in\mathbb{N}\:|\:P(n)\text{ is false}\}\neq\emptyset\]
    By well-ordering principle, \(C\) has a minimal element, say \(m\). Now \(\forall k<m\), \(k\notin C\) (by minimality of \(m\)), so \(P(k)\) holds \(\forall k<m\). But by (2) of strong principle of induction, \(P(m)\) holds, contradicting \(m\in C\). Hence SPI holds.

    To show that SPI implies WOP, suppose there is no least \(n\in\mathbb{N}\) such that \(P(n)\) holds. We want to show that \(P(n)\) does not hold for any \(n\in\mathbb{N}\), using SPI. Consider
    \[Q(n)=\neg P(n)\]
    Certainly \(P(1)\) is false,\footnote{Else \(1\) would be the minimal element.} so \(Q(1)\) holds. Given \(n\in\mathbb{N}\), suppose that \(Q(k)\) is true \(\forall k<n\). Then \(P(k)\) is false \(\forall k<n\). So \(P(n)\) is false as otherwise \(n\) would be the minimal element for which \(P\) holds. Hence \(Q(n)\) is true, and (2) of SPI is satisfied, so \(Q(n)\) holds for all \(n\in\mathbb{N}\). Thus \(P(n)\) is false \(\forall n\in\mathbb{N}\).
\end{proof}
Well-ordering principle enables us to prove \(P(n)\) is true \(\forall n\in N\) as follows: if not, there is a minimal counterexample, and we may try and derive a contradiction.
\subsection{Integer}
The integer set, \(\mathbb{Z}\), consist of all symbols \(n\), \(-n\), where \(n\in\mathbb{N}\), along with \(0\). We can also define \(+\) and \(\cdots\) etc. on \(\mathbb{Z}\) from \(\mathbb{N}\), and check that the usual rules (1) - (5) of arithmetic hold. We also have
\begin{enumerate}
    \setcounter{enumi}{9}
    \item \(\forall a\in\mathbb{Z}\), \(a+0=0\) \space (identity for \(+\)).
    \item \(\forall a\in\mathbb{Z}\), \(\exists b\in\mathbb{Z}\) such that \(a+b=0\) \space (inverses for \(+\)). Here, \(b=-a\).
\end{enumerate}
Similarly define \(a<b\) if \(a+c=b\) for some \(c\in\mathbb{N}\). Rules (6), (8), and (9) continue to hold, but (7) must be modified:
\begin{enumerate}
    \setcounter{enumi}{6}
    \item \(\forall a,b,c\in\mathbb{Z}\), \(a<b\text{  and  }c>0\Rightarrow ac<bc\).
\end{enumerate}
\subsection{Rational Number}
The rational number set, \(\mathbb{Q}\), consist of all expressions \(a/b\), where \(a\), \(b\) are integers, \(b\neq 0\), and \(a/b\) and \(c/d\) are regarded as the same if \(ad=bc\). Define 
\[\frac ab+\frac cd=\frac{ad+bc}{bd}\]
and one can check it does not matters how we wrote \(a/b\) or \(c/d\) (commutivity). We similarly define multiplication, and
\[\frac ab<\frac cd\]
where \(b,d>0\) if \(ad<bc\). All the previous rules apply to rational numbers, but, furthermore,
\begin{enumerate}
    \setcounter{enumi}{11}
    \item \(\forall a\in\mathbb{Q}\), \(a\neq 0\), \(\exists b\) such that \(ab=1\) \space (inverse for \(\cdot\)).
\end{enumerate}
Finally, note that
\[\mathbb{N}\subseteq\mathbb{Z}\subseteq\mathbb{Q}\]
\subsection{Primes}
\begin{definition}
    A natural number \(n\geq 2\) is \emph{prime} if its only factors are \(\pm 1\) and \(\pm n\). If \(n\geq 2\) is not prime, then it is \emph{composite}.
\end{definition}
\begin{proposition}
    Every natural number \(n\geq 2\) can be written as a product of primes.
    \label{prop:prod_prime}
\end{proposition}
\begin{proof}
    It is true for \(n=2\). Let \(n>2\) and suppose that claim holds up to and including \(n-1\). If \(n\) is prime, done. If \(n\) is composite, then \(n=ab\) for some \(1<a,b<n\).

    By the induction hypothesis, we have
    \begin{align*}
        a&=p_1p_2\cdots p_k \\
        b&=q_1q_2\cdots q_l
    \end{align*}
    for some primes \(p_1,\ldots,p_k,q_1,\ldots,q_l\). Hence
    \[n=ab=p_1\cdots p_kq_1\cdots q_l\]
    is a product of primes. Proof is complete by induction.
\end{proof}
\begin{theorem}
    There are infinitely many primes.
    \label{thm:infty_prime}
\end{theorem}
\begin{proof}
    (Euclid, 300 B.C.) Suppose there are finitely many primes, say \(p_1,\ldots,p_k\). Let \(N=p_1\cdots p_k+1\). Then \(p_1\nmid N\), else
    \[p_1|N-p_1\cdots p_k=1\]
    Likewise, none of \(p_2,p_3,\ldots,p_k\) divide \(N\), contradicting the fact that \(N\) can be written as a product of primes (Proposition \ref{prop:prod_prime}).
\end{proof}
Can a number have more than one representation as a product of primes? Our proof of Proposition \ref{prop:prod_prime} does not give uniqueness. 
\begin{definition}
    Given \(a,b\in\mathbb{N}\), a natural number \(c\) is the \emph{highest common factor} (hcf) or \emph{greatest common divisor} (gcd) of \(a\) and \(b\) if
    \begin{enumerate}
        \item \(c|a\) and \(c|b\);
        \item \(d|a\) and \(d|b\:\Rightarrow d|c\).
    \end{enumerate}
    We write \(c=\text{hcf}(a,b)\), or \(c=\text{gcd}(a,b)\), or \(c=(a,b)\).
    \label{def:gcd}
\end{definition}
For example, the factors of \(12\) are \(1,2,3,4,6,12\), and those of \(18\) are \(1,2,3,6,9,18\). So the common factors are \(1,2,3,6\), hence \(\gcd(12,18)=6\). But observe that if \(a\) and \(b\) had common factors \(1,2,3,4,6\), then \(a\) and \(b\) would have no gcd according to Definition \ref{def:gcd} (2). We will need to show that \(\gcd(a,b)\) always exists.
\begin{proposition}
    (\emph{Division Algorithm}) Let \(n,k\in\mathbb{N}\). Then we can write \[n=qk+r\] where \(q\) and \(r\) are integers with \(0\leq r\leq k-1\).
    \label{prop:da}
\end{proposition}
\begin{proof}
    It is true for \(n=1\). Suppose \(n\geq 2\) and statement holds for \(n-1\), i.e. \[n-1=qk+r\] for some \(q,r\in\mathbb{Z}\), \(0\leq r\leq k-1\).
    \begin{itemize}
        \item If \(r<k-1\), then \(n=(n-1)+1=qk+(r+1)\).
        \item If \(r=k-1\), then \(n=(n-1)+1=qk+(k-1)+1=(q+1)k\).
    \end{itemize}
\end{proof}
Note that \(q\) and \(r\) obtained by the division algorithm are unique: if \(n=qk+r=q^\prime k+r^\prime\), then 
\[(q-q^\prime)k=r^\prime-r\]
is an integer smaller than \(k\) and larger than \(-k\) so \(q=q^\prime\) and \(r=r^\prime\).

We now introduce the \emph{Euclid's Algorithm}. We break down \(a\) and \(b\) until \(r_{n+1}=0\) as follows;
\begin{align*}
    a&=q_1b+r_1 \\
    b&=q_2r_1+r_2 \\
    &\vdots \\
    r_{n-2}&=q_nr_{n-1}+r_n \\
    r_{n-1}&=q_{n+1}r_n+r_{n+1}
\end{align*}
and the algorithm returns \(r_n\).
N.b. the algorithm terminates in \(n<b\) steps, since 
\[b>r_1>r_2>\ldots>r_n>0\]
\begin{theorem}
    The output of Euclid's algorithm with input \(a\), \(b\) is \(\gcd(a,b)\).
\end{theorem}
\begin{proof}
    We show (1) and (2) from Definition \ref{def:gcd}.
    \begin{enumerate}
        \item Have \(r_n/r_{n-1}\) (as \(r_{n+1}=0\)), so \(r_n/r_{n-2}\) and \(r_n/r_i\) \(\forall i=1,2,\ldots,n-1\) by induction. Hence \(r_n/b\) and \(r_n/a\).
        \item Given \(d\) such that \(d|a\) and \(d|b\), have \(d|r_1\), so \(d|r_2\) and \(d|r_i\) \(\forall i=1,2,\ldots,n\) by induction.
    \end{enumerate}
\end{proof}
By the division algorithm and Euclid's algorithm, we have found out that the gcd of any two natural numbers always exists, and is unique. For example, consider Euclid's algorithm with \(87\) and \(52\) as inputs:
\begin{align*}
    87&=1\cdot 52+35 \\
    52&=1\cdot 35+17 \\
    35&=2\cdot 17+1 \\
    17&=17\cdot1
\end{align*}
so \(\gcd(87,52)=1\).
\begin{definition}
    When \(\gcd(a,b)=1\), we say that \(a\) and \(b\) are \emph{coprime}.
\end{definition}
Observe that we can reverse the Euclid's algorithm:
\begin{align*}
    1&=35-2\cdot 17 \\
    &=35-2(52-1\cdot 35) \\
    &=-2\cdot 52 + 3\cdot 35 \\
    &=-2\cdot 52+3(87-1\cdot 52) \\
    &=-5\cdot 52+3\cdot 87
\end{align*}
\begin{theorem}
    \(\forall a,b\in\mathbb{N}\), \(\exists x,y\in\mathbb{Z}\) such that
    \[xa+yb=\gcd(a,b)\]
    ``\emph{We can write \(\gcd(a,b)\) as a linear combination of \(a\) and \(b\)}.''
    \label{thm:lin_gcd}
\end{theorem}
\begin{proof}
    (\emph{Method 1}) Run Euclid's algorithm with input \(a\), \(b\) to obtain an output \(r_n\). At step \(n\), have 
    \[r_n=xr_{n-1}+yr_{n-2}\]
    for some \(x,y\in\mathbb{Z}\). But from step \(n-1\), we see that \(r_{n-1}\) is expressible as 
    \[r_{n-1}=xr_{n-2}+yr_{n-3}\] 
    for some \(x,y\in\mathbb{Z}\), whence 
    \[r_{n}=xr_{n-2}+yr_{n-3}\] 
    for some \(x,y\in\mathbb{Z}\). Continuing inductively, we have \(\forall i=2,\ldots,n-1\),
    \[r_n=xr_i+yr_{i-1}\]
    for some \(x,y\in\mathbb{Z}\). Thus
    \[r_n=xa+yb\]
    for some \(x,y\in\mathbb{Z}\), by steps one and two.
\end{proof}
\begin{remark}
    Euclid's algorithm not only proves the existence of \(x,y\in\mathbb{Z}\), but gives a quick way to find them.
\end{remark}
\begin{proof}
    (\emph{Method 2}) Let \(g\) be the least positive linear combination of \(a\) and \(b\), i.e. the least positive integer of the form \(xa+yb\) for some \(x,y\in\mathbb{Z}\). We shall show that \(g=\gcd(a,b)\) (Definition \ref{def:gcd}).

    To see (2), observe that given \(d\) such that \(d|a\) and \(d|b\), we have
    \[d|ax+by\quad\forall x,y\in\mathbb{Z}\]
    so in particular, \(d|g\).

    To see (1), suppose that \(g\nmid a\). Then we can write
    \[a=qg+r\] for some \(q,r\in\mathbb{Z}\) with \(0<r<g\). Hence
    \[r=a-qg=a-q(xa+yb)\]
    is also a positive linear combination of \(a\) and \(b\), and strictly smaller than \(g\), contradicting the definition of \(g\). Therefore, \(g|a\) and by the same argument, \(g|b\).
\end{proof}
\begin{remark}
    (\emph{Method 2}) tells us that \(\gcd(a,b)\) exists and is a linear combination of \(a\) and \(b\), but gives no way to find \(\gcd(a,b)\) or the coefficients \(x,y\in\mathbb{Z}\).
\end{remark}
With help of Theorem \ref{thm:lin_gcd}, we can tell
\[160x+72y=33\]
does not have any integer solution, but
\[87x+52y=33\]
does. Let's formalise this.
\begin{corollary}
    (\emph{Bézout's Theorem}) Let \(a,b\in\mathbb{Z}\). Then the equation
    \[ax+by=c\]
    has a solution in integers \(x,y\) if and only if
    \[\gcd(a,b)|c\]
    \label{coro:bezout}
\end{corollary}
\begin{proof}
    Let \(g=\gcd(a,b)\). Suppose there are \(x,y\in\mathbb{Z}\) such that
    \[ax+by=c\]
    Then, since \(g|a\) and \(g|b\), \(g|c\).

    Conversely, suppose \(g|c\). But Theorem \ref{thm:lin_gcd} implies that there exist \(x,y\in\mathbb{Z}\) such that
    \[g=ax+by\]
    But then
    \[c=\frac cgg=\frac cg(ax+by)=a\left(x\frac cg\right)+b\left(y\frac cg\right)\]
\end{proof}
\begin{proposition}
    If \(p\) is a prime and \(p|ab\), then \(p|a\) or \(p|b\).
    \label{prop:prime_div}
\end{proposition}
\begin{proof}
    Suppose \(p|ab\) but \(p\nmid a\). We claim \(p|b\). 

    Since \(p\) is prime and \(p\nmid a\), \(\gcd(a,p)=1\). Thus by Theorem \ref{thm:lin_gcd}, there exists \(x,y\in\mathbb{Z}\) such that \(xp+ya=1\). It follows that \(xpb+yab=b\), whence \(b\) is a multiple of \(p\) (as each of \(p\) and \(ab\) is).
\end{proof}
\begin{remark} \item[]
    \begin{enumerate}
        \item Similarly, 
        \[p|a_1a_2\cdots a_n\Rightarrow p|a_i\]
        for some \(i=1,2,\ldots,n\). Indeed, Proposition \ref{prop:prod_prime} tells us that if \(p|a_1a_2\cdots a_n\), the \(p|a_1\) or \(p|a_2\cdots a_n\), so we may conclude by induction on the number of terms in the product.
        \item We do need \(p\) to be prime.
    \end{enumerate}
\end{remark}
\begin{theorem}
    (\emph{Fundamental Theorem of Arithmetic}) Every natural number \(n\geq 2\) is expressible as a product primes, uniquely up to reordering.
\end{theorem}
\begin{proof}
    Existence of factorisation follows from Proposition \ref{prop:prod_prime}. We can show uniqueness by induction. Clearly it is unique for \(n=2\). Given \(n\geq 2\), suppose 
    \[n=p_1p_2\cdots p_k=q_1q_2\cdots q_l\]
    where \(p_i,q_j\) are all prime. Want to show that \(k=l\), and, after reordering, \(p_i=q_i\) \(\forall i=1,\ldots,k\). We have 
    \[p_1|n=q_1q_2\cdots q_l\]
    so by Proposition \ref{prop:prime_div},
    \[p_1|q_i\] for some \(i\). Relabelling the \(q_i\), we may assume that \(p_1|q_1\). Since \(q_1\) is prime, \(p_1=q_1\), so
    \[\frac n{p_1}=p_2\cdots p_k=q_2\cdots q_l<n\]
    By the induction hypothesis, \(k=l\), and, after reordering, \(p_2=q_2,\ldots,p_k=q_k\).
\end{proof}
\begin{remark}
    There are arithmetical systems (permitting addition and multiplication) in which factorisation is not unique.

    For example, consider \(\mathbb{Z}[\sqrt{-3}]\), meaning all complex numbers of the form \(x+y\sqrt{-3}=x+y\sqrt{3}i\) where \(x,y\in\mathbb{Z}\). We can add and multiply two elements of \(\mathbb{Z}[\sqrt{-3}]\) to get another element of \(\mathbb{Z}[\sqrt{-3}]\), e.g.
    \[(1+\sqrt{-3})+(q-\sqrt{-3})=2\]
    \[(1+\sqrt{-3})(q-\sqrt{-3})=4\]
     In \(\mathbb{Z}[\sqrt{-3}]\), we can define what it means to be a prime, and both \(1+\sqrt{-3}\) and \(1-\sqrt{-3}\) happen to be prime in this sense. But, we can also write \(4=2\cdot 2\), so factorisation is not unique.
\end{remark}
Let's take a look at some applications of the fundamental theorem of arithmetic.
\begin{enumerate}
    \item What are the factors of \(n=2^33^711\)? -- All numbers of the form \(2^a3^b{11}^c\) where \(0\leq a\leq 3\), \(0\leq b\leq 7\), \(0\leq c\leq 1\). There are no others: if, for example, \(7|n\), then we would have a factorisation of \(n\) involving \(7\), contradicting uniqueness. More generally, the factors of \(n=p_1^{a_1}p_2^{a_2}\cdots p_k^{a_k}\) are precisely the numbers of the form 
    \[p_1^{b_1}p_2^{b_2}\cdots p_k^{b_k}\]
    with \(0\leq b_i\leq a_i\) \(\forall i=1,2,\ldots,k\).
    \item What are common factors of \(2^3\cdot 3^7\cdot5\cdot11^3\) and \(2^4\cdot 3^2\cdot 11\cdot 13\)? -- All numbers of the form \(2^33^b11^c\) where \(0\leq a\leq 3\), \(0\leq b\leq 2\), \(0\leq c\leq 1\). Thus the gcd is \(2^3\cdot 3^2\cdot 11\). In general, the gcd of \(p_1^{a_1}p_2^{a_2}\cdots p_k^{a_k}\) and \(p_1^{b_1}p_2^{b_2}\cdots p_k^{b_k}\), where \(a_i, b_i\geq 0\), is 
    \[p_1^{\min\{a_1,b_1\}}\cdots p_k^{\min\{a_k,b_k\}}\]
    \item What are the common multiples of the two numbers in (2)? -- All numbers of the form \(2^a3^b5^c11^d13^2\) where \(a\geq 4\), \(b\geq 7\), \(c\geq 1\), \(d\geq 3\), \(e\geq 1\), times any integer. Hence \(2^4\cdot 3^7\cdot\cdot 5\cdot 11^3\cdot 13\) is a common multiple, and any other common multiple is a multiple of it. We say that it is the \emph{least common multiple} (lcm) of the two numbers.  In general, the lcm of \(p_1^{a_1}p_2^{a_2}\cdots p_k^{a_k}\) and \(p_1^{b_1}p_2^{b_2}\cdots p_k^{b_k}\), where \(a_i, b_i\geq 0\), is 
    \[p_1^{\max\{a_1,b_1\}}\cdots p_k^{\max\{a_k,b_k\}}\]
    Since \(\min\{a_i,b_i\}+\max{a_i,b_i}=a_i+b_i\), we have 
    \[\gcd(x,y)\cdot\text{lcm}(x,y)=xy\]
    for any \(x,y\).
    \item Another proof of Theorem \ref{thm:infty_prime}, due Erdös (1930): let \(p_1,p_2,\ldots,p_k\) be all the primes. Any number which is a product of jest these primes is of the form (\(\asterisk\)):
    \[p_1^{j_1}p_2^{j_2}\cdots p_k^{j_k}=m^2p_1^{i_1}p_2^{i_2}\cdots p_k^{i_k}\]
    where \(i_l=0\text{ or }1\). Let \(M\in\mathbb{N}\). If a number is equal or less than \(M\) is of the form (\(\asterisk\)), then \(m\leq\sqrt{M}\). So there are at most \(\sqrt{M}2^k\) numbers of the form (\(\asterisk\)) that are equal or less than \(M\). If \(M>\sqrt{M}2^k\), i.e. if \(M>4^k\), then there must be a number equal or less than \(M\) which is not of the form (\(\asterisk\)). But this number must have a prime factor not amongst the \(p_1,\ldots,p_k\). \hfill\qedsymbol
    
    Proof by Euclid tells us that \(k\)\textsuperscript{th} prime is less than \(2^{2^k}\), while the proof by Erdös tells us \(k\)\textsuperscript{th} prime is less than \(4^k\). In fact, we know \(k\)\textsuperscript{th} prime is \(\sim k\ln k\) (\emph{Prime Number Theorem}).
\end{enumerate}
\subsection{Modular Arithmetic}
Let \(n\geq 2\) be a natural number. Then the \emph{integer modulo \(n\)}, written as \(\mathbb{Z}_n\) or \(\mathbb{Z}/n\mathbb{Z}\) consist of the integers, with two regarded as the same if they differ by a multiple of \(n\). If \(x\) and \(y\) are the same in \(\mathbb{Z}_n\), we write 
\[x\equiv  y\mod n\]
or \(x\equiv y\quad(n)\) or \(x=y\text{  in  }\mathbb{Z}_n\). Thus 
\begin{align*}
    x\equiv y\mod n&\Leftrightarrow n|x-y \\
    &\Leftrightarrow x=y+kn\:\text{for some \(k\in\mathbb{Z}\)}
\end{align*}
N.b. if \(a\equiv a^\prime\mod n\) and \(b\equiv b^\prime\mod n\), then 
\[n|(a-a^\prime)+(b-b^\prime)=(a+b)-(a^\prime+b^\prime)\]
so \(a+b\equiv a^\prime+b^\prime\mod n\). Similarly, 
\[n|(a-a^\prime)b+a^\prime(b-b^\prime)=ab-a^\prime b^\prime\]
so \(ab=a^\prime b^\prime\mod n\). Hence we can do arithmetic on modulo \(n\) with inheriting the usual rules of arithmetic in \(\mathbb{Z}\).
\begin{example}
    Does \(2a^2+3b^3=1\) have a solution with \(a,b\in\mathbb{Z}\)? \newline 
    If there is a solution, then \(2a^2\equiv 1\mod 3\), but \(2\cdot 0^2\equiv 0\), \(2\cdot 1^2\equiv 2\), \(2\cdot 2^2\equiv 2\mod 3\) so there is no solution.
\end{example}
\subsubsection{Solution of congruences}
\begin{example}
    Solve \(7n\equiv 2\mod 10\).\newline 
    We note \(3\cdot 7\equiv 1\mod 10\) so \(3\cdot 7n\equiv 3\cdot 2\mod 10\) and \(n\equiv 6\mod 10\).
\end{example}
As shown in the example above, given \(a,b\in\mathbb{Z}\), we say that \(b\) is an \emph{inverse of a modulo \(n\)} if \[ab\equiv 1\mod n\]
We say that \(a\) is \emph{invertible modulo \(n\)} or that \(a\) is a \emph{unit modulo \(n\)}, if it has an inverse. For example, in \(\mathbb{Z}_{10}\), \(3\) is an inverse of \(7\), and both \(3\) and \(7\) are units modulo \(10\); but \(4\) is not a unit modulo \(10\) since \(4n\nequiv 1\mod 10\) for all \(n\in\mathbb{Z}\).
\begin{remark}
    If \(a\) is a unit modulo \(n\), then 
    \begin{enumerate}
        \item its inverse is unique. Suppose \(\exists b,b^\prime\) such that 
        \[ab\equiv ab^\prime\equiv 1\mod n\]
        then
        \[b\equiv bab\equiv bab^\prime\equiv b^\prime\mod n\]
        \item we can write \(a^{-1}\) for its inverse.
        \item if \(ab\equiv ac\mod n\), then \(b\equiv c\mod n\).
    \end{enumerate}
    However, this is not true in general, e.g. 
    \[4\cdot 3\equiv 4\cdot 8\mod 10\]
    but \(3\nequiv 8\mod 10\).
\end{remark}
\begin{proposition}
    Let \(p\) be prime. Then every \(a\neq 0\mod p\) is a unit modulo \(p\).
\end{proposition}
\begin{proof}
    From \(\gcd(a,p)=1\), \(\exists x,y\in\mathbb{Z}\) such that \(ax+py=1\) (Corollary \ref{coro:bezout}). Hence \(ax=1-py\), so 
    \[ax\equiv 1\mod p\]
    for some \(x\in\mathbb{Z}\).
\end{proof}
\begin{proposition}
    Let \(n\geq 2\). Then \(a\) is a unit modulo \(n\) if and only if \(\gcd(a,n)=1\).
\end{proposition}
\proof
\begin{align*}
    \gcd(a,n)=1&\Leftrightarrow ax+ny=1\:\text{ for some \(x,y\in\mathbb{z}\)} \\
    &\Leftrightarrow ax=1-ny:\text{ for some \(x,y\in\mathbb{z}\)} \\
    &\Leftrightarrow ax\equiv 1\mod n:\text{ for some \(x,y\in\mathbb{z}\)}
\end{align*}
\begin{corollary}
    If \(\gcd(a,n)=1\), then the congruence
    \[ax\equiv b\mod n\]
    has a unique solution. In particular, if \(\gcd(a,n)=1\), then there is a unique inverse of \(a\) modulo \(n\).
\end{corollary}
For cases like \(ax\equiv b\mod n\) with \(\gcd(a,n)=d\neq 1\), the solution may not exist. \(n|ax-b\) so \(d|ax-b\) and thus \(d|b\) for solution to exist. If \(d|b\), write \(n=dn^\prime\), \(a=da^\prime\), \(b=db^\prime\). Then,
\begin{align*}
    ax\equiv b\mod n&\Leftrightarrow ax-b=kn\:\text{ for some \(k\in\mathbb{Z}\)} \\
    &\Leftrightarrow da^\prime x-db^\prime=kdn^\prime:\text{ for some \(k\in\mathbb{Z}\)} \\
    &\Leftrightarrow a^\prime x-b^\prime=kn^\prime :\text{ for some \(k\in\mathbb{Z}\)} \\
    &\Leftrightarrow a^\prime x\equiv b^\prime\mod n^\prime
\end{align*}
Since \(\gcd(a^\prime,n^\prime)=1\), \(a^\prime x\equiv b^\prime\mod n^\prime\) has a unique solution.
\begin{example}
    Solve \(7x\equiv 4\mod 30\).\newline 
    We have \(\gcd(7,30)=1\), so by Euclid's algorithm, \(13\cdot 7-3\cdot 30=1\). Hence \(13\cdot 7\equiv 1\mod 30\), whence 
    \[x\equiv 13\cdot 4\equiv 22\mod 30\]
\end{example}
\begin{example}
    Solve \(10x\equiv 12\mod 34\). \newline 
    This is equivalent with \(5x\equiv 6\mod 17\), and we can now solve as the example above to obtain \(x\equiv 6\cdot 7\equiv 8\mod 17\).
\end{example}
\subsubsection{Simultaneous congruences}
Note 
\[x\equiv 5\mod 12\Rightarrow\begin{cases}
    x\equiv 2\mod 3 \\
    x\equiv 1\mod 4
\end{cases}\]
However, we cannot be sure if the converse is true, i.e. does \(x\equiv 2\mod 3\) and \(x\equiv 1\mod 4\) imply that \(x\equiv 5\mod 12\)? It turns out that it is true for the case above, but it is not generally true -- see \(x\equiv 1\mod 4\) and \(x\equiv 2\mod 6\).
\begin{theorem}
    (\emph{The Chinese Remainder Theorem}) Let \(m,n\) be coprime, and \(a,b\in\mathbb{Z}\). Then there is a unique solution modulo \(mn\) to the simultaneous congruences 
    \[x\equiv a\mod m\text{  and  }x\equiv b\mod n\]
    That is, there is a solution \(x\) to 
    \[\begin{cases}
        x\equiv a\mod m \\
        x\equiv b\mod n
    \end{cases}\]
    and \(y\) is a solution if and only if \(x\equiv y\mod mn\).
    \label{thm:crt}
\end{theorem}
\begin{proof}
    We first prove existence. Since \(\gcd(m,n)=1\), \(\exists s,t\in\mathbb{Z}\) with \(sm+tn=1\). Note 
    \[sm\equiv 1\mod n,\quad sm\equiv 0\mod m\]
    and 
    \[tn\equiv 1\mod m,\quad tn\equiv 0\mod n\]
    Hence 
    \begin{align*}
        x=a(tn)+b(sm)&\equiv a\mod m \\
        &\equiv b\mod n 
    \end{align*}
    Next, for uniqueness, suppose \(y\) is also a solution, i.e. \(y\equiv a\mod m\) and \(y\equiv b\mod n\). This implies 
    \begin{align*}
        y\equiv x\mod m\text{  and  }y\equiv x\mod n&\Leftrightarrow m|y-x\text{  and }n|y-x \\
        &\Leftrightarrow mn|y-x \text{  since  } \gcd(m,n)=1 \\
        &\Leftrightarrow y\equiv x\mod mn
    \end{align*}
\end{proof}
\begin{remark}
    Theorem \ref{thm:crt} can be extended, by induction, to more than two moduli: \newline if \(m_1,m_2,\ldots,m_k\) are pairwise coprime, then \(\forall a_1,a_2,\ldots,a_k\in\mathbb{Z}\), \(\exists x\in\mathbb{Z}\) such that 
    \[x\equiv a_1\mod m_1\]
    \[x\equiv a_2\mod m_2\]
    \[\vdots\]
    \[x\equiv a_k\mod m_k\]
\end{remark}
\begin{definition}
    We define the \emph{Euler totient function}, \(\varphi(m)\), as the number of integers \(a\) with \(1\leq a\leq m\) such that \(\gcd(a,m)=1\), i.e. \(\varphi(m)\) is the number of units modulo \(m\). Additionally, we define \(\varphi(1)=1\).
\end{definition}
For example, when \(p\) is prime, \(\varphi(p)=p-1\), and \(\varphi(p^2)=p^2-p\). When \(p\), \(q\) are distinct primes,
\[\varphi(p,q)=pq-p-q+1\]
Next, let's take a look at behavior of a power of an integer modulo \(p\).
\begin{theorem}
    (\emph{Fermat's Little Theorem})
    Let \(p\) be a prime. Then \(a^p\equiv a\mod p\) for all \(a\in\mathbb{Z}\). Equivalently, 
    \[a^{p-1}\equiv 1\mod p\]
    for all \(a\nequiv 0\mod p\).
    \label{thm:flt}
\end{theorem}
\begin{proof}
    If \(a\nequiv 0\mod p\), then \(a\) is a unit mod \(p\). Thus \(ax\equiv ay\mod p\) if and only if \(x\equiv y\mod p\). Hence the numbers \(a,2a,\ldots,(p-1)a\) are pairwise incongruent (distinct) modulo \(p\), and \(\nequiv 0\mod p\), so they are \(1,2,3,\ldots,p-1\) in some order. Hence 
    \[a\cdot 2a\cdots(p-1)a\equiv 1\cdot2\cdots(p-1)\mod p\]
    or 
    \[a^{p-1}(p-1)!\equiv(p-1)!\mod p\]
    But \((p-1)!\) is a unit mod \(p\) (since it is a product of units), so we can cancel it to obtain \(a^{p-1}\equiv 1\mod p\).
\end{proof}
\begin{theorem}
    (\emph{Fermat-Euler Theorem}) Let \(\gcd(a,m)=1\). Then \(a^{\varphi(m)}\equiv 1\mod m\).
    \label{thm:euler}
\end{theorem}
\begin{proof}
    Let 
    \[U=\{x\in\mathbb{Z}\:|\:0<x<m,\gcd(x,m)=1\}\]
\end{proof}
\chapter{Groups}
\chapterauthor{Lecture by Professor Claude Warnick. 
    Michaelmas term 2023.}
\chapter{Analysis I}
\chapterauthor{Lecture by Professor Claude Warnick. 
    Lent term 2024.}
\section{Limits and Convergence}
\subsection{Sequences}
Consider a sequence of real numbers
\[a_1,a_2,a_3,\ldots\]
\((a_n)\) where \(a_n\in\mathbb{R}\).
We start by defining \emph{limit}.
\begin{definition}
    We say \(a_n\to a\) as \(n\to\infty\) for some \(a\in\mathbb{R}\) if: given \(\epsilon>0\), there exists \(N\in\mathbb{N}\) such that
    \[|a_n-a|<\epsilon\quad\forall n\geq N\]
    \label{def:limit}
\end{definition}
If \(a_n\leq a_{n+1}\;\forall n\) we say \((a_n)\) is \emph{increasing}; and \emph{decreasing, strictly increasing, strictly decreasing} for \(a_n\geq a_{n+1}\), \(a_n>a_{n+1}\), \(a_n<a_{n+1}\) respectively. In all above cases, \((a_n)\) is \emph{monotone}.
\begin{theorem}
    (\emph{Monotone Convergence Theorem}) An increasing sequence of real numbers which is bounded above converges (i.e. it has a limit).
    \label{mct}
\end{theorem}
In other words, monotone convergence theorem says if \(a_n\in\mathbb{R}\) (\(n\geq 1\)), \(A\in\mathbb{R}\) with
\[a_1\geq a_2\geq a_3\geq\cdots\text{  and  }a_n\geq A\quad\forall n\]
there exists \(a\in\mathbb{R}\) such that \(a_n\to a\) as \(n\to\infty\). Equivalently, decreasing sequence bounded below has a limit. Theorem \ref{mct} is also equivalent with Theorem \ref{luba}
\begin{theorem}
    (\emph{Least Upper Bound Axiom}) Every non-empty set bounded above has a \emph{supremum}.
    \label{luba}
\end{theorem}
\begin{definition}
    (Supremum) If \(S\subset\mathbb{R}\),\(S\neq\emptyset\) we say that
    \[\sup S=K\]
    if 
    \begin{enumerate}
        \item \(x\leq K\quad\forall x\in S\) (\(K\) is upper bound for \(S\)).
        \item Given \(\epsilon>0\), \(\exists x\in S\) such that \(x>K-\epsilon\) (\(K\) is least upper bound).
    \end{enumerate}
    \label{def:sup}
\end{definition}
Note that similar definition can be made for greatest lower bound and infimum. If \(\sup S\in S\), we say \(\sup S\) is the \emph{maximum} of \(S\), i.e. \(\sup S=\max S\).
\begin{lemma} \hfill
    \begin{enumerate}
        \item The limit is unique, i.e. if \(a_n\to a\) and \(a_n\to b\) as \(n\to\infty\) then \(a=b\).
        \item Subsequences converge to the same limit, i.e. if \(a_n\to a\) as \(n\to \infty\) and \(n_1<n_2<\cdots\), then \(a_{n_j}\to a\) as \(j\to\infty\).
        \item If \(a_n=c\quad\forall n\), then \(a_n\to c\) as \(n\to\infty\).
        \item If \(a_n\to a\) and \(b_n\to b\) then \(a_n+b_n\to a+b\).
        \item If \(a_n\to a\) and \(b_n\to b\) then \(a_nb_n\to ab\).
        \item If \(a_n\to a\), \(a_n\neq 0\) and \(a\neq 0\), then \(1/a_n\to 1/a\).
        \item If \(a_n\leq A\quad\forall n\) and \(a_n\to a\), then \(a\leq A\).
        \item If \(a_n\to a\) and \(c_n\to a\) as \(n\to\infty\) and
        \(a_n\leq b_n\leq c_n\), then \(b_n\to a\).
    \end{enumerate}
    \label{fundlemma}
\end{lemma}
\begin{proof}
    We will only prove 1, 2, and 5 here.
    \begin{enumerate}
        \item For any \(\epsilon>0\), we can find \(N_1(\epsilon)\) and \(N_2(\epsilon)\) such that
        \[n\geq N_1(\epsilon)\Rightarrow|a_n-a|<\epsilon\]
        \[n\geq N_2(\epsilon)\Rightarrow|a_n-b|<\epsilon\]
        If \(n\geq\max\{N_1(\epsilon),N_2(\epsilon)\}\), then
        \begin{align*}
            0&\leq|b-a|=|b-a_n+a_n-a| \\
            &\leq|b-a_n|+|a_n-a|<2\epsilon
        \end{align*}
        This implies |b-a|=0, otherwise we can set \(\epsilon=|b-a|/3\) to find
        \[0\leq|b-a|<\frac 23|b-a|\]
        \hfill\qedsymbol
        \item Since \(n_j<n_{j+1}\Rightarrow n_{j+1}\geq n_j+1\), by induction, we have \(n_j\geq j\). As \(a_n\to a\) as \(n\to\infty\), given \(\epsilon>0\) there exists \(N=N(\epsilon)\) such that 
        \[n\geq N(\epsilon)\Rightarrow|a_n-a|<\epsilon\]
        So if \(j\geq N(\epsilon)\), then \(n_j\geq j\geq N(\epsilon)\) and 
        \[|a_{n_j}-a|<\epsilon\]
        \hfill\qedsymbol
        \item As \(a_n\to a\), \(b_n\to b\) as \(n\to\infty\), for any \(\epsilon>0\), we can find \(N_1(\epsilon)\) and \(N_2(\epsilon)\) such that
        \[n\geq N_1(\epsilon)\Rightarrow|a_n-a|<\epsilon\]
        \[n\geq N_2(\epsilon)\Rightarrow|b_n-b|<\epsilon\]
        Now
        \begin{align*}
            |a_nb_n-ab|&=|a_nb_n-a_nb+a_nb-ab| \\
            &\leq|a_nb_n-a_nb|+|a_nb-ab| \\
            &=|a_n||b_n-b|+|b||a_n-a|
        \end{align*}
        If \(n\geq N_1(1)\) then \(|a_n-a|\leq 1\) and hence
        \[|a_n|=|a_n-a+a|\leq |a_n-a|+|a|\leq 1+|a|\]
        Thus if \(n\geq N_3(\epsilon)=\max\{N_1(1),N_1(\epsilon),N_2(\epsilon)\}\) then
        \[|a_nb_n-ab|<(1+|a|)\epsilon+|b|\epsilon=(1+|a|+|b|)\epsilon\]
        which can be made as small as we like.
    \end{enumerate}
\end{proof}
\begin{lemma}\item[]
    \begin{enumerate}
        \item \(1/n\to 0\) as \(n\to\infty\).
        \begin{proof}
            \((1/n)\) is a decreasing sequence, bounded below by 0, so by monotone convergence theorem it has a limit \(L\). Now,
            \[\frac{1}{2n}=\left(\frac 12\right)\left(\frac 1n\right)\to\frac 12 L\]
            (Lemma \ref{fundlemma} (3), (5)). But \((1/2n)\) is a subsequence of \((1/n)\), so by Lemma \ref{fundlemma} (2),
            \[\frac 1{2n}\to L\]
            Then, by Lemma \ref{fundlemma} (1),
            \[\frac{1}{2}L=L\]
            and \(L=0\).
        \end{proof}
        \item If \(|x|<1\), \(x^n\to 0\) as \(n\to\infty\).
        \begin{proof}
            Suppose \(0\leq x<1\). Then \((x^n)\) is a decreasing sequence bounded below by \(0\), and it converges by monotone convergence theorem to a limit \(L\). Now,
            \[x^{n+1}=xx^n\to xL\]
            (Lemma \ref{fundlemma} (5)). However, \((x^{n+1})\) is a subsequence of \((x^n)\) so by Lemma \ref{fundlemma} (2), \(x^{n+1}\to L\); and consequently by Lemma \ref{fundlemma} (1), \(L=xL\Rightarrow L=0\).

            Suppose \(-1<x<1\). Then,
            \[-|x|^n\leq x^n\leq|x|^n\]
            We know \(|x|^n\to 0\) and \(-|x|^n\to 0\) from above, so
            \(x^n\to 0\) by Lemma \ref{fundlemma} (8).
        \end{proof}
    \end{enumerate}
\end{lemma}
Note that when we talk about a sequence converging, we mean to a \emph{finite} limit, while there is a notion of \emph{tending to infinity}: \(a_n\to\infty\) if \(\forall M\in\mathbb{R}\) \(\exists N=N(M)\) such that \(n\geq N\Rightarrow a_n>M\). 

Meanwhile, we can see that our definition of convergence still works if \(a_n,a\in\mathbb{C}\) (Definition \ref{def:limit}). Furthermore, Lemma \ref{fundlemma} (1) to (6) all apply for complex sequences, but (7), (8), and Theorem \ref{mct} use the \emph{order relation} so do not carry over directly.
\begin{lemma}
    If \((z_n)\) is a complex sequence, then \(z_n\to z\) if and only if \(\Re(z_n)\to\Re(z)\) and \(\Im(z_n)\to\Im(z)\). 
    \label{lemma:complex_conv}
\end{lemma}
\begin{proof}
    Note if \(\omega\in\mathbb{C}\),
    \[\max\{|\Re(\omega)|,|\Im(\omega)|\}\leq|\omega|\leq|\Re(\omega)|+|\Im(\omega)|\]
    
    (\(\Rightarrow\)) Suppose \(z_n\to z\). Then, \(\forall\epsilon>0\) there exists \(N=N(\epsilon)\) such that
    \begin{align*}
        n\geq N\Rightarrow|z_n-z|<\epsilon&\Rightarrow|\Re(z_n)-\Re(z)|<\epsilon \\
        &\text{and } |\Im(z_n)-\Im(z)|<\epsilon
    \end{align*} 
    Therefore  \(\Re(z_n)\to\Re(z)\) and \(\Im(z_n)\to\Im(z)\).

    (\(\Leftarrow\)) Suppose \(\Re(z_n)\to\Re(z)\) and \(\Im(z_n)\to\Im(z)\). Then \(\forall\epsilon>0\) \(\exists N_1=N_1(\epsilon),N_2=N_2(\epsilon)\) such that 
    \begin{align*}
        n\geq N_1&\Rightarrow|\Re(z_n)-\Re(z)|<\epsilon \\
        n\geq N_2&\Rightarrow|\Im(z_n)-\Im(z)|<\epsilon
    \end{align*}
    So if \(n\geq\max\{N_1(\epsilon),N_2(\epsilon)\}=N_3(\epsilon)\), then
    \[|z_n-z|\leq|\Re(z_n)-\Re(z)|+|\Im(z_n)-\Im(z)|<2\epsilon\]
    and therefore \(z_n\to z\).
\end{proof}
\begin{theorem}
    (\emph{Bolzano-Weierstrass Theorem}) Every bounded sequence in \(\mathbb{R}\) has a convergent subsequence, i.e. if \(x_n\in\mathbb{R}\) and there exists \(K>0\) such that \(|x_n|\leq K\quad\forall n\), we can find \(n_1<n_2<n_3<\cdots\) and \(x\in\mathbb{R}\) such that \(x_{n_j}\to x\) as \(j\to\infty\). 
    N.b. we do not assert uniqueness, e.g. if \(x_n=(-1)^n\), \(x_{2n}\to 1\) but \(x_{2n+1}\to -1\).
    \label{thm:bwt}
\end{theorem}
\begin{proof}
    Set \(a_1=-K\), \(b_1=K\) so that all terms of \((x_n)\) lie in \([a_1,b_1]\). Let \(c=(a_1+b_1)/2\). Either
    \begin{enumerate}
        \item There are infinitely many terms of \((x_n)\) in \([a_1,c]\) or 
        \item There are infinitely many terms of \((x_n)\) in \([c,b_1]\).
    \end{enumerate}
    If (1) holds, we set \(a_2=a_1\), \(b_2=c\); or if (1) does not hold, we set \(a_2=c\), \(b_2=b_1\). Continue inductively to construct \(a_k\), \(b_k\) such that infinitely many terms of \((x_n)\) lie in \([a_k,b_k]\), with
    \[b_{k+1}-a_{k+1}=\frac 12(b_k-a_k)\]
    and 
    \[a_k\leq a_{k+1}<b_{k+1}\leq b_k\]
    By construction, \((a_k)\) is increasing and bounded above by \(b_1\). So, from the monotone convergence theorem,
    \[a_k\to a\in[a_1,b_1]\text{  as  }k\to\infty\]
    Similarly, since \((b_k)\) is decreasing and bounded below by \(a_1\),
    \[b_k\to b\in[a_1,b_1]\text{  as  }k\to\infty\]
    But
    \[b_{k+1}-a_{k+1}=\frac 12(b_k-a_k)\Rightarrow b-a=\frac 12(b-a)\]
    and \(b=a\). Now construct \(n_j\) as follows.
    \begin{itemize}
        \item Pick \(n_1=1\).
        \item Pick \(n_j\) to be the smallest integer greater than \(n_{j-1}\) such that \(x_{n_j}\in[a_j,b_j]\).
    \end{itemize}
    We can do this as \([a_j,b_j]\) contains infinitely many terms of \((x_n)\). Viz, \(a_j\leq x_{n_j}\leq b_j\) and by Lemma \ref{fundlemma} (8), \(x_{n_j}\to a\).
\end{proof}
\begin{definition}
    A sequence \((a_n)\) of real numbers is a \emph{Cauchy sequence} (Cauchy) if for all \(\epsilon>0\) there exists \(N=N(\epsilon)\) such that \(n,m\geq N\Rightarrow|a_n-a_m|<\epsilon\).
\end{definition}
\begin{lemma}
    Every convergent sequence is a Cauchy sequence.
    \label{lemma:conv_cauchy}
\end{lemma}
\begin{proof}
    If \(a_n\to a\), then given \(\epsilon>0\) \(\exists N=N(\epsilon)\) such that if \(n\geq N\), \(|a_n-a|<\epsilon\). But if \(m,n\geq N\),
    \[|a_n-a_m|=|a_n-a+a-a_m|\leq |a_n-a|+|a_m-a|<2\epsilon\]
\end{proof}
\begin{theorem}
    Every Cauchy sequence is convergent.
    \label{thm:conv_cauchy}
\end{theorem}
\begin{proof}
    Suppose \((a_n)\) is Cauchy. First we show \((a_n)\) is bounded. Since \((a_n)\) is Cauchy, given \(\epsilon>0\) \(\exists N=N(\epsilon)\) such that 
    \[|a_n-a_m|<\epsilon\quad\forall n,m\geq N(\epsilon)\]
    So if \(n,m\geq N(1)\), then \(|a_n-a_m|<1\). Set \(m=N(1)\) to see 
    \[|a_n|=|a_n-a_{N(1)}+a_{N(1)}|\leq|a_n-a_{N(1)}|+|a_{N(1)}|\leq 1+|a_{N(1)}|\quad\forall n\geq N(1)\]
    Thus if \(K=1+\max\{|a_1|,\ldots,|a_{N(1)}|\}\),
    \[|a_n|\leq K\quad\forall n\]
    Now, by Bolzano-Weierstrass theorem (Theorem \ref{thm:bwt}), there must be \(a\in\mathbb{R}\) and \(n_1<n_2<n_3<\cdots\) such that \(a_{n_j}\to a\) as \(j\to\infty\). We claim, in fact, \(a_n\to a\) as \(n\to\infty\). To see this, write
    \[|a_n-a|=|a_n-a_{n_j}+a_{n_j}-a|\leq|a_n-a_{n_j}|+|a_{n_j}-a|\] and fix \(\epsilon>0\). Since \((a_n)\) is Cauchy, \(\exists N_1(\epsilon)\) such that if \(n,n_j\geq N_1(\epsilon)\), \(|a_n-a_{n_j}|<\epsilon\). 

    Since \(a_{n_j}\to a\), \(\exists N_2(\epsilon)\) such that if \(j\geq N_2(\epsilon)\), \(|a_{n_j}-a|<\epsilon\). Fix \(j\) such that \(j\geq N_2(\epsilon)\) and \(n_j\geq N_1(\epsilon)\). Then we have, for any \(n\geq N_1(\epsilon)\),
    \[|a_n-a|<2\epsilon\]
    i.e. \(a_n\to a\).
\end{proof}
We have shown a real sequence converges if and only if it is Cauchy (Lemma \ref{lemma:conv_cauchy} and Theorem \ref{thm:conv_cauchy}). This is called the \emph{Cauchy's general principle of convergence}.
\begin{corollary}
    A complex sequence converges if and only if it is Cauchy.
\end{corollary}
\begin{proof}
    From estimate at start of proof of Lemma \ref{lemma:complex_conv}, it follows that \((z_n)\) is Cauchy if and only if \((\Re(z_n))\) and \((\Im(z_n))\) are both Cauchy.
\end{proof}
\subsection{Series and Convergence Tests}
\begin{definition}
    Suppose \(a_j\in\mathbb{R}(\text{ or }\mathbb{C})\). Define sequence of \emph{partial sums} \((S_N)\) where
    \[S_N=\sum_{j=1}^N a_j\]
    Then, if \(S_N\to S\) as \(N\to\infty\), we write
    \[S=\sum_{j=1}^\infty a_j\]
    and say \(\sum_{j=1}^\infty a_j\) converges. Conversely, if \(S_N\) does not converge, we say \(\sum_{j=1}^\infty a_j\) diverges.
\end{definition}
\begin{remark}
    Any problem on series is a problem about sequences, and vice versa.
\end{remark}
\begin{lemma} \item[]
    \begin{enumerate}
        \item If \(\sum_{j=1}^\infty a_j\) and \(\sum_{j=1}^\infty b_j\) converge, then so does 
        \[\sum_{j=1}^\infty(\lambda a_j+\mu b_j)\]
        for \(\lambda, \mu\in\mathbb{R}(\text{ or }\mathbb{C})\); and 
        \[\sum_{j=1}^\infty(\lambda a_j+\mu b_j)=\lambda\sum_{j=1}^\infty a_j+\mu\sum_{j=1}^\infty b_j\]
        \item Suppose there exists \(N\) such that \(a_j=b_j\) \(\forall j\geq N\). Then either \(\sum_{j=1}^\infty a_j\) and \(\sum_{j=1}^\infty b_j\) both converge, or both diverge.
        \begin{proof}
            Suppose \(n\geq N\). Then,
            \[S_n=\sum_{j=1}^{N-1} a_j+\sum_{j=N}^n a_j\]
            and
            \begin{align*}
                D_n&=\sum_{j=1}^{N-1} b_j+\sum_{j=N}^n b_j \\
                &=S_n+\left(\sum_{j=1}^{N-1}b_j-\sum_{j=1}^{N-1}a_j\right) \\
                &=S_n+k
            \end{align*}
            where \(k\) finite constant. Thus, \(D_n\) converges if and only if \(S_n\) converges.
        \end{proof}
    \end{enumerate}
    \label{lemma:series}
\end{lemma}
An important example is the \emph{geometric series}. Suppose \(x\in\mathbb{R}\) and let \(a_j=x^{j-1}\) for \(j\geq 1\). Then,
\[S_n=\sum_{j=1}^{n}x^{j-1}=1+x+x^2+\cdots+x^{n-1}\]
and 
\[S_n=\begin{cases}
    \frac{1-x^n}{1-x} & x\neq 1 \\
    n & x=1
\end{cases}\]
We can check the convergence of \(S_n\) for different values of \(x\):
\begin{itemize}
    \item if \(|x|<1\), \(x^n\to 0\) and \(S_n\to 1/(1-x)\). 
    \item if \(x\geq 1\), write \(x=1+\delta\) where \(\delta\geq 0\). By expansion,
    \[x^n=1+\delta n+\cdots+\delta^n\geq 1+\delta n\]
    Hence, \(x^n\to\infty\) and \(S_n\to\infty\) for \(x>1\).
    \item if \(x=1\), trivially \(S_n=n\to\infty\).
    \item if \(x<-1\), \(x^n=(-1)^n|x|^n\) does not converge as \(|x|^n\to\infty\). \(|S_n|\to\infty\) but \(S_n\) may alternate in sign.
    \item if \(x=-1\), 
    \[S_n=\begin{cases}
        1 & n\text{ odd} \\
        0 & n\text{ even}
    \end{cases}\]
    and hence it does not converge.
\end{itemize}
Therefore, we may conclude that \(\sum_{j=1}^{\infty}x^{j-1}\) converges if and only if \(|x|<1\).

Let's take a further look into convergence tests. A simple, but useful result is the \emph{n{\textsuperscript{th}} term test}.
\begin{lemma}
    If \(\sum_{j=1}^{\infty}a_j\) converges, then \(a_j\to 0\) as \(j\to\infty\).
    \label{lemma:nth_test}
\end{lemma}

\begin{proof}
    If \(S_n=\sum_{j=1}^{n}a_j\), \(a_n=S_n-S_{n-1}\) but
    \[S_n\to S\Rightarrow S_{n-1}\to S\]
    so \(a_n\to 0\).
\end{proof}
Note that converse of Lemma \ref{lemma:nth_test} is false. For example, consider \(\sum_{j=1}^{\infty}1/j\), i.e. \emph{harmonic series}. If we let \(S_n=\sum_{j=1}^{n}1/j\),
\begin{align*}
    S_{2n}&=S_n+\frac{1}{n+1}+\frac{1}{n+2}+\cdots +\frac{1}{2n} \\
    &\geq S_n+\frac{1}{2n}+\frac{1}{2n+1}+\cdots +\frac{1}{2n}
\end{align*}
Thus \(S_{2n}\geq S_n+1/2\) and \(S_{2n}-S_n\geq 1/2\). If \(S_n\to S\), then \(S_{2n}\to S\) and \(0\geq 1/2\), which is a contradiction. Therefore, \(S_n=\sum_{j=1}^{n}1/j\) diverges. 

Moreover, Lemma \ref{lemma:nth_test} is often used to show a series does not converge. 


\subsubsection{Series with non-negative terms}
We consider, for the time being, series whose terms satisfy 
\[a_j\geq 0\quad\forall j\]
\begin{theorem}
    (\emph{Comparison Test})
    Suppose \(0\leq b_n\leq a_n\quad\forall n\). Then if \(\sum_{n=1}^{\infty}a_n\) converges, so does \(\sum_{n=1}^{\infty}b_n\).
    \label{thm:comparison_test}
\end{theorem}
\begin{proof}
    Let \(S_N=\sum_{n=1}^{N}a_n\) and \(D_N=\sum_{n=1}^{N}b_n\). Both \(S_N\) and \(D_N\) are monotonically increasing and \(S_N\to S\). But
    \[b_n\leq a_n\Rightarrow D_N\leq S_N\leq S\]
    So, since \((D_N)\) is increasing and bounded above, \(D_N\) converges (Theorem \ref{mct}).
\end{proof}
For example of the comparison test, consider \(\sum_{n=1}^{\infty}1/n^2\). We have
\[0\leq\frac{1}{n^2}<\frac{1}{n(n-1)}=\underbrace{\frac{1}{n-1}-\frac 1n}_{a_n}\]
for \(n\geq 2\). Then,
\[\sum_{n=2}^{N}a_n=\left(1-\frac 12\right)+\left(\frac 12-\frac 13\right)+\cdots+\left(\frac 1{N-1}-\frac 1N\right)=1-\frac 1N\to 1\]
as \(N\to\infty\).
Hence, since \(\sum_{n=2}^{\infty}1/(n-1)n\) converges, \(\sum_{n=2}^{\infty}1/n^2\) and consequently \(\sum_{n=1}^{\infty}1/n^2\) converges by comparison test.
\begin{theorem}
    (\emph{Root Test}) Suppose \(a_n\geq 0\) and \(a_n^{1/n}\to a\) as \(n\to\infty\). Then if \(a<1\), \(\sum a_n\) converges; else if \(a>1\), \(\sum a_n\) diverges. If \(a=1\), test is inconclusive.
\end{theorem}
\begin{proof}
    If \(a<1\), choose \(r\) such that \(a<r<1\). From Definition \ref{def:limit}, \(\exists N\) such that \(\forall n\geq N\)\footnote{Choose \(\epsilon=r-a>0\).} 
    \[a_n^{1/n}<r\Rightarrow a_n<r^n\]
    Since \(r<1\), the series \(\sum r^n\) converges, so by comparison test and Lemma \ref{lemma:series} (2), we have that \(\sum a_n\) converges.

    If \(a>1\), \(\exists N\) such that \(\forall n\geq N\) \(a_n^{1/n}>1\Rightarrow a_n>1\). Hence, \(\sum a_n\) diverges (Lemma \ref{lemma:nth_test}).
\end{proof}
\begin{theorem}
    (\emph{Ratio Test}) Suppose \(a_n>0\) and \(a_{n+1}/a_n\to l\). If \(l<1\) \(\sum a_n\) converge; else if \(l>1\) \(\sum a_n\) diverge. If \(l=1\), test is inconclusive.
\end{theorem}
\begin{proof}
   Suppose \(l<1\) and choose \(r\) with \(l<r<1\). Then from Definition \ref{def:limit}, \(\exists N\) such that \(\forall n\geq N\) \(a_{n+1}/a_n<r\). Hence, for \(n>N\),
   \[a_n=\frac{a_n}{a_{n-1}}\frac{a_{n-1}}{a_{n-2}}\cdots\frac{a_{N+1}}{a_{N}}a_N<a_Nr^{n-N}\Rightarrow a_n<kr^n\]
   where \(k\) is independent of \(n\). But since \(\sum kr^n\) converges, so does \(\sum a_n\) (Lemma \ref{lemma:series} (2)).

   If \(l>1\), pick \(r>1\) such that \(1<r<l\). Then, \(\exists N\) such that \(\forall n\geq N\) \(a_{n+1}/a_n>r\) and
   \[a_n=\frac{a_n}{a_{n-1}}\frac{a_{n-1}}{a_{n-2}}\cdots\frac{a_{N+1}}{a_{N}}a_N>a_Nr^{n-N}\]
   But \(r^{n-N}\to\infty\) as \(n\to\infty\). Thus \(a_n\to\infty\) and \(\sum a_n\) diverges.
\end{proof}
Here are some examples for the tests above.
\begin{itemize}
    \item \(\sum(n/2^n)\). Can show the covergence by both ratio and root test.
    \item \(\sum 1/n\) diverges but ratio test and root test both yields 1 (inconclusive).
    \item \(\sum 1/n^2\) converges but ratio test and root test both yields 1 (inconclusive).
\end{itemize}
\begin{remark}
    To show \(n^{1/n}\to 1\), write \(n^{1/n}=1+\delta_n\) (\(\delta_n>0\)). Then, binomial expansion gives
    \[n=(1+\delta_n)^n>\frac{n(n-1)}{2}\delta_n^2\]
    and
    \[0<\delta_n^2<\frac{2}{n+1}\Rightarrow\delta_n=0\]
\end{remark}
\begin{theorem}
    (\emph{Cauchy's Condensation Test}) Let \((a_n)\) be a decreasing sequence of positive terms. Then \(\sum_{n=1}^{\infty}a_n\) converges if and only if
    \[\sum_{n=1}^{\infty}2^na_{2^n}\]
    converges.
    \label{thm:cauchy_condensation_test}
\end{theorem}
\begin{proof}
    Since \(a_n\) is decreasing, note that
    \[a_{2^k}\leq a_{2^{k-1}+i}\leq a_{2^{k-1}}\]
    for \(1\leq i\leq 2^{k-1}\). Let us prove each direction seperately.

    (\(\Rightarrow\)) Suppose \(\sum a_n\) converges. But
    \begin{align*}
        2^{k-1}a_{2^k}&=a_{2^k}+\cdots+a_{2^k} \\
        &\leq a_{2^{k-1}+1}+a_{2^{k-1}+2}+\cdots+a_{2^{k-1}+2^{k-1}} \\
        &=\sum_{n=2^{k-1}+1}^{2^k}a_n
    \end{align*}
    Hence,
    \[\sum_{k=1}^{K}2^{k-1}a_{2^k}\leq\sum_{k=1}^{K}\left(\sum_{n=2^{k-1}+1}^{2^k}a_n\right)=\sum_{n=2}^{2^K}a_n\leq\sum_{n=1}^{\infty}a_n\]
    and \(\sum_{k=1}^{K}2^ka_{2^k}\) converges since it is increasing in \(K\) and bounded above.

    (\(\Leftarrow\)) Suppose \(\sum 2^na_{2^n}\) converges. Then,
    \begin{align*}
        \sum_{n=2^{k-1}+1}^{2^k}a_n&= a_{2^{k-1}+1}+a_{2^{k-1}+2}+\cdots+a_{2^{k-1}+2^{k-1}} \\
        &\leq
        a_{2^{k-1}}+\cdots+a_{2^{k-1}} \\
        &=2^{k-1}a_{2^{k-1}}
    \end{align*}
    This implies
    \[\sum_{n=2}^{2^K}a_n=\sum_{k=1}^{K}\left(\sum_{n=2^{k-1}+1}^{2^k}a_n\right)\leq\sum_{k=1}^{K}2^{k-1}a_{2^{k-1}}\leq\sum_{n=1}^{\infty}2^{k-1}a_{2^{k-1}}\]
    Thus for any \(N\), if we pick \(K\) such that \(2^K>N\),
    \[\sum_{n=2}^{N}\leq\sum_{n=2}^{2^K}a_n\leq\sum_{n=1}^{\infty}2^{k-1}a_{2^{k-1}}\]
    Similarly, by monotone convergence theorem, \(\sum_{n=2}^Na_n\) converges.
\end{proof}
\begin{corollary}
    (\emph{\(p\)-series test}) \(\sum_{n\geq 1}(1/n^p)\) (for \(p>0\)) converges if and only if \(p>1\).
\end{corollary}
\begin{proof}
    \(a_n=1/n^p\) is a decreasing sequence of positive numbers, since
    \[\frac{n}{n+1}<1\Rightarrow\left(\frac{n}{n+1}\right)^p<1\Rightarrow\frac{1}{(n+1)^p}<\frac{1}{n^p}\]
    Meanwhile,
    \[2^na_{2^n}=2^n\left(\frac{1}{2^n}\right)^p=2^{n-np}=\left(2^{1-p}\right)^n=r^n\]
    We know that \(\sum r^n\) converges if and only if \(r<1\), which is equivalent to \(p>1\). Hence, by Cauchy's condensation test, \(\sum_{n\geq 1}(1/n^p)\) (for \(p>0\)) converges if and only if \(p>1\).
\end{proof}
\subsubsection{Alternating series}
\begin{theorem}
    (\emph{Alternating Series Test}) Suppose \((a_n)\) is a decreasing sequence, tending to \(0\) as \(n\to\infty\). Then, the series 
    \[\sum_{n=1}^{\infty}(-1)^{n+1}a_n\]
    converges.
    \label{thm:alter_test}
\end{theorem}
\begin{proof}
    Let
    \[S_n=\sum_{k=1}^{n}(-1)^{k+1}a_k\]
    Then we can find \(S_{2n}\) is increasing, since
    \[S_{2n}=(a_1-a_2)+(a_3-a_4)+\cdots+(a_{2n-1}-a_{2n})\]
    Similarly,
    \[S_{2n+1}=a_1-(a_2-a_3)-(a_4-a_5)-\cdots-(a_{2n}-a_{2n+1})\]
    gives
    \[S_{2n+1}\leq S_{2n-1}\leq\cdots\leq S_3\leq S_1\]
    Furthermore,
    \(S_{2n+1}=S_{2n}+a_{2n+1}\leq S_{2n}\), so
    \[S_2\leq S_4\leq\cdots\leq S_{2n}\leq S_{2n+1}\leq S_{2n-1}\leq\cdots\leq S_3\leq S_1\]
    See that \((S_{2n})\) is increasing, bounded above by \(S_1\); so \(S_{2n}\to S\); and \((S_{2n+1})\) is decreasing, bounded below by \(S_2\), so \(S_{2n+1}\to\tilde{S}\). But
    \[S_{2n+1}=S_{2n}+a_{2n+1}\]
    implies \(\tilde{S}=S\). Thus, given \(\epsilon>0\) there exists \(N_1,N_2\) such that
    \[|S_{2n}-S|<\epsilon\quad\forall n\geq N_1\]
    \[|S_{2n+1}-S|<\epsilon\quad\forall n\geq N_2\]
    Therefore, if we choose \(n\geq 2\max\{N_1,N_2\}+1=N\), \(|S_n-S|<\epsilon\Rightarrow S_n\to S\).
\end{proof}
One may easily see that \(\sum(-1)^{n+1}/n\) converges using the alternating series test.
\subsubsection{Absolute  and conditional convergence}
\begin{definition}
    Let \(a_n\in\mathbb{C}\). If \(\sum_{n=1}^{\infty}|a_n|\) converges, we say \(\sum_{n=1}^\infty a_n\) is \emph{absolutely convergent}.
\end{definition}
Note that since \(|a_n|\geq 0\), previous tests can be applied to show absolute convergence.
\begin{theorem}
    If \(\sum_{n=1}^{\infty}a_n\) is absolutely convergent, then it is convergent.
    \label{thm:abconv}
\end{theorem}
\begin{proof}
    Let
    \[S_n=\sum_{k=1}^{n}a_k,\quad\bar{S}_n=\sum_{k=1}^{n}|a_k|\]
    Suppose that \(n\leq m\). Then
    \[|S_m-S_n|=\left|\sum_{k=n+1}^{m}a_k\right|\leq\sum_{k=n+1}^{m}|a_k|=|\bar{S}_m-\bar{S}_n|\]
    \((\bar{S}_n)\) is convergent, hence Cauchy (Lemma \ref{lemma:conv_cauchy}), so given \(\epsilon>0\) \(\exists N\) such that \(\forall m\geq n\geq N\) we have 
    \[|\bar{S}_m-\bar{S}_n|<\epsilon\Rightarrow|S_m-S_n|<\epsilon\]
    Thus \((S_n)\) is Cauchy and it converges (Theorem \ref{thm:conv_cauchy}).
\end{proof}
For example of absolute convergence, consider \(\sum_{n=1}^{\infty}a_n\) where \(z\in\mathbb{C}\) and \(a_n=(z^n/2^n)\). \(|a_n|=(|z|/2)^n\) so \(\sum|a_n|\) converges if and only if \(|z|/2<1\). This gives absolute convergence for \(|z|<2\). If \(|z|\geq 2\), \(|a_n|\geq 1\) and there is no absolute convergence. Finally, note that coverse of Theorem \ref{thm:abconv} is false. 
\begin{definition}
    If \(\sum a_n\) converges, but \(\sum|a_n|\) does not, we say series is \emph{conditionally convergent}. 
\end{definition}
N.b. order of terms matters. If rearranged, the sum may change. Consider the rearranged sequences below.
\begin{enumerate}
    \item \(1-\frac 12+\frac 13-\frac 14+\cdots\)
    \item \(1+\frac 13-\frac 12+\frac 15-\frac 17-\frac 14+\frac 19+\frac 1{11}-\frac 16+\cdots\)
\end{enumerate}
If \(S_n\) is partial sum of (1), \(T_n\) partial sum of (2), then
\begin{align*}
    S_n&\to S>0 \\
    T_n&\to\frac{3S}{2}\neq S
\end{align*}
\begin{definition}
    Let \(\sigma\::\:\mathbb{N}\to\mathbb{N}\) be a bijection, then \((a_n^\prime)\) with \(a_n^\prime=a_{\sigma(n)}\) is a \emph{rearrangement} of \((a_n)\).
\end{definition}
\begin{theorem}
    If \(a_n^\prime=a_{\sigma(n)}\) is a rearrangement of \((a_n)\), and \(\sum_{n=1}^\infty a_n\) is absolutely convergent, then
    \[\sum_{n=1}^\infty a_n=\sum_{n=1}^\infty a_n^\prime\]
\end{theorem}
\begin{proof}
    Fix \(\epsilon>0\). Since \(\sum_{n=1}^\infty |a_n|\) converges, \(\exists N\) such that
    \[\sum_{n=N+1}^\infty |a_n|<\epsilon\]
    Pick \(M\) such that \(\sigma^{-1}(k)<M\) for \(k=1,\ldots,N\). Then if \(m\geq M\),
    \[\sum_{n=1}^\infty a_n-\sum_{n=1}^m a_{\sigma(n)}=\sum_{n\in K_m}a_n\]
    where \(K_m=\{N+1,N+2,\ldots\}\setminus\{\text{finitely many points}\}\). So
    \[\left|\sum_{n=1}^\infty a_n-\sum_{n=1}^m a_n^\prime\right|\leq\sum_{n\in K_m}|a_n|\leq\sum_{n\geq N+1}|a_n|<\epsilon\]
    i.e. \(\sum_{n=1}^{m}a_n^\prime\to\sum_{n=1}^{\infty}a_n\) as \(m\to\infty\).
\end{proof}
\section{Continuity}
\subsection{Continuity of a Function}
Suppose \(\mathrm{E}\subseteq\mathbb{C}\) is non-empty, and \(f:\mathrm{E}\to\mathbb{C}\) is any function (includes case where \(\mathrm{E}\subseteq\mathbb{R}\), \(f\::\:\mathrm{E}\to\mathbb{R}\)).
\begin{definition}
    \(f\) is \emph{continuous} at \(a\in\mathrm{E}\) if: given \(\epsilon>0\), there exists \(\delta=\delta(\epsilon)>0\) such that
    \[|f(z)-f(a)|<\epsilon\]
    for all \(z\in\mathrm{E}\) with \(|z-a|<\delta\), i.e. ``\emph{Points close to \(a\) in the domain are mapped close to \(f(a)\) in range}.''
    \label{def:contd}
\end{definition}
We say \(f\) is continuous on \(\mathrm{E}\) if \(f\) is continuous at \(a\) for all \(a\in\mathrm{E}\). 
% N.b. if \(\mathrm{E}^\prime\subseteq\mathrm{E}\) then \(f\) continuous on \(\mathrm{E}\), 
\begin{theorem}
    \(f:\mathrm{E}\to\mathbb{C}\) is continuous at \(a\in\mathrm{E}\) if and only if
    \[f(z_n)\to f(a)\]
    for all sequences \((z_n)\) with \(z_n\in\mathrm{E}\), \(z_n\to a\).
    \label{thm:contd}
\end{theorem}
\begin{proof}
    (\(\Rightarrow\)) Suppose \(f\) is continuous at \(a\), and \((z_n)\) is a sequence \(z_n\in\mathrm{E}\) with \(z_n\to a\). Let \(\epsilon>0\). Then \(\exists\delta>0\) such that
    \[z\in\mathrm{E},|z-a|<\delta\Rightarrow|f(z)-f(a)|<\epsilon\]
    Since \(z_n\to a\), there exists \(N\) such that 
    \[n\geq N\Rightarrow|z_n-a|<\delta\Rightarrow|f(z)-f(a)|<\epsilon\]
    Therefore \(f(z_n)\to f(a)\).

    (\(\Leftarrow\)) Suppose \(f\) is not continuous at \(a\). Then,
    \(\exists\epsilon>0\) such that \(\forall\delta>0\), \(\exists z\in\mathrm{E}\) with
    \[|z-a|<\delta\text{  and  }|f(z)-f(a)|\geq\epsilon\]
    apply this with 
    \[\delta=1,\frac 12,\frac 13,\ldots,\frac 1n,\ldots\]
    to find for each \(n\) and \(z_n\in\mathrm{E}\) with
    \[|z_n-a|<\frac 1n\text{  and  }|f(z_n)-f(a)|\geq\epsilon>0\]
    Then \(z_n\to a\) as \(n\to\infty\) but \(f(z_n)\nrightarrow f(a)\), which is a contradiction. Hence \(f\) is continuous at \(a\).
\end{proof}
This means we could alternatively take our definition of continuity as:
\[f(z_n)\to f(a)\]
for all sequences \((z_n)\) with \(z_n\in\mathrm{E}\), \(z_n\to a\).
\begin{lemma}
    Suppose \(f,g:\mathrm{E}\to\mathbb{C}\) are continuous at \(a\in\mathrm{E}\). Then so are the functions
    \begin{enumerate}
        \item \(f(z)+g(z)\),
        \item \(f(z)g(z)\),
        \item \(\lambda g(z)\) \space (constant \(\lambda\in\mathbb{C}\)),
        \item \(1/f(z)\) \space provided \(f(z)\neq 0\) \(\forall z\in\mathrm{E}\).
    \end{enumerate}
    \label{lemma:fund_contd}
\end{lemma}
\begin{proof}
    Using the sequential characterisation of continuity, this follows easily from analogous results for sequences (Lemma \ref{fundlemma}). E.g. if \(z_n\to a\),
    \[f(z_n)\to f(a)\text{  and  }g(z)\to g(a)\Rightarrow f(z_n)+g(z_n)\to f(a)+g(a)\]
    etc.
\end{proof}
Note that Lemma \ref{lemma:fund_contd} can also be directly proved from Definition \ref{def:contd}. We now show that composition of continuous functions is continuous.
\begin{theorem}
    Suppose \(A,B\subseteq\mathbb{C}\), \(f:A\to B\), \(g:B\to C\) and that \(f\) is continuous at \(a\in A\), \(g\) is continuous at \(f(a)\in B\). Then \(g\circ f:A\to\mathbb{C}\) is continuous at \(a\).
    \label{thm:comp_contd}
\end{theorem}
\begin{proof}
    Suppose \((z_n)\) is any sequence with \(z_n\in A\), \(z_n\to a\). Then by continuity of \(f\) at \(a\),
    \[f(z_n)\to f(a)\]
    By continuity of \(g\) at \(f(a)\),
    \[g(f(z_n))\to g(f(a))\Leftrightarrow g\circ f(z_n)\to g\circ f(a)\]
    Hence \(g\circ f\) is continuous at \(a\).
\end{proof}
Here are some examples of continuous (and discontinuous) functions.
\begin{enumerate}
    \item \(f(z)=z\) is continuous at all points of \(\mathbb{C}\).
    \item By Lemma \ref{lemma:fund_contd} and Example (1) above, any polynomial in \(z\) is continuous at all points of \(\mathbb{C}\).
    \item \(f(z)=|z|\) is continuous at all points of \(\mathbb{C}\).\footnote{See reverse triangle inequality.}
    \item \(f:\mathbb{R}\to\mathbb{R}\),
    \[x\mapsto\begin{cases}
        0 & x<0 \\
        1 & x\geq 0
    \end{cases}\]
    is not continuous at \(x=0\).
    \item \(f:\mathbb{R}\to\mathbb{R}\),
    \[f(x)=\begin{cases}
        \sin\frac 1x & x\neq 0 \\
        0 & x=0
    \end{cases}\]
    \(\sin x\) is continuous,\footnote{See later sections for proof.} so if \(x\neq 0\) then Theorem \ref{thm:comp_contd} and Lemma \ref{lemma:fund_contd} imply \(f\) is continuous at \(x\). However, \(f\) is discontinuous at \(x=0\). Choose \(x_n\) such that
    \[\frac 1{x_n}=\left(2n+\frac 12\right)\pi\]
    which imply \(f(x_n)=1\), \(x_n\to 0\), \(f(0)=0\neq\lim_{n\to\infty}f(x_n)\).
    \item \(f:\mathbb{R}\to\mathbb{R}\),
    \[f(x)=\begin{cases}
        x\sin\frac 1x & x\neq 0 \\
        0 & x=0
    \end{cases}\]
    \(f\) is continuous at \(x\neq 0\) by same reasons as (5). But \(f\) is also continuous at \(0\) this time. Suppose \(x_n\to 0\). Then
    \[|f(x_n)|=|x_n|\left|\sin\frac 1{x_n}\right|\leq|x_n|\]
    So \(|f(x_n)|\leq|x_n|\) and \(f(x_n)\to 0=f(0)\).
    \item (\emph{Dirichlet Function})  \(f:\mathbb{R}\to\mathbb{R}\),
    \[f(x)=\begin{cases}
        1 & x\in\mathbb{Q} \\
        0 & x\notin\mathbb{Q}
    \end{cases}\]
    is discontinuous at every point. If \(x\in\mathbb{Q}\), take sequence \(x_n\notin\mathbb{Q}\), then \(x_n\to x\) but 
    \[f(x_n)=0\nrightarrow f(x)=1\]
    If \(x\notin\mathbb{Q}\), take \(x_n\in\mathbb{Q}\), \(x_n\to x\) but
    \[f(x_n)=1\nrightarrow f(x)=0\]
\end{enumerate}
\subsection{Limit of a Function}
Suppose \(\mathrm{E}\subseteq\mathbb{C}\), \(f:\mathrm{E}\to\mathbb{C}\). We want to define 
\[\lim_{z\to a}f(z)\]
even when \(a\) may not belong to \(\mathrm{E}\). For instance, consider \(f:\mathbb{C}\backslash\{0\}\to\mathbb{C}\),
\[z\mapsto{\sin z}/{z}\] What is \(\lim_{z\to 0}f(z)\)? -- However, this does not always make sense. If \(\mathrm{E}=\{0\}\cup[1,2]\), for \(f:\mathrm{E}\to\mathbb{R}\) it is impossible to consider \(\lim_{x\to 0}f(x)\), because there are no point near \(0\) except \(0\) itself. 
\begin{definition}
    Suppose \(\mathrm{E}\subseteq\mathbb{C}\), \(a\in\mathbb{C}\). We say that \(a\) is a \emph{limit point} of \(\mathrm{E}\) if for any \(\delta>0\) there exists \(z\in\mathrm{E}\) such that
    \[0<|z-a|<\delta\]
    \label{def:limit_point}
\end{definition}
N.b. \(a\) is a limit point of \(\mathrm{E}\) if and only if there exists a sequence \((z_n)\) such that \(z_n\in\mathrm{E}\), \(z_n\neq a\), and 
\[z_n\to a\]
\begin{definition}
    Suppose \(\mathrm{E}\subseteq C\), \(f:\mathrm{E}\to\mathbb{C}\) and let \(a\in\mathbb{C}\) be a limit point of \(\mathrm{E}\). We say 
    \[\lim_{z\to a}f(z)=l\]
    if: given \(\epsilon>0\), \(\exists\delta>0\) such that \(\forall z\in\mathrm{E}\),
    \[0<|z-a|<\delta\Rightarrow|f(z)-l|<\epsilon\]
    \label{def:limit_ed}
\end{definition}
\begin{lemma}
    If \(f,\mathrm{E},a\) as above, then 
    \[\lim_{z\to a}f(z)=l\]
    if and only if \(f(z_n)\to l\) for all sequences \(z_n\in\mathrm{E}\), \(z_n\neq a\), \(z_n\to a\).
\end{lemma}
Observe that the definitions immediately tell us that if \(a\in\mathrm{E}\) is a limit point then \(f\) is continuous at \(a\) if and only if 
\[\lim_{z\to a}f(z)=f(a)\]
If \(a\in\mathrm{E}\) is \emph{isolated}, i.e. not a limit point, then \(f\) is always continuous at \(a\). 

Note that limit of functions behave similarly to limits of sequences.
\begin{lemma}
    Suppose \(\mathrm{E}\subseteq\mathbb{C}\), \(a\in\mathbb{C}\) is a limit point, and \(f,g:\mathrm{E}\to\mathbb{C}\)
    \begin{enumerate}
        \item The limit is unique, i.e. if \(f(z)\to A\) and \(f(z)\to B\) as \(z\to a\), then \(A=B\).
        \item If \(f(z)\to l\), \(g(z)\to k\), then\(f(z)+g(z)=l+k\) \space as \(z\to a\);
        \item \(f(z)g(z)=lk\) \space as \(z\to a\);
        \item \(f(z)/g(z)=l/k\) \space as \(z\to a\) (if \(k\neq 0\)).
    \end{enumerate}
    \label{lemma:fund_limit}
\end{lemma}
\begin{proof}
    (of (1))
    \[|A-B|=|A-f(z)+f(z)-B|\leq|A-f(z)|+|f(z)-B|\]
    for all \(z\in\mathrm{E}\), \(z\neq a\). Given \(\epsilon>0\), \(\exists\delta_1>0\) such that
    \[0<|z-a|<\delta_1,z\in\mathrm{E}\Rightarrow |f(z)-A|<\epsilon,\:z\in\mathrm{E}\]
    Also \(\exists\delta_2>0\) such that 
    \[0<|z-a|<\delta_2,z\in\mathrm{E}\Rightarrow |f(z)-B|<\epsilon,\:z\in\mathrm{E}\]
    Since \(a\) is a limit point, \(\exists z\in\mathrm{E}\) such that 
    \[0<|z-a|<\min\{\delta_1,\delta_2\}\Rightarrow|A-B|<2\epsilon\]
    Because \(\epsilon\) is arbitrary, \(A=B\).
\end{proof}
\begin{theorem}
    (\emph{Intermediate Value Theorem}) Suppose \(f:[a,b]\to\mathbb{R}\) is continuous and \(f(a)<f(b)\). Then for any \(\eta\) with \(f(a)<\eta<f(b)\) there exists \(c\in[a,b]\) such that \(f(c)=\eta\).
    \label{thm:ivt}
\end{theorem}
\begin{proof}
    Let 
    \[S=\{x\in[a,b]\:|\:f(x)<\eta\}\]
    Clearly \(S\) is not empty as \(a\in S\). \(S\) is bounded above by \(b\). So \(S\) has a supremum, \(c\) (Theorem \ref{luba}). We claim \(f(c)=\eta\). From the definition of a supremum (Definition \ref{def:sup}), for each \(n\in\mathrm{N}\) there exists \(x_n\in S\) with 
    \[c-\frac 1n\leq x_n\leq c\]
    Hence \(x_n\to c\). But \(f\) is continuous so \(f(x_n)\to f(c)\) and 
    \[f(x_n)<\eta\Rightarrow f(c)\leq\eta\]
    In particular, \(c\neq b\). Now let
    \[\tilde{x}_n=c+\frac 1n\]
    For \(n\) large enough, \(\tilde{x}_n\in[a,b]\), and \(\tilde{x}_n\to c\). Furthermore, \(f(\tilde{x}_n)\geq\eta\) since \[\tilde{x}_n>c\Rightarrow\tilde{x}_n\notin S\]
    Hence 
    \[f(c)=\lim_{n\to\infty}f(\tilde{x}_n)\geq\eta\]
    and thus \(f(c)=\eta\).
\end{proof}
This theorem is useful to find roots of functions. For example, we can check existence of \(N\){\textsuperscript{th}} roots. Suppose \(y>0\). Consider for \(N\in\mathbb{N}\) the function \(f:[0,1+y]\to\mathbb{R}\),
\[x\mapsto x^N\]
Then since
\[(a+y)^N\geq 1+Ny>y\]
we have 
\[f(0)<y<f(1+y)\]
and there exists \(c\in(0,1+y)\) such that \(f(c)=y\) by intermediate value theorem (IVT). \(c\) is a \emph{positive \(N\)\textsuperscript{th} root} of \(y\). In fact, since
\[y_1<y_2\Rightarrow f(y_1)<f(y_2)\]
\(c\) is unique.
\begin{lemma}
    (\emph{Bounds on Continuous Function}) Suppose \(f:[a,b]\to\mathbb{R}\) is continuous. Then there exist \(K\) such that
    \[|f(x)|\leq K\quad\forall x\in[a,b]\]
    \label{lemma:fn_bound}
\end{lemma}
\begin{proof}
    Suppose not. Then for each \(n=1,2,\ldots\) we can find \(x_n\in[a,b]\) with \(|f(x_n)|>n\). By Bolzano-Weierstrass theorem (Theorem \ref{thm:bwt}), \((x_n)\) is a bounded sequence, and hence has a subsequence \(x_{n_j}\to x\) for some \(x\). Moreover, since
    \[a\leq x_{n_j}\leq b\Rightarrow a\leq x\leq b\]
    so \(x\in[a,b]\). But 
    \[|f(x_{n_j})|>n_j\geq j\]
    so \(f(x_{n_j})\) cannot converge. This contradicts the assumption that \(f\) is continuous as \(f(x_{n_j})\nrightarrow f(x)\).
\end{proof}
\begin{theorem}
    (\emph{Extreme Value Theorem}) Suppose \(f:[a,b]\to\mathbb{R}\) is continuous. Then there exist \(y,Y\in[a,b]\) such that
    \[f(y)\leq f(x)\leq f(Y)\quad\forall x\in[a,b]\]
    \label{thm:evt}
\end{theorem}
\begin{proof}
    The set 
    \[A=\{f(x)\:|\:x\in[a,b]\}\]
    is bounded by Lemma \ref{lemma:fn_bound}, so has a supremum \(M=\sup A\). From Definition \ref{def:sup}, \(M-1/n\) is not an upper bound of \(A\) for \(n\in\mathbb{N}\). So \(\exists y_n\in A\) with 
    \[M-\frac 1n\leq y_n\leq M\]
    From definition of \(A\), there exists \(x_n\in[a,b]\) with
    \[y_n=f(x_n)\Rightarrow M-\frac 1n\leq f(x_n)\leq M\]
    \((x_n)\) is a bounded sequence. So by Bolzano-Weierstrass theorem we can pick a subsequence \((x_{n_j})\) such that \[x_{n_j}\to y\] for some \(y\in[a,b]\). Also \(f(x_{n_j})\to M\), so by continuity of \(f\),
    \[f(y)=\lim_{j\to\infty}f(x_{n_j})=M\]
    It follows immediately that
    \[f(x)\leq f(y)\quad\forall x\in[a,b]\]
    For lower bound, we can either consider \(\inf A\) and argue similarly, or apply result already established to \(-f\).
\end{proof}
Note that, for Lemma \ref{lemma:fn_bound} and Theorem \ref{thm:evt}, it is crucial that \(f\) is defined on a closed bounded interval: e.g. consider 
\begin{itemize}
    \item \(f:(0,1]\to\mathbb{R},\:x\mapsto 1/x\), continuous, but unbounded.
    \item \(f:[0,\infty)\to\mathbb{R},\:x\mapsto x\), continuous, but unbounded.
\end{itemize}
\subsection{Inverse Function Theorem}
\begin{definition}
    Function \(f:[a,b]\to\mathbb{R}\) is 
    \begin{itemize}
        \item \emph{increasing} if \(a\leq x_1<x_2\leq b\Rightarrow f(x_1)\leq f(x_2)\);
        \item \emph{strictly increasing} if \(a\leq x_1<x_2\leq b\Rightarrow f(x_1)< f(x_2)\).
    \end{itemize}
    Decreasing and strictly decreasing are defined similarly.
    \label{def:f_increasing}
\end{definition}
\begin{theorem}
    Suppose \(f:[a,b]\to\mathbb{R}\) is continuous and strictly increasing. Let \(c=f(a)\), \(d=f(b)\). Then 
    \[f:[a,b]\to[c,d]\]
    is a bijection and
    \[f^{-1}:[c,d]\to[a,b]\]
    is continuous and strictly increasing.
    \label{thm:ift_1}
\end{theorem}
\begin{proof}
    First we note that \(f\) is injective. If \(x\neq y\), then without loss of generality
    \[a\leq x<y\leq b\Rightarrow f(x)<f(y)\Rightarrow f(x)\neq f(y)\]
    Next, \(f\) maps into \([c,d]\). If \(a\leq x\leq b\), then 
    \[c=f(a)\leq f(x)\leq f(b)=d\]
    Also, \(f\) is surjective by intermediate value theorem: if \(\eta\in[c,d]\) then \(\exists x\in[a,b]\) with \(f(x)=\eta\).

    To show \(f^{-1}\) is continuous, fix \(z\in(c,d)\) and let \(y=f^{-1}(z)\in(a,b)\). Let \(\epsilon>0\) to be sufficiently small that
    \[a\leq y-\epsilon<y<y+\epsilon\leq b\Rightarrow c\leq f(y-\epsilon)<f(y)<f(y+\epsilon)\leq d\]
    Pick \(\delta>0\) such that \((z-\delta,z+\delta)\subset(f(y-\epsilon),f(y+\epsilon))\). Since \(f:(y-\epsilon,y+\epsilon)\to(f(y-\epsilon),f(y+\epsilon))\) is bijective, if \(|z^\prime-z|<\delta\), then 
    \begin{align*}
        z^\prime\in(f(y-\epsilon),f(y+\epsilon))&\Rightarrow f^{-1}(z^\prime)\in(y-\epsilon,y+\epsilon) \\
        &\Rightarrow|f^{-1}(z^\prime)-f^{-1}(z)|<\epsilon
    \end{align*}
    If \(z=c\) or \(d\) similar argument works. Therefore \(f^{-1}\) is continuous.

    To see \(f^{-1}\) is increasing, suppose not. Then \(\exists c\leq z_1<z_2\leq d\) with \(f^{-1}(z_1)\geq f^{-1}(z_2)\). But \(f\) is strictly increasing; this implies 
    \[f\left(f^{-1}(z_1)\right)\geq f\left(f^{-1}(z_2)\right)\Rightarrow z_1\geq z_2\]
    which is a contradiction. Thus \(f^{-1}\) is strictly increasing.
\end{proof}
\section{Differentiability}
In this section, let
\[f:\mathrm{E}\to\mathbb{C}\]
where \(\mathrm{E}\subseteq\mathbb{C}\), while mostly \(\mathrm{E}\) will be a real interval.
\begin{definition}
    Let \(x\in\mathrm{E}\) be a limit point. \(f\) is said to be \emph{differentiable} at \(x\), with derivative \(f^\prime(x)\) if
    \[\lim_{y\to x}\frac{f(y)-f(x)}{y-x}=f^\prime(x)\]
    exists.
\end{definition}
If \(f\) is differentiable at each \(x\in\mathrm{E}\), we say \(f\) is differentiable on \(\mathrm{E}\). Also, we will assume from now on \(\mathrm{E}\) has no isolated points (set is either interval or disc).
\begin{remark} \item[]
    \begin{enumerate}
        \item Other common notations are 
        \[\frac{df}{dx},\frac{dy}{dx}\]
        etc.
        \item We can equivalently write \[f^\prime(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]
        \item Another ways to phrase definition: 
        let \(\epsilon(h)=f(x+h)-f(x)-hf^\prime(x)\); then 
        \[\lim_{h\to 0}\frac{\epsilon(h)}{h}=0\]
        We say, \(f\) has a \emph{best affine approximation} near \(x\).
        \item If \(f\) is differentiable at \(x\), then \(f\) is continuous at \(x\), since \(\epsilon(h)\to 0\) as \(h\to 0\) giving \(f(x+h)\to f(x)\) as \(h\to 0\).
    \end{enumerate}
\end{remark}
Let's look at some examples.
\begin{enumerate}
    \item \(f:\mathbb{R}\to\mathbb{R}\), \(x\mapsto x\) is differentiable at each \(x\) and \(f^\prime(x)=1\), i.e.
    \[f(x+h)=x+h=f(x)+h\cdot 1+0\]
    where \(1=f^\prime(x)\) and \(0=\epsilon(h)\).
    \item \(f:\mathbb{R}\to\mathbb{R}\), \(x\to|x|\) is differentiable for \(x\neq 0\). At \(x=0\) consider
    \[\frac{f(h)-f(0)}{h}=\frac{|h|}{h}\]
    We have
    \[\lim_{h_n\to 0+}\frac{f(h)-f(0)}{h}=1\]
    but
    \[\lim_{h_n\to 0-}\frac{f(h)-f(0)}{h}=-1\]
    hence the limit does not exist and \(f\) is not differentiable at \(x=0\).
\end{enumerate}
\subsection{Differentiation of Sums and Products}
\begin{proposition} \item[]
    \begin{enumerate}
        \item If \(f(x)=c\) \(\forall x\in\mathrm{E}\) then \(f\) is differentiable on \(\mathrm{E}\) with \(f^\prime(x)=0\).
        \item If \(f,g\) are differentiable at \(x\), so is \(f+g\) and 
        \[(f+g)^\prime(x)=f^\prime(x)+g^\prime(x)\]
        \item If \(f,g\) are differentiable at \(x\), so is \(fg\) and
        \[(fg)^\prime(x)=f(x)g^\prime(x)+f^\prime(x)g(x)\]
        \item If \(f\) is differentiable at \(x\) and \(f(y)\neq 0\) \(\forall y\in E\) then \(1/f\) is differentiable at \(x\) and 
        \[\left(\frac 1f\right)^\prime=-\frac{f^\prime(x)}{f(x)^2}\]
    \end{enumerate}
    \label{prop:diff_sp}
\end{proposition}
\begin{proof}
    \item[]
    \begin{enumerate}
        \item Can easily see
        \[\lim_{h\to 0}\frac{c-c}{h}=0\]
        \hfill\qedsymbol
        \item By Lemma \ref{lemma:fund_limit}, and from 
        \[\frac{f(x+h)+g(x+h)-f(x)-g(x)}{h}=\frac{f(x+h)-f(x)}{h}+\frac{g(x+h)-g(x)}{h}\]
        we have 
        \[\lim_{h\to 0}\frac{(f+g)(x+h)-(f+g)(x)}{h}=f^\prime(x)+g^\prime(x)\]
        \hfill\qedsymbol
        \item Let \(\phi(x)=f(x)g(x)\). Then for \(h\neq 0\)
        \begin{align*}
            \frac{\phi(x+h)-\phi(x)}{h}&=\frac{f(x+h)g(x+h)-f(x)g(x)}{h} \\
            &=\frac{f(x+h)g(x+h)-f(x+h)g(x)+f(x+h)g(x)-f(x)g(x)}{h} \\
            &=f(x+h)\left(\frac{g(x+h)-g(x)}{h}\right)+g(x)\left(\frac{f(x+h)-f(x)}{h}\right)
        \end{align*}
        implying 
        \[\frac{\phi(x+h)-\phi(x)}{h}\to f(x)g^\prime(x)+f^\prime(x)g(x)\]
        \hfill\qedsymbol
        \item Let \(\phi(x)=1/f(x)\). Then,
        \[\frac{\phi(x+h)-\phi(x)}{h}=\frac{\frac{1}{f(x+h)}-\frac{1}{f(x)}}{h}=\frac{f(x)-f(x+h)}{h}\frac{1}{f(x)f(x+h)}\]
        Again, by Lemma \ref{lemma:fund_limit}, 
        \[\frac{\phi(x+h)-\phi(x)}{h}\to-\frac{f^\prime(x)}{f(x)^2}\]
    \end{enumerate}
\end{proof}
Note that (3) and (4) give the quotient rule:
\[\left(\frac fg\right)^\prime(x)=\frac{f^\prime(x)g(x)-g^\prime(x)f(x)}{g(x)^2}\]
For example, consider \(f_n(x)=x^n\) where \(n\in\mathbb{N}\). Shown that \(f_1(x)\) is differentiable and \(f^\prime_1(x)=1\), we claim \(f_n(x)\) is differentiable with \(f_n^\prime(x)=nx^{n-1}\) for all \(n\). If the claim is true for \(f_{n-1}\), observe that
\[f_n(x)=x^{n-1}x=f_{n-1}(x)f_1(x)\]
By Proposition \ref{prop:diff_sp} (3), \(f_n\) is differentiable, and 
\begin{align*}
    f_n^\prime(x)&=f_1(x)f_{n-1}^\prime(x)+f_1^\prime(x)f_{n-1}(x) \\
    &=x(n-1)x^{n-2}+x^{n-1}=nx^{n-2}
\end{align*}
Hence, by induction,  \(f_n^\prime(x)=nx^{n-1}\) for all \(n\in\mathbb{N}\). 

Now consider \(f_{-n}(x)=x^{-n}\) where \(n\in\mathbb{N}\). If \(x\neq 0\) \(f_{-n}(x)=1/f_{n}(x)\). So by Proposition \ref{prop:diff_sp} (4), \(f_{-n}(x)\) is differentiable and 
\[f_{-n}^\prime(x)=-\frac{f_n^\prime(x)}{f_n(x)^2}=-\frac{nx^{n-1}}{x^{2n}}=-nx^{-n-1}\]
Therefore \(f_n^\prime(x)=nx^{n-1}\) holds for all \(n\in\mathbb{Z}\) (with condition \(x\neq 0\) if \(n<0\)).

Combining results above with Proposition \ref{prop:diff_sp}, we see all polynomial functions are differentiable everywhere, and rational functions \(f(x)=p(x)/q(x)\) (\(p\), \(q\) coprime polynomials) are differentiable everywhere except the roots of \(q\).
\begin{theorem}
    (\emph{Chain Rule}) Suppose \(U,V\subset\mathbb{C}\) and \(f:U\to V\), \(g:V\to\mathbb{C}\) are such that \(f\) is differentiable at \(a\in{U}\) and \(g\) is differentiable at \(f(a)\in  V\). Then,
    \(g\circ f:U\to \mathbb{C}\) 
    is differentiable at \(a\) and 
    \[(g\circ f)^\prime(a)=g^\prime(f(a))f^\prime(a)\]
    \label{thm:diff_chain}
\end{theorem}
\begin{proof}
    Let \(f(a)=b\). We can restate the differentiability of \(f\) at \(a\), \(g\) at \(b\) as:
    \[f(x)=f(a)+(x-a)f^\prime(a)+\epsilon_f(x)(x-a)\]
    \[g(y)=g(b)+(y-b)g^\prime(b)+\epsilon_g(y)(y-b)\]
    with \(\lim_{x\to a}\epsilon_f(x)=\lim_{y\to b}\epsilon_g(y)=0\). Notice we can set \(\epsilon_f(a)=0\), \(\epsilon_g(b)=0\) to make \(\epsilon_f\), \(\epsilon_g\) continuous at \(a\), \(b\) respectively. Now set \(y=f(x)\) and write 
    \begin{align*}
        g(f(x))&=g(f(a))+(f(x)-f(a))g^\prime(f(a))+\epsilon_g(f(x))(f(x)-f(a)) \\
        &=g(f(a))+\left((x-a)f^\prime(a)+\epsilon_f(x-a)\right)g^\prime(f(a)) \\
        &+\epsilon_g(f(x))\left((x-a)f^\prime(a)+\epsilon_f(x)(x-a)\right)
    \end{align*}
    Thus 
    \begin{align*}
        g(f(x))&=g(f(a))+(x-a)f^\prime(a)g^\prime(f(a)) +(x-a)\left[g^\prime(f(a))\epsilon_f(x)+f^\prime(a)\epsilon_g(f(x))+\epsilon_g(f(x))\epsilon_f(x)\right] \\
        &=g(f(a))+(x-a)f^\prime(a)g^\prime(f(a)) +(x-a)\sigma(x)
    \end{align*}
    where 
    \[\sigma(x)=g^\prime(f(a))\epsilon_f(x)+f^\prime(a)\epsilon_g(f(x))+\epsilon_g(f(x))\epsilon_f(x)\]
    Note that \(\epsilon_f(x)\to 0\) as \(x\to a\), and \(\epsilon_g(f(x))\) is composition of continuous functions, so \(\epsilon_g(f(x))\to 0\) as \(x\to a\). Hence \(\sigma(x)\to 0\) as \(x\to a\) and therefore \((g\circ f)^\prime(a)=g^\prime(f(a))f^\prime(a)\) from definition of differentiation.
\end{proof}
\begin{remark}
    Chain rule is often written as
    \[\frac{dy}{dx}=\frac{dy}{dt}\frac{dt}{dx}\]
    where \(y(t(x))\).
\end{remark}
\subsection{The Mean Value Theorem}
\begin{theorem}
    (\emph{Rolle's Theorem})
    Let \(f:[a,b]\to\mathbb{R}\) be continuous on \([a,b]\) and differentiable on \((a,b)\). If \(f(a)=f(b)\) then \(\exists c\in(a,b)\) such that \(f^\prime(c)=0\).
    \label{thm:rolle}
\end{theorem}
\begin{proof}
    By Theorem \ref{thm:evt} (EVT), \(\exists y,Y\in[a,b]\) such that 
    \[m=f(y)\leq f(x)\leq f(Y)=M\]
    \(\forall x\in[a,b]\). If \(m=M=f(a)\) then \(f(x)=M\) and \(f\) constant, so we can take any \(c\in(a,b)\).

    Otherwise, either \(M>f(a)\) or \(m<f(a)\). If \(M>f(a)\), then \(Y\in(a,b)\). We claim \(f^\prime(Y)=0\). To see this, suppose \(h_n\to 0+\). Then
    \[\frac{f(Y+h_n)-f(Y)}{h_n}\leq 0\Rightarrow\lim_{h\to 0}\frac{f(Y+h)-f(Y)}{h}\leq 0\]
    If \(h_n\to 0-\),
    \[\frac{f(Y+h_n)-f(Y)}{h_n}\geq 0\Rightarrow\lim_{h\to 0}\frac{f(Y+h)-f(Y)}{h}\geq 0\]
    Hence by uniqueness of limit, \(f^\prime(Y)=0\). If \(m<f(a)\) a similiar argument shows \(y\in(a,b)\) and \(f^\prime(y)=0\). Regardless \(\exists c\in(a,b)\) such that \(f^\prime(c)=0\).
\end{proof}
\begin{theorem}
    (\emph{Mean Value Theorem}) Let \(f:[a,b]\to\mathbb{R}\) be a continuous function, differentiable on \((a,b)\). Then there exists \(c\in(a,b)\) such that
    \[f(b)-f(a)=f^\prime(c)(b-a)\Leftrightarrow f^\prime(c)=\frac{f(b)-f(a)}{b-a}\]
    \label{thm:mvt}
\end{theorem}
\begin{proof}
    Consider 
    \[\phi(x)=(x-a)(f(b)-f(a))-(b-a)(f(x)-f(a))\]
    Clearly, \(\phi\) satisfies conditions of Rolle's theorem, so \(\exists c\in(a,b)\) such that 
    \[\phi^\prime(c)=0\Rightarrow 0=(f(b)-f(a))-(b-a)f^\prime(c)\]
\end{proof}
If \(f\) is differentiable on an open interval \(I\) containing \(a\), another way to state mean value theorem (MVT) is: given \(h\) such that \(a+h\in I\), \(\exists \Theta=\Theta(h)\in(0,1)\) such that 
\[f(a+h)=f(a)+hf^\prime(a+\Theta h)\]

The mean value theorem allows us to export local information about the derivative to global properties of the function.
\begin{corollary}
    Let \(f:[a,b]\to\mathbb{R}\) continuous, and differentiable on \((a,b)\). Then, 
    \begin{enumerate}
        \item if \(f^\prime(x)>0\) \(\forall x\in(a,b)\), \(f\) is strictly increasing.
        \item if \(f^\prime(x)\geq 0\) \(\forall x\in(a,b)\), \(f\) is increasing.
        \item if \(f^\prime(x)=0\) \(\forall x\in(a,b)\), \(f\) is constant on \([a,b]\)
    \end{enumerate}
    \label{coro:inc}
\end{corollary}
\begin{proof} \item[]
    \begin{enumerate}
        \item Let \(a\leq x<y\leq b\). Hypotheses of mean value theorem apply to \(f:[x,y]\to\mathbb{R}\) so \(\exists c\in(x,y)\) such that 
        \[f(y)-f(x)=f^\prime(c)(y-x)>0\]
        \item Same as above, but use \(f^\prime(c)\geq 0\).
        \item Pick \(x\in(a,b]\). Then, by applying mean value theorem on \([a,x]\), we deduce that there exists \(c\in(a,x)\) such that 
        \[f(x)-f(a)=f^\prime(c)(x-a)=0\]
        and \(f\) is constant.
    \end{enumerate}
\end{proof}
Meanwhile, note that the mean value theorem is not necessarily true on general sets: e.g. \(f:\mathbb{Q}\to\mathbb{Q}\),
\[x\mapsto\begin{cases}
    0 & x^2<2 \\
    1 & x^2>2
\end{cases}\]
Now we revisit the inverse function theorem.
\begin{theorem}
    Suppose \(f:[a,b]\to\mathbb{R}\) is continuous and differentiable on \((a,b)\), with \(f^\prime(x)>0\) \(\forall x\in(a,b)\). Let \(f(a)=c\), \(f(b)=d\). Then,
    \[f:[a,b]\to[c,d]\]
    is bijective and \(f^{-1}\) is differentiable on \((c,d)\) with
    \[(f^{-1})^\prime(y)=\frac{1}{f^\prime(f^{-1}(y))}\]
    \label{thm:ift_diff}
\end{theorem}
\begin{proof}
    By Corollary \ref{coro:inc} \(f\) is strictly increasing on \([a,b]\). By Theorem \ref{thm:ift_1}, 
    \[f:[a,b]\to[c,d]\]
    is bijective and 
    \[f^{-1}:[c,d]\to[a,b]\]
    is continuous and strictly increasing. However, it remains to show \(f^{-1}\) is differentiable on \((c,d)\).

    Let \(y\in(c,d)\) and set \(x=f^{-1}(y)\). Given \(h\) such that \(y+h\in(c,d)\), let \(k\) be such that \(y+h=f(x+k)\). Then,
    \[\frac{f^{-1}(y+h)-f^{-1}(y)}{h}=\frac{x+k-x}{f(x+k)-y}=\frac{k}{f(x+k)-f(x)}\]
    Fix \(\epsilon>0\); then by differentiability of \(f\) and facts about limits, \(\exists\delta>0\) such that for all \(0<|k|<\delta\) we have 
    \[\left|\frac{k}{f(x+k)-f(x)}-\frac{1}{f^\prime(x)}\right|<\epsilon\] 
    Since \(f^{-1}\) is continuous, there exists \(\delta^\prime\) such that 
    \begin{align*}
        0<|h|<\delta^\prime&\Rightarrow 0<|f^{-1}(y+h)-x|<\delta \\
        &\Rightarrow 0<k<\delta \\
        &\Rightarrow \left|\frac{f^{-1}(y+h)-f^{-1}(y)}h-\frac{1}{f^\prime(x)}\right|<\epsilon
    \end{align*}
    Therefore \(f^{-1}\) is differentiable at \(y\) and 
    \[(f^{-1})^\prime(y)=\frac{1}{f^\prime(f^{-1}(y))}\]
\end{proof}
With fixed \(R>0\), consider \(f:[0,R]\to\mathbb{R}\), \(x\mapsto x^n\) for \(n\in\mathbb{N}\). \(f\) is continuous on \([0,R]\), differentiable on \((0,R)\) with \(f^\prime(x)=nx^{n-1}>0\) (\(x\in(0,R)\)). Hence by Theorem \ref{thm:ift_diff}, \(f\) maps \([0,R]\) bijectively onto \([0,R^n]\) and the inverse \(g(y)=f^{-1}(y)=y^{1/n}\) is differentiable with 
\[g^\prime(y)=\frac{1}{f^\prime(f^{-1}(y))}=\frac{1}{n(y^{1/n})^{n-1}}=\frac 1ny^{\frac 1n-1}\]
More generally, let \(h(x)=x^r\) where \(r\in\mathbb{Q}\). Writing \(r=m/n\) for \(m\in\mathbb{Z}\), \(n\in\mathbb{N}\) and defining 
\[x^r=\left(x^{1/n}\right)^m\]
\(h\) is differentiable on \((0,\infty)\) and 
\[h^\prime(x)=m\left(x^{1/n}\right)^{m-1}\left(\frac 1nx^{\frac 1n-1}\right)=\frac mnx^{\frac mn-1}=rx^{r-1}\]
by chain rule.
\begin{theorem}
    (\emph{Cauchy's Mean Value Theorem}) Let \(f,g:[a,b]\to\mathbb{R}\) be continuous on \([a,b]\) and differentiable on \((a,b)\). Then there exists \(c\in(a,b)\) such that 
    \[g^\prime(f(a)-f(b))=f^\prime(c)(g(a)-g(b))\]
    which can be also written as 
    \[\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f^\prime(c)}{g^\prime(c)}\]
    if both sides are well-defined.
    \label{thm:mvt_cauchy}
\end{theorem}
\begin{proof}
    Let 
    \[\phi(x)=(g(x)-g(a))(f(b)-f(a))-(g(b)-g(a))(f(x)-f(a))\]
    \(\phi\) is continuous on \([a,b]\), differentiable on \((a,b)\) and \(\phi(a)=\phi(b)=0\). Hence by Rolle's theorem, there exists \(c\in(a,b)\) such that
    \[\phi^\prime(c)=0\Rightarrow g^\prime(c)(f(a)-f(b))-f^\prime(c)(g(a)-g(b))=0\]
\end{proof}
A famous application of Cauchy's mean value theorem is the \emph{L'Hôpital's rule}. Consider
\[\frac{e^x-1}{\sin x}\]
as \(x\to 0\).\footnote{We will formally define \(e\) and \(\sin\) later.} With noting that 
\[\frac{e^x-1}{\sin x}=\frac{e^x-e^0}{\sin x-\sin 0}\]
apply Cauchy's mean value theorem with \(f(x)=e^x\), \(g(x)=\sin x\) on interval \([x,0]\) or \([0,x]\) to deduce that \(\exists\theta_x\in(0,1)\) such that 
\[\frac{e^x-1}{\sin x}=\frac{e^{\theta_xx}}{\cos(\theta_xx)}\]
Now \(0<|\theta_xx|<|x|\) so as \(x\to 0\) \(\theta_xx\to 0\). Further, because \(e^y/\cos y\) is continuous, we have 
\[\frac{e^{\theta_xx}}{\cos(\theta_xx)}\to 1\]
as \(x\to 0\). Thus
\[\lim_{x\to 0}\frac{e^x-1}{\sin x}=1\]
\subsection{Higher Derivatives and Taylor's Theorem}
Suppose \(f:(a,b)\to\mathbb{R}\) is differentiable on \((a,b)\). Then we can consider the function 
\[f^\prime:(a,b)\to\mathbb{R},\quad x\mapsto f^\prime(x)\]
If this is differentiable at \(x\in(a,b)\) we say \(f\) is twice differentiable at \(x\) and write 
\[(f^\prime)^\prime(x)=f^\pprime(x)=f^{(2)}(x)\]
We can iterate to define \(k\)-times differentiability and write 
\[f^{(k)}(x)=\left(f^{(k-1)}\right)^\prime(x)\]
Furthermore, function is said to be \emph{smooth} if it is \(k\)-times differentiable on \((a,b)\) for every \(k\). We would like to extend mean value theorem for a function which is more differentiable to incorporate higher derivatives.
\begin{theorem}
    (\emph{Taylor's Theorem with Lagrange Remainder})
    Suppose \(f\) and its derivatives to order \(n-1\) are continuous on \([a,a+h]\) and \(f\) is \(n\) times differentiable on \((a,a+h)\). Then there exists \(\theta\in(0,1)\) such that 
    \[f(a+h)=f(a)+hf^\prime(a)+\frac{h^2}{2!}f^\pprime(a)+\cdots+\frac{h^{n-1}}{(n-1)!}f^{(n-1)}(a)+\frac{h^n}{n!}f^{(n)}(a+\theta h)\]
    \label{thm:taylor_lagrange}
\end{theorem}
N.b. for \(n=1\) Theorem \ref{thm:taylor_lagrange} is mean value theorem, so Theorem \ref{thm:taylor_lagrange} is a \(n\)\textsuperscript{th} order mean value theorem. We say 
\[R_n=\frac{h^n}{n!}f^{(n)}(a+\theta h)\]
is \emph{Lagrange's form of the remainder}. 

Also, considering \(g(x)=-f(x)\) and applying Theorem \ref{thm:taylor_lagrange} at \(x=-a\), we can show the result also holds if \(h<0\), provided conditions hold on \([a+h,a],(a+h,a)\) etc. -- which is able to be assured by stating \(f\) is \(n\) times differentiable on some interval \((c,d)\) with \([a,a+h]\subset(c,d)\) (or \([a+h,a]\)).
\begin{proof}
    (\emph{Method 1}) Observe we can choose \(a=0\) without loss of generality; if we prove the result for \(a=0\), applying it to \(g(x)=f(a+x)\) gives general case.

    For \(0\leq t\leq h\) let 
    \[\phi(t)=f(t)-f(0)-tf^\prime(0)-\cdots-\frac{t^{n-1}}{(n-1)!}f^{(n-1)}(0)-\frac{t^n}{n!}B\]
    where we choose \(B\) such that \(\phi(h)=0\), i.e. 
    \[\frac{h^n}{n!}B=f(h)-f(0)-tf^\prime(0)-\cdots-\frac{t^{n-1}}{(n-1)!}f^{(n-1)}(0)\tag{\(\asterisk\)}\]
    Now repeatedly apply Rolle's theorem (Theorem \ref{thm:rolle}) to find another expression for B. First observe \(\phi\) and its first \(n-1\) derivatives are continuous on \([0,h]\), and \(\phi^{(n)}\) exists on \((0,h)\). Also note that \(\phi^{(k)}(0)=0\) for \(0\leq k\leq n-1\). Then
    \[\phi(0)=\phi(h)=0\Rightarrow\exists\theta_1\in(0,1)\text{  such that  }\phi^\prime(\theta_1h)=0\]
    \[\phi^\prime(0)=\phi^\prime(\theta_1h)=0\Rightarrow\exists\theta_2\in(0,1)\text{  such that  }\phi^\pprime(\theta_2\theta_1h)=0\]
    \[\vdots\]
    \[\phi^{(n-1)}(0)=\phi^{(n-1)}(\theta_{n-1}\cdots\theta_1h)=0\Rightarrow\exists\theta_n\in(0,1)\text{  such that  }\phi^{(n)}(\theta_n\theta_{n-1}\cdots\theta_1h)=0\]
    Let \(\theta=\theta_1\theta_2\cdots\theta_n\in(0,1)\). Then
    \[\phi^{(n)}(\theta h)=0\Rightarrow f^{(n)}(\theta h)-B=0\]
    i.e. \(B=f^{(n)}(\theta h)\) for some \(\theta\in(0,1)\). Rearranging equation (\(\asterisk\)) gives us the desired result.
\end{proof}
\begin{proof}
    (\emph{Method 2}) Again, assume \(a=0\) without loss of generality. This time, for \(0\leq t\leq h\), let 
    \[F(t)=f(h)-f(t)-(h-t)f^\prime(t)-\frac{(h-t)^2}{2!}f^\pprime(t)-\cdots-\frac{(h-t)^{n-1}}{(n-1)!}f^{(n-1)}(t)\]
    F is continuous on \([0,h]\) and differentiable on \((0,h)\), and 
    \begin{align*}
        F^\prime(t)&=-f^\prime(t)+f^\prime(t)-(h-t)f^\pprime(t)+(h-t)f^\pprime(t)-\frac{(h-t)^2}{2!}f^{(3)}(t)+\cdots-\frac{(h-t)^{n-1}}{(n-1)!}f^{(n)}(t) \\
        &=-\frac{(h-t)^{n-1}}{(n-1)!}f^{(n)}(t)
    \end{align*}
    Now set 
    \[\phi(t)=F(t)-\left(\frac{h-t}{h}\right)^pF(0)\]
    with \(1\leq p\leq n,\:p\in\mathbb{N}\). Then \(\phi(0)=0=\phi(h)\). So by Rolle's theorem there exists \(\theta\in(0,1)\) such that \(\phi^\prime(\theta h)=0\). But 
    \[\phi^\prime(\theta h)=F^\prime(\theta h)+\frac{p(1-\theta)^{p-1}}{h}F(0)\]
    Hence
    \begin{align*}
        0&=-\frac{h^{n-1}(1-\theta)^{n-1}}{(n-1)!}f^{(n)}(\theta h) \\&+\frac{p(1-\theta)^{p-1}}{h}\left(f(h)-f(0)-hf^\prime(0)-\frac{h^2}{2!}f^\pprime(0)-\cdots-\frac{h^{n-1}}{(n-1)!}f^{(n-1)}(0)\right)        
    \end{align*}
    If \(p=n\), we can rearrange to find Taylor's theorem with Lagrange remainder. Otherwise, if \(p=1\), we have proved the \emph{Taylor's theorem with Cauchy remainder}.
\end{proof}
\begin{theorem}
    (\emph{Taylor's Theorem with Cauchy Remainder}) With the same hypotheses as Theorem \ref{thm:taylor_lagrange}, we have 
    \[f(a+h)=f(a)+hf^\prime(a)+\cdots+\frac{h^{n-1}}{(n-1)!}f^{(n-1)}f^{(n-1)}(a)+\tilde{R}_n\]
    where 
    \[\tilde{R}_n=\frac{(1-\theta)^{n-1}h^n}{(n-1)!}f^{(n)}(a+\theta h)\]
    for some \(\theta\in(0,1)\).
    \label{thm:taylor_cauchy}
\end{theorem}

Both versions of Taylor's theorem assert that 
\[f(h)=P_{n-1}(h)+R_n(h)\]
where 
\[P_{n-1}(h)=\sum_{i=0}^{n-1}\frac{h^i}{i!}f^{(i)}(0)\]
the \emph{Taylor polynomial}, and
\[R_n(h)=\begin{cases}
    \frac{h^n}{n!}f^{(n)}(a+\theta h) & (\text{Lagrange}) \\
    \frac{(1-\tilde{\theta})^{n-1}h^n}{(n-1)!}f^{(n)}(a+\tilde{\theta}h) & (\text{Cauchy})
\end{cases}\] 
for some \(\theta,\tilde{\theta}\in(0,1)\). Finally, be aware that Taylor's theorem does not say 
\[f(h)=\sum_{i=0}^\infty\frac{h^i}{i!}f^{(i)}(0)\]
where the right hand side is called the \emph{Taylor series}.
In fact this is not always true, even if \(f\) is smooth and even if the series converges. To show a function is equal to its Taylor series, we need to show \(R_n(h)\to 0\) as \(n\to\infty\) for fixed \(h\). For example, consider the binomial series \(f(x)=(1+x)^r\) where \(r\in\mathbb{Q}\). Claim that if \(|x|<1\), then 
\[(1+x)^r=1+\binom{r}{1}x+\cdots+\binom rnx^n+\cdots\]
where we define 
\[\binom rn=\frac{r(r-1)\cdots(r-n+1)}{n!}\]
where the series converges absolutely.
\begin{proof}
    Clearly,
    \[f^{(n)}(x)=r(r-1)\cdots(r-n+1)(1+x)^{r-n}\]
    By Theorem \ref{thm:taylor_lagrange}, for \(|x|<1\) and \(n\geq r\),
    \[(1+x)^r=1+\binom{r}{1}x+\cdots+\binom r{n-1}x^{n-1}+\binom rn\frac{x^n}{(1+\theta x)^{n-r}}\]
    for some \(\theta\in(0,1)\), which can depend on both \(n\) and \(x\). But if \(x\geq 0\), \((1+\theta x)^{n-r}\geq 1\) so 
    \[0\leq\frac{1}{(1+\theta x)^{n-r}}\leq 1\Rightarrow|R_n(x)|=\left|\binom rn\frac{x^n}{(1+\theta x)^{n-r}}\right|\leq\left|\binom rnx^n\right|\]
    Now observe that \(\sum_{n\geq 0}{\binom rnx^n}\) converges absolutely for \(|x|<1\):
    \[\left|\frac{a_{n+1}}{a_n}\right|=\left|\frac{r-n}{n+1}\right||x|\to|x|<1\quad\text{as  }n\to\infty\]
    So by ratio test and Theorem \ref{thm:abconv}, \(\sum_{n\geq 0}{\binom rnx^n}\) converges. This implies 
    \[\binom rnx^n\to 0\quad\text{as  }n\to\infty\]
    Thus, \(R_n(x)\to 0\) as \(n\to\infty\) for \(x\in[0,1)\).

    However, if \(-1<x<0\), the above approach does not work as \((1+\theta x)^{n-1}<1\). Instead, we can use Cauchy's remainder 
    \[R_n=\frac{(1-\theta)^{n-1}x^n}{(n-1)!}r(r-1)\cdots(r-n+1)(1+\theta x)^{r-n}=r\binom{r-1}{n-1}\left(\frac{1-\theta}{1+\theta x}\right)^{n-1}(1+\theta x)^{r-1}x^n\]
    for some \(\theta\in(0,1)\). But \((1-\theta)/(1+\theta x)<1\) for all \(x\in(-1,1)\) as \(1+\theta x=1-\theta +\theta(x+1)\geq 1-\theta\). Hence 
    \[|R_n|\leq r|x|\left|\binom{r-1}{n-1}x^{n-1}\right|(1+\theta x)^{r-1}\]
    Moreover, \((1+\theta x)^{r-1}\leq\max\{(1-|x|)^{r-1},(1+|x|)^{r-1}\}\), and 
    \[|R_n|\leq r|x|\max\{(1-|x|)^{r-1},(1+|x|)^{r-1}\}\left|\binom{r-1}{n-1}x^{n-1}\right|=K_{r,x}\left|\binom{r-1}{n-1}x^{n-1}\right|\to 0\] as \(n\to\infty\) since \(K_{r,x}\) is independent of \(n\). Therefore \(R_n\to 0\) as \(n\to\infty\) for \(x\) fixed in \(-1,1\).
\end{proof}
% \subsection{Complex Differentiability}
% We defined differentiability for functions 
\section{Power Series}
We want to consider functions defined by power series of the form 
\[f(z)=\sum_{n=0}^{\infty}a_n(z-z_0)^n\]
where \(a_n,z,z_0\in\mathbb{C}\). Obviously the series may not converge for every \(z\in\mathbb{C}\). First thing to do is to find out the set of points for which it does converge.\footnote{Note that set is always non-empty as it contains \(z_0\).} By translation, we can assume \(z_0=0\). 
\begin{lemma}
    If \(\sum_{n=0}^\infty a_nz^n\) converges, and \(|w|<|z|\), then \(\sum_{n=0}^\infty a_nw^n\) converges absolutely.
    \label{lemma:small_conv}
\end{lemma}
\begin{proof}
    Since \(\sum_{n=0}^\infty a_nz^n\) converges, \(a_nz^n\to 0\). Thus \(\exists K>0\) such that\footnote{Recall that convergent series is bounded.} 
    \[|a_nz^n|\leq K\quad\forall n\]
    Now consider (note that \(z>0\) to define \(w\))
    \[|a_nw^n|=|a_nz^n|\left|\frac wz\right|^n\leq K\rho^n\]
    where \(\rho=|w/z|<1\) by assumption. Thus \(\sum_{n=0}^\infty |a_nw^n|\) converges by comparison to the geometric series \(\sum_{n=0}^\infty K\rho^n\), which converges.
\end{proof}
We now use Lemma \ref{lemma:small_conv} to show every power series has a well-defined \emph{radius of convergence}.
\begin{theorem}
    Let \(\sum_{n=0}^\infty a_nz^n\) be a power series. Then there exists \(R\in[0,\infty]\), the radius of convergence, such that the series converges absolutely for \(|z|<R\) and diverges for \(|z|>R\).
\end{theorem}
\begin{proof}
    Let
    \[A=\left\{r\geq 0\:\left|\:\exists z\in\mathbb{C}\text{  with  }|z|=r\text{  such that }\sum_{n=0}^\infty a_nz^n\text{  converges}\right.\right\}\]
    Clearly, \(0\in A\), and \(A\) is non-empty. So let 
\[R=\sup A\]
with noting that \(\sup A=\infty\) meaning \(A\) is unbounded above. From definition of \(A\), \(\sum a_nz^n\) diverges for \(|z|>R\). Suppose \(|w|<R\). Then there exists \(r\in\mathbb{A}\) with \(|w|<r\) so \(\exists z\in\mathbb{C}\) with \(|z|=r\) and \(\sum a_nz^n\) converging. \(|w|<|z|\) so by Lemma \ref{lemma:small_conv} \(\sum a_nw^n\) converges absolutely.
\end{proof}
Note that \(R=0\) means \(\sum a_nz^n\) converges only for \(z=0\), and \(R=\infty\) means \(\sum a_nz^n\) converges absolutely for all \(z\in\mathbb{C}\). When \(0<R<\infty\) theorem tells us nothing about convergence for \(|z|=R\). Now we introduce a lemma that is useful at finding \(R\):
\begin{lemma}
    If \(|a_{n+1}/a_n|\to l\) as \(n\to\infty\), then \(R=1/l\). 
\end{lemma}
\begin{proof}
    We use ratio test. Consider 
    \[\lim_{n\to\infty}\left|\frac{a_{n+1}z^{n+1}}{a_nz^n}\right|=\lim_{n\to\infty}\left|\frac{a_{n+1}}{a_n}\right||z|=l|z|\]
    so if \(l|z|<1\) we get absolute convergence, and if \(l|z|>1\) we get divergence.
\end{proof}
Let's take a look at some examples.
\begin{itemize}
    \item \(\sum_{n=0}^\infty z^n/n!\) converges absolutely for all \(z\in\mathbb{C}\), since 
    \[\left|\frac{a_{n+1}}{a_n}\right|=\frac{n!}{(n+1)!}=\frac{1}{n+1}\to 0=l\]
    and \(R=\infty\).
    \item \(\sum_{n=0}^\infty n!z^n\) converges only for \(z=0\), since \(|a_{n+1}/a_n|=n+1\to\infty\) for \(R=0\).
    \item \(\sum_{n=0}^\infty z^n\) geometric series converges if and only if \(|z|<1\).
    \item \(\sum_{n=0}^\infty z^n/n^2\) has radius of convergence \(R=1\); specifically, absolute convergence for \(|z|\leq 1\) and divergence for \(|z|>1\).
    \item \(\sum_{n=0}^\infty z^n/n\) has radius of convergence \(R=1\). For \(z=1\), it diverges (harmonic series). For \(|z|=1\), \(z\neq 1\), consider 
    \begin{align*}
        (1-z)\sum_{n=1}^{N}\frac{z^n}{n}&=\sum_{n=1}^{N}\left(\frac{z^n}{n}-\frac{z^{n+1}}{n}\right) \\
        &=\sum_{n=1}^{N}\left(\frac{z^{n+1}}{n+1}-\frac{z^{n+1}}{n}\right)+z-\frac{z^{N+1}}{N+1} \\
        &=z-z\sum_{n=1}^{N}\frac{1}{n(n+1)}z^n-\frac{z^{N+1}}{N+1}
    \end{align*}
    If \(|z|\leq 1\), 
    \[\sum_{n=1}^{N}\frac{1}{n(n+1)}z^n\] converges absolutely by comparison to \(\sum 1/n(n+1)\), and 
    \[\left|\frac{z^{N+1}}{N+1}\right|\leq\frac{1}{N+1}\to 0\]
    Therefore \(\sum_{n=0}^\infty z^n/n\) converges for \(|z|\leq 1\), \(z\neq 1\).
\end{itemize}
We conclude that nothing can be said in general about convergence on \(|z|=R\), and need to analyse case by case. We shall see that inside the radius of convergence, power series are very well behaved, and ``can treated like polynomials.''
\begin{theorem}
    Suppose 
    \[f(z)=\sum_{n=0}^{\infty}a_nz^n\]
    has radius of convergence \(R>0\). Then \(f\) is differentiable at all points \(z\) with \(|z|<R\), and 
    \[f^\prime(z)=\sum_{n=1}^{\infty}na_nz^{n-1}\]
    \label{thm:taylor_diff}
\end{theorem}
\begin{proof} We start by stating two auxillary lemmas:
    \begin{lemma}
        If \(\sum_{n=0}^{\infty}a_nz^n\) has radius of convergence \(R\), then so do \(\sum_{n=1}^{\infty}na_nz^{n-1}\) \newline and  \(\sum_{n=2}^{\infty}n(n-1)a_nz^{n-2}\)
        \label{lemma:aux:rc_1}
    \end{lemma}
    \begin{lemma}\item[]
        \begin{enumerate} 
            \item Let \(n,r\in\mathbb{N}\). For all \( 2\leq r\leq n \),
            \[\binom nr\leq n(n-1)\binom{n-2}{r-2}\]
            \item Let \(n\in\mathbb{N}\). For all \(z,h\in\mathbb{C}\),
            \[|(z+h)^n-z^n-nhz^{n-1}|\leq n(n-1)(|z|+|h|)^{n-2}|h|^2\]
        \end{enumerate}
        \label{lemma:aux:rc_2}
    \end{lemma}
    Assume, for now, that these results hold. By Lemma \ref{lemma:aux:rc_1}, we may define 
    \[g(z)=\sum_{n=1}^{\infty}na_nz^{n-1}\]
    where \(|z|<R\). We need to show 
    \[I=\frac{f(z+h)-f(z)-hg(z)}{h}\to 0\]
    as \(h\to 0\). Fix \(z\) with \(|z|<R\), and assume \(|z|+|h|<r<R\) for some \(r\). All sums in \(I\) converge by Lemma \ref{lemma:aux:rc_1}, and 
    \[I=\frac 1h\sum_{n=0}^\infty a_n[(z+h)^n-z^n-hnz^{n-1}]\]
    Then by continuity of absolute value function,
    \begin{align*}
        |I|&=\frac 1{|h|}\left|\lim_{N\to\infty}\sum_{n=0}^{N} a_n[(z+h)^n-z^n-hnz^{n-1}]\right| \\
        &=\lim_{N\to\infty}\underbrace{\frac 1{|h|}\left|\sum_{n=0}^{N} a_n[(z+h)^n-z^n-hnz^{n-1}]\right|}_{I_N}
    \end{align*}
    Now, using the triangle inequality and Lemma \ref{lemma:aux:rc_2} (2), 
    \begin{align*}
        |I_N|&\leq\frac 1{|h|}\sum_{n=0}^{N}|a_n||(z+h)^n-z^n-hnz^{n-1}| \\
        &\leq\frac 1{|h|}\sum_{n=0}^{N}|a_n||n(n-1)(|z|+|h|)^{n-2}|h|^2| \\
        &\leq |h|\sum_{n=0}^{N}n(n-1)|a_n|r^{n-2} \\
        &\leq |h|\sum_{n=0}^\infty n(n-1)|a_n|r^{n-2} =|h|A_r
    \end{align*}
    where \(A_r\) converges by Lemma \ref{lemma:aux:rc_1} plus the fact that \(r<R\). We have shown that 
    \[|I|=\lim_{N\to\infty}|I_N|\leq|h|A_r\to 0\]
    as \(h\to 0\).
\end{proof}
Here we proof two auxillary lemmas:
\begin{proof}
    (Lemma \ref{lemma:aux:rc_1}) Suppose \(0<|z|<R\), then \(\exists r\) such that \(|z|<r<R\). We know \(\sum_{n=0}^{\infty}a_nr^n\) converges so \(a_nr^n\to 0\) as \(n\to\infty\) and hence \(\exists K\) such that 
    \[|a_nr^n|\leq K\quad\forall n\geq 0\]
    Thus 
    \[|na_nz^{n-1}|=\frac{|a_nr^n|}{|z|}n\left|\frac zr\right|^n\leq\frac K{|z|}n\rho^n\]
    where \(K\) is independent of \(n\) and \(\rho=|z|/r<1\). But \(\sum_{n=1}^{\infty}n\rho^n\) converges by ratio test:
    \[\left|\frac{(n+1)\rho^{n+1}}{n\rho^n}\right|=\rho\left(1+\frac 1n\right)\to\rho<1\]
    Therefore, \(\sum_{n=1}^\infty na_nz^{n-1}\) converges absolutely by comparison.

    If \(|z|>R\), then 
    \[|na_nz^{n-1}|\geq\frac 1{|z|}|a_nz^n|\]
    If \(\sum_{n=1}^{\infty}na_nw^{n-1}\) converges for some \(|w|>R\), then taking \(|w|>|z|>R\) we have \(\sum_{n=1}^{\infty}na_nz^{n-1}\) converging absolutely by Lemma \ref{lemma:small_conv}. This implies that \(\sum a_nz^n\) converges absolutely (by comparison), contradicting \(R\) being radius of convergence of \(\sum a_nz^n\). Therefore \(\sum_{n=1}^{\infty}na_nw^{n-1}\) diverges, and \(\sum_{n=1}^{\infty}na_nz^{n-1}\) has radius of convergence \(R\).

    For the series \(\sum_{n=2}^{\infty}n(n-1)a_nz^{n-2}\), apply result above, starting with \(\sum_{n=1}^{\infty}na_nz^{n-1}\).
\end{proof}
\begin{proof}
    (Lemma \ref{lemma:aux:rc_2})
    \begin{enumerate}
        \item Simple manipulation gives
        \[{\binom nr}/{\binom{n-2}{r-2}}=\frac{n!}{(n-r)!r!}\frac{(n-r)!(r-2)!}{(n-2)!}=\frac{n(n-1)}{r(r-1)}\geq n(n-1)\]
        since \(r\in\mathbb{N}\), \(r\geq 2\).
        \item By binomial expansion, (1), and triangle inequality, we have 
        \begin{align*}
            |(z+h)^n-z^n-nhz^{n-1}|&=\left|\sum_{r=2}^{n}\binom nrz^{n-r}h^r\right| \\
            &\leq\sum_{r=2}^{n}n(n-1)\binom{n-2}{r-2}|z|^{n-r}|h|^r \\
            &=n(n-1)|h|^2\sum_{r=2}^{n}\binom{n-2}{r-2}|z|^{n-r} \\
            &=n(n-1)|h|^2(|z|+|h|)^{n-2}
        \end{align*}
    \end{enumerate}
\end{proof}
N.b. Theorem \ref{thm:taylor_diff} can be iterated: power series are smooth inside the radius of convergence. 
\subsection{The Standard Functions}
\subsubsection{Exponentials and logarithms}
We saw in previous example that \(\sum_{n=0}^{\infty}z^n/n!\) has \(R=\infty\), i.e. it converges at all \(z\in\mathbb{C}\). With this fact, we define the \emph{exponential function} as follows.
\begin{definition} (\emph{Exponential Function})
    Let \(\exp:\mathbb{C}\to\mathbb{C}\),
    \[z\mapsto \exp(z)=\sum_{n=0}^{\infty}\frac{z^n}{n!}\]
    \label{def:exp}
\end{definition}
We immediately have from Theorem \ref{thm:taylor_diff} that \(\exp\) is differentiable and 
\[\exp^\prime(z)=\exp(z)\]
Nextly, we claim \(\exp(a+b)=\exp(a)\exp(b)\). To show this, we need the following fact: if \(F:\mathbb{C}\to\mathbb{C}\) satisfies \(F^\prime(z)=0\) for all \(z\in\mathbb{C}\), then \(F\) is constant.\footnote{Note the difference with Corollary \ref{coro:inc} -- range is now \(\mathbb{C}\).}
\begin{proof}
    Consider \(g:\mathbb{R}\to\mathbb{C}\), \(g(t)=F(tz)\) for some fixed \(z\in\mathbb{C}\). By chain rule,
    \[g^\prime(t)=zF^\prime(tz)=0\]
    We can write 
    \[g(t)=u(t)+iv(t)\]
    with \(u,v\) real, and then 
    \[g^\prime(t)=u^\prime(t)+iv^\prime(t)\]
    giving
    \[u^\prime(t)=v^\prime(t)=0\Rightarrow u,v\text{  constant}\]
    by Corollary \ref{coro:inc}. Therefore \(F(z)=F(0)\) (put \(t=0\) and \(t=1\)). But since \(z\) is arbitrary, \(F\) is constant.
\end{proof}
Now for \(a,b\in\mathbb{C}\) consider 
\[F(z)=\exp(a+b-z)\exp(z)\]
We compute 
\[F^\prime(z)=-\exp^\prime(a+b-z)\exp(z)+\exp(a+b-z)\exp^\prime(z)=0\]
to find out that \(F(0)=F(b)\). Hence \(\exp(a+b)\exp(0)=\exp(a)\exp(b)\), but
\[\exp(0)=\sum_{n=0}^{\infty}\frac{0^n}{n!}=1\]
Therefore, \(\exp(a+b)=\exp(a)\exp(b)\) for all \(a,b\in\mathbb{C}\).

From now on we restrict to \(\mathbb{R}\).
\begin{theorem}
    Consider \(\exp:\mathbb{R}\to\mathbb{R}\).
    \begin{enumerate}
        \item \(\exp\) is everywhere differentiable and \(\exp^\prime(x)=\exp(x)\).
        \item \(\exp(x+y)=\exp(x)\exp(y)\) for all \(x,y\in\mathbb{R}\).
        \item \(\exp(x)>0\) for all \(x\in\mathbb{R}\).
        \item \(\exp\) is strictly increasing.
        \item \(\exp(x)\to\infty\) as \(x\to\infty\); and \(\exp\to 0\) as \(x\to-\infty\).
        \item \(\exp:\mathbb{R}\to(0,\infty)\) is a bijection.
    \end{enumerate}
    \label{thm:exp_property}
\end{theorem}
\begin{proof}
    (1) and (2) are done. We prove the remainings.
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item If \(x>0\), clearly 
        \[\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}\geq 1>0\]
        Also, \(\exp(0)=1\) and \(\exp(x-x)=\exp(x)\exp(-x)=1\).
        Thus \(\exp(-x)>0\) for all \(x>0\).
        \item \(\exp^\prime(x)=\exp(x)>0\). Hence \(\exp\) is strictly increasing by Corollary \ref{coro:inc}.
        \item \(\exp(x)\geq 1+x\) for \(x\geq 0\) so if \(x\to\infty\), \(\exp(x)\to\infty\).
        Meanwhile, for \(x\geq 0\),
        \[\exp(-x)=\frac{1}{\exp(x)}\]
        so \(\exp(-x)\to 0\) as \(x\to\infty\), i.e. \(\exp(x)\to 0\) as \(x\to-\infty\).
        \item Injectivity is immediate from being strictly increasing. For surjectivity, suppose \(y\in(0,\infty)\). Then from (4), there exists \(a,b\in\mathbb{R}\) such that 
        \[\exp(a)<y<\exp(b)\]
        Applying intermediate value theorem (Theorem \ref{thm:ivt}) to \(\exp:[a,b]\to\mathbb{R}\) gives \(\exists x\in\mathbb{R}\) such that \(\exp(x)=y\). Hence \(\exp\) is surjective.
    \end{enumerate}
\end{proof}
Notice that \(\exp:(\mathbb{R},+)\to((0,\infty),\times)\) is a group isomorphism. And since \(\exp\) is a bijection, it has an inverse function
\[\ln:(0,\infty)\to\mathbb{R}\]
which is called the \emph{logarithmic function}. 
\begin{theorem} \item[]
    \begin{enumerate}
        \item \(\ln:(0,\infty)\to\mathbb{R}\) is a bijection, and 
        \[\ln(\exp(x))=x\quad\forall x\in\mathbb{R},\]
        \[\exp(\ln(t))=t\quad\forall t\in(0,\infty)\]
        \item \(\ln\) is differentiable and monotone, with 
        \[\ln^\prime(t)=\frac 1t\]
        \item \(\ln(st)=\ln(s)+\ln(t)\) where \(s,t>0\).
        \item \(\ln(x)\to\infty\) as \(x\to\infty\); and \(\ln(x)\to-\infty\) as \(x\to 0\).
    \end{enumerate}
    \label{thm:ln_property}
\end{theorem}
\begin{proof} \item[]
    \begin{enumerate}
        \item Trivial from construction (\(\ln\) is the inverse of \(\exp\)).
        \item Inverse function theorem (Theorem \(\ref{thm:ift_diff}\)) gives that \(\ln\) is differentiable and 
        \[\ln^\prime(t)=\frac{1}{\exp^\prime(\ln(t))}=\frac 1{\exp(\ln{t})}=\frac 1t\]
        for all \(t>0\).
        \item Because \(e\) is an isomorphism, so is its inverse.
    \end{enumerate}
\end{proof}
Now define for \(\alpha\in\mathbb{R}\) and \(x>0\),
\[\Gamma_\alpha(x)=\exp(\alpha\ln(x))\]
\begin{theorem}
    Suppose \(x,y>0\) and \(\alpha,\beta\in\mathbb{R}\). Then 
    \begin{enumerate}
        \item \(\Gamma_\alpha(x,y)=\Gamma_\alpha(x)\Gamma_\alpha(y)\).
        \item \(\Gamma_{\alpha+\beta}(x)=\Gamma_\alpha(x)\Gamma_\beta(x)\).
        \item \(\Gamma_\alpha(\Gamma_\beta(x))=\Gamma_{\alpha\beta}(x)\).
        \item \(\Gamma_1(x)=x\), \(\Gamma_0(x)=1\).
    \end{enumerate}
    \label{thm:power_property}
\end{theorem}
\begin{proof} \item[]
    \begin{enumerate}
        \item \(
            \Gamma_\alpha(xy)=\exp(\alpha\ln(xy))=\exp(\alpha\ln(x)+\alpha\ln(y))=\exp(\alpha\ln(x))\exp(\alpha\ln(y))=\Gamma_\alpha(x)\Gamma_\alpha(y)
        \).
        \item \(\Gamma_{\alpha+\beta}(x)=\exp((\alpha+\beta)\ln(x))=\exp(\alpha\ln(x)+\beta\ln(x))\\=\exp(\alpha\ln(x))\exp(\beta(\ln(x)))=\Gamma_\alpha(x)\Gamma_\beta(x)\).
        \item \(\Gamma_\alpha(\Gamma_\beta(x))=\exp(\alpha\ln(\exp(\beta\ln(x))))=\exp(\alpha\beta\ln(x))=\Gamma_{\alpha\beta}(x)\).
        \item \(\Gamma_1(x)=\exp(\ln(x))=x\), \(\Gamma_0(x)=\exp(0)=1\).
    \end{enumerate}
\end{proof}
Now suppose \(p,q\in\mathbb{Z}\), \(p,q\geq 1\). Then,
\[\Gamma_p(x)=\Gamma_{1+1+\cdots+1}(x)=\Gamma_1(x)\Gamma_1(x)\cdots\Gamma_1(x)=x^p\]
and 
\[\Gamma_p(x)\Gamma_{-p}(x)=\Gamma_0(x)=1\Rightarrow\Gamma_{-p}(x)=\frac 1{x^p}\]
Further,
\[\left(\Gamma_{1/q}(x)\right)^q=\Gamma_{1/q}(x)\cdots\Gamma_{1/q}(x)=\Gamma_{1/q+\cdots+1/q}(x)=\Gamma_{1}(x)=x\]
gives \(\Gamma_{1/q}(x)=x^{1/q}\). Finally,
\[\Gamma_{p/q}(x)=\Gamma_{\underbrace{1/q+\cdots+1/q}_{p\text{  times}}}(x)=\left(\Gamma_{1/q}(x)\right)^p=(x^1/q)^p=x^{p/q}\].
Thus \(\Gamma_\alpha(x)\) agrees with \(x^\alpha\) for \(x\in\mathbb{Q}\) as previously defined. Hence we can extend the definition of \(x^\alpha\) into \(x\in\mathbb{R}\) and write 
\[x^\alpha=\Gamma_\alpha(x)\]
for \(\alpha\in\mathbb{R}\), \(x\in(0,\infty)\). We also introduce \emph{Euler's number}
\[e=\exp(1)=\sum_{n=1}^{\infty}\frac 1{n!}\]
and write \(\exp\) as a power:
\[\exp(x)=\exp(x\ln e)=\Gamma_x(e)=e^x\]
Now we can generalise as follows.
\[(x^\alpha)^\prime=(e^{\alpha\ln x})^\prime=\frac\alpha xe^{\alpha\ln x}=\alpha x^{\alpha-1}\]
for all \(x>0\), \(\alpha\in\mathbb{R}\). Meanwhile, for \(f(x)=a^x\) (\(a>0\), \(x\in\mathbb{R}\)),
\[f^\prime(x)=(e^{x\ln a})^\prime=e^{x\ln a}\ln a=a^x\ln a\]
In particular, \(f^\prime(x)>0\) for \(a>1\) and \(f^\prime(x)<0\) for \(a<1\).
\begin{lemma}
    For any \(r>0\) we have
    \begin{enumerate}
        \item \(x^re^{-x}\to 0\) as \(x\to\infty\).
        \item \(x^{-r}\ln x\to 0\) as \(x\to\infty\).
        \item \(x^r\ln x\to 0\) as \(x\to 0+\).
    \end{enumerate}
\end{lemma}
\begin{proof}\item[] 
    \begin{enumerate}
        \item For \(x>0\),
        \[e^x=1+x+\frac{x^2}{2!}+\cdots+\frac{x^n}{n!}+\cdots>\frac{x^n}{n!}\]
        for any \(n\in\mathbb{N}\). Pick \(n\) such that \(n-r\geq 1\). Then,
        \[0\leq\frac{x^r}{e^x}\leq\frac{n!}{x^{n-r}}\leq\frac{n!}{x}\]
        so \(x^re^-x\to 0\) as \(x\to\infty\).
        \item Pick \(m\) such that \(m\geq 2/r\). For \(x>1\),
        \[0\leq\frac{x^{1/r}}{e^x}\leq\frac{m!}{x^{m-1/r}}\leq\frac{m!}{x^{1/r}}\]
        Let \(x=\ln y\) and write 
        \[0\leq\frac{(\ln y)^{1/r}}{r}\leq\frac{m!}{(\ln y)^{1/r}}\]
        giving 
        \[0\leq\frac{\ln y}{y^r}\leq\frac{(m!)^r}{\ln y}\]
        But \(\ln y\to\infty\) as \(y\to\infty\); thus \(\ln y/y^r\to 0\).
        \item Set \(z=1/y\) where \(y\) is from above. We have 
        \[0\leq-z^r\ln z\leq\frac{(m!)^r}{-\ln z}\]
        Since \(\ln z\to-\infty\) as \(z\to 0+\), \(z^r\ln z\to 0\).
    \end{enumerate}
\end{proof}
\subsubsection{Trigonometric functions}
\begin{definition}
    (\emph{Trigonometric Functions}) We define 
    \[\cos z=1-\frac{z^2}{2!}+\frac{z^4}{4!}-\cdots=\sum_{k=0}^{\infty}\frac{(-1)^kz^{2k}}{(2k)!}\]
    \[\sin z=z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots=\sum_{k=0}^{\infty}\frac{(-1)^kz^{2k+1}}{(2k+1)!}\]
\end{definition}
We can check that, like the exponential function, both series have infinite radius of convergence by ratio test. Hence, 
\[\cos^\prime z=-\sin z\text{  and  }\sin^\prime z=\cos z\]
by Theorem \ref{thm:taylor_diff}.
Also observe that 
\begin{align*}
    e^{iz}&=\lim_{N\to\infty}\left(\sum_{k=0}^{2N+1}\frac{(iz)^k}{k!}\right) \\
    &=\lim_{N\to\infty}\left(\sum_{k=0}^N\frac{(iz)^{2k}}{(2k)!}+\sum_{k=0}^N\frac{(iz)^{2k+1}}{(2k+1)!}\right) \\
    &=\lim_{N\to\infty}\left(\sum_{k=0}^N(-1)^k\frac{z^{2k}}{(2k)!}\right)+i\sum_{k=0}^N(-1)^k\frac{z^{2k+1}}{(2k+1)!} \\
    &=\cos z+i\sin z
\end{align*}
Similarly, \(e^{-iz}=\cos z-i\sin z\). Hence,
\[\cos z=\frac 12(e^{iz}+e^{-iz})\]
and 
\[\sin z=\frac 1{2i}(e^{iz}-e^{-iz})\]
These formulae give many trigonometric identities, e.g. \(\cos z=\cos(-z)\), \(\sin(z)=-\sin(-z)\), \(\cos(0)=1\), \(\sin(0)=0\) etc. Employing \(e^{a+b}=e^{a}e^b\), we also find 
\[\sin(z+w)=\sin z\sin w+\cos z\sin w\]
and 
\[\cos(z+w)=\cos z\cos w-\sin z\sin w\]
for all \(z,w\in\mathbb{C}\). Furthermore, set \(w=-z\) to deduce 
\[\cos^2+\sin^2=\cos(0)=1\tag{\(\asterisk\)}\]
Now, if \(x\in\mathbb{R}\) then \(\sin x,\cos x\in\mathbb{R}\) and (\(\asterisk\)) implies \(|\cos x|,|\sin x|\leq 1\). N.b. this need not be true away from real axis, e.g. if \(y\in\mathbb{R}\),
\[\cos iy=\frac 12(e^{-y}+e^y)\to\infty\]
as \(y\to\pm\infty\).
\subsubsection{Periodicity of trigonometric functions}
\begin{proposition}
    There is a smallest positive number \(\omega\) (where \(\sqrt{2}<\omega/2<\sqrt{3}\)) such that 
    \[\cos\frac{\omega}{2}=0\]
\end{proposition}
\begin{proof}
    Suppose \(0\leq x\leq 2\).
    \[\sin x=\left(x-\frac{x^3}{3!}\right)+\left(\frac{x^5}{5!}-\frac{x^7}{7!}\right)+\cdots+\frac{x^{2n-1}}{(2n-1)!}\left(1-\frac{x^2}{2n(2n+1)}\right)+\cdots\]
    Since each term in parenthesis are positive, \(\sin x\geq 0\), and if \(0<x\leq 2\), \(\sin x>0\). So \(\cos^\prime x=-\sin x<0\) for \(0<x<2\). Hence \(\cos x\) is strictly decreasing in this interval, hence it has at most one root in \([0,2]\). To complete the proof we show \(\cos\sqrt{2}>0>\cos\sqrt{3}\), then intermediate valuable theorem implies a root exists in \([\sqrt{2},\sqrt{3}]\). But 
    \[\cos\sqrt{2}=1-\underbrace{\frac{(\sqrt{2})^2}{2!}}_{=0}+\underbrace{\frac{(\sqrt{2})^4}{4!}-\frac{(\sqrt{2})^6}{6!}}_{>0}+\cdots+\underbrace{\frac{(\sqrt{2})^{2n}}{(2n)!}\left(1-\frac{2}{(2n+1)(2n+2)}\right)}_{>0}+\cdots\]
    so \(\cos\sqrt{2}>0\), and 
    \[\cos\sqrt{3}=\underbrace{1-\frac{(\sqrt{3})^2}{2!}+\frac{(\sqrt{3})^4}{4!}}_{-1/8}-\left(\underbrace{\frac{(\sqrt{3})^6}{6!}-\frac{(\sqrt{3})^8}{8!}}_{>0}\right)-\cdots-\frac{(\sqrt{3})^{2n}}{(2n)!}\left(\underbrace{1-\frac{3}{(2n+1)(2n+2)}}_{>0}\right)-\cdots\]
    implies \(\cos{\sqrt{3}}\), completing the proof.
\end{proof}
\begin{corollary}
    \(\sin\omega/2\)=1.
\end{corollary}
\begin{proof}
    From 
    \[\sin^2\frac\omega 2+\cos^2\frac\omega 2=1\]
    we have \(\sin^2\omega/2=1\Rightarrow\sin\omega/2=\pm 1\). But \(\omega/2\in(0,2)\) so \(\sin\omega/2>0\). Therefore \(\sin\omega/2=1\).
\end{proof}
Since we established some properties, we now define \(\pi=\omega\). Periodic properties of the \newline trigonometric functions follows.
\begin{theorem} \item[]
    \begin{enumerate}
        \item \(\sin(z+\pi/2)=\cos z\); \space \(\cos(z+\pi/2)=-\sin z\).
        \item \(\sin(z+\pi)=-\sin z\); \space \(\cos(z+\pi)=-\cos z\).
        \item \(\sin(z+2\pi)=\sin z\); \space \(\cos(z+2\pi)=\cos z\).
    \end{enumerate}
\end{theorem}
\begin{proof}
    (1) Follows from addition formulae plus \(\cos(\pi/2)=0\), \(\sin(\pi/2)=1\). (2) and (3) follow by iterating.
\end{proof}
It follows that 
\begin{align*}
    e^{iz+2\pi i}&=\cos(z+2\pi)+i\sin(z+2\pi)=\cos z+i\sin z=e^{iz}
\end{align*}
and hence \(e^\omega\) is periodic with period \(2\pi i\). Also 
\[e^{i\pi}=\cos\pi+i\sin\pi=-\cos 0+i(-\sin 0)=-1\]
giving the \emph{Euler's identity}:
\[e^{i\pi}+1=0\]
\subsubsection{Trigonometric functions and geometry}
Given \(\mathbf{x},\mathbf{y}\in\mathbb{R}^2\), define \(\mathbf{x}\cdot\mathbf{y}\) as usual. We set \(\|\mathbf{x}\|=\sqrt{\mathbf{x}\cdot\mathbf{x}}\). Cauchy-Schwarz shows that 
\[|\mathbf{x}\cdot\mathbf{y}|\leq\|\mathbf{x}\|\|\mathbf{y}\|\]
Hence for \(\mathbf{x}\neq 0\), \(\mathbf{y}\neq 0\),
\[-1\leq\frac{\mathbf{x}\cdot\mathbf{y}}{\|\mathbf{x}\|\|\mathbf{y}\|}\leq 1\]
Thus we can define the angle between \(\mathbf{x}\) and \(\mathbf{y}\) as the unique \(\theta\in[0,\pi]\) with 
\[\cos\theta=\frac{\mathbf{x}\cdot\mathbf{y}}{\|\mathbf{x}\|\|\mathbf{y}\|}\]
\subsubsection{Hyperbolic functions}
\begin{definition}
    (\emph{Hyperbolic Functions}) Define 
    \[\cosh z=\frac 12(e^z+e^{-z})\]
    \[\sinh z=\frac 12(e^z-e^{-z})\]
    where \(z\in\mathbb{C}\).
\end{definition}
It follows that 
\[\cosh z=\cos(iz)\text{  and }\sinh z=-i\sin(iz)\]
Also,
\[\cosh^\prime z=\sinh z,\quad\sinh^\prime z=\cosh z\]
and 
\[\cosh^2z-\sinh^2 z=1\]
\section{Integration}
\subsection{Riemann Integral}
Informally, we define 
    \[\int_a^bf(x)dx\]
    as the (signed) area under the graph of \(f(x)\).
To find the area, we approximate graph from above and below by rectangles. If \(f\) is `nice', estimates from above and below will be close for a suitably fine dissection of \([a,b]\). We assume \(f:[a,b]\to\mathbb{R}\) is bounded, i.e. \(\exists K\) such that \(|f(x)|\leq K\) for all \(x\in[a,b]\).
\begin{definition}
    A \emph{dissection} \(\mathcal{D}\) of \([a,b]\) is a finite subset of \([a,b]\) containing the end points \(a\), \(b\). We write 
    \[\mathcal{D}=\{x_0,x_1,\ldots,x_n\}\]
    with 
    \[a=x_0<x_1<\cdots<x_n=b\]
\end{definition}
Associated to a dissection are the \emph{upper} and \emph{lower sums}, given by 
\[U(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})\sup_{x\in[x_{j-1},x_j]}f(x)\]
and 
\[L(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})\inf_{x\in[x_{j-1},x_j]}f(x)\]
respectively. Clearly, for any dissection, \(L(f,\mathcal{D})\leq U(f,\mathcal{D})\).
\begin{lemma}
    Suppose \(\mathcal{D}^\prime\),\(\mathcal{D}\) are dissections with \(\mathcal{D}^\prime\supseteq\mathcal{D}\). Then,
    \[L(f,\mathcal{D})\leq L(f,\mathcal{D}^\prime)\leq U(f,\mathcal{D}^\prime)\leq U(f,\mathcal{D})\]
    We say \(\mathcal{D}^\prime\) is a refinement of \(\mathcal{D}\).
    \label{lemma:refine}
\end{lemma}
\begin{proof}
    Let \(\mathcal{D}=\{x_0,\ldots,x_n\}\) with \(x_0<x_1<\cdots<x_n\). First, consider the case where \(\mathcal{D}^\prime=\mathcal{D}\cup\{y\}\). Then, \(y\in(x_{r-1},x_r)\) for some \(r\). Clearly,
    \[\sup_{[x_{r-1},y]}f(x)\leq\sup_{[x_{r-1},x_r]}f(x)\]
    and 
    \[\sup_{[y,x_r]}f(x)\leq\sup_{[x_{r-1},x_r]}f(x)\]
    Combining these,
    \begin{align*}
        (y-x_{r-1})\sup_{[x_{r-1},y]}f(x)+(x_r-y)\sup_{[y,x_r]}f(x)&\leq (y-x_{r-1})\sup_{[x_{r-1},x_r]}f(x)+(x_r-y)\sup_{[x_{r-1},x_r]}f(x) \\
        &=(x_r-x_{r-1})\sup_{[x_{r-1},x_r]}f(x)
    \end{align*}
    Hence \(U(f,\mathcal{D}^\prime)\leq U(f,\mathcal{D})\). Similarly, 
    \[\inf_{[x_{r-1},y]}f,\;\inf_{[y,x_r]}f\geq\inf_{[x_{r-1},x_r]}f\]
    and \(L(f,\mathcal{D}^\prime)\geq U(f,\mathcal{D})\). Now if \(\mathcal{D}^\prime\) has more extra points, we add them one at a time and use the result recursively.
\end{proof}
\begin{lemma}
    Suppose \(\mathcal{D}_1\) and \(\mathcal{D}_2\) are two dissections. Then,
    \[L(f,\mathcal{D}_1)\leq U(f,\mathcal{D}_2)\]
    \label{lemma:ulsum_rel}
\end{lemma}
\begin{proof}
    Since \(\mathcal{D}_1\subseteq\mathcal{D}_1\cup\mathcal{D}_2\) and  \(\mathcal{D}_2\subseteq\mathcal{D}_1\cup\mathcal{D}_2\), we have, from Lemma \ref{lemma:refine}, 
    \[L(f,\mathcal{D}_1)\leq L(f,\mathcal{D}_1\cup\mathcal{D}_2)\leq U(f,\mathcal{D}_1\cup\mathcal{D}_2)\leq U(f,\mathcal{D}_2)\]
\end{proof}
Note that if \(\mathcal{D}_0=\{a,b\}\),
\[L(f,\mathcal{D}_0)=(b-a)\inf_{[a,b]}f\geq-(b-a)K\]
and 
\[U(f,\mathcal{D}_0)=(b-a)\sup_{[a,b]}f\leq(b-a)K\]
Since \(\mathcal{D}_0\subseteq\mathcal{D}\) for any \(\mathcal{D}\), we deduce 
\[\{U(f,\mathcal{D})\:|\:\mathcal{D}\text{  dissections}\}\]
and 
\[\{L(f,\mathcal{D})\:|\:\mathcal{D}\text{  dissections}\}\]

are bounded above by \((b-a)K\), and below by \(-(b-a)K\); and both sets are non-empty. We can define the \emph{upper} and \emph{lower integra}l now.
\begin{definition}
    The \emph{upper integral} of \(f\) is 
    \[I^\asterisk(f)=\overline{\int_a^b}f(x)dx=\inf_{\mathcal{D}}U(f,\mathcal{D})\]
    and the \emph{lower integral} of \(f\) is 
    \[I_\asterisk(f)=\underline{\int_a^b}f(x)dx=\sup_{\mathcal{D}}L(f,\mathcal{D})\]
\end{definition}
Also notice that from Lemma \ref{lemma:ulsum_rel}, 
\[L(f,\mathcal{D}_1)\leq U(f,\mathcal{D}_2)\Rightarrow L(f,\mathcal{D}_1)\leq\inf_{\mathcal{D}_2}U(f,\mathcal{D}_2)\Rightarrow\sup_{\mathcal{D}_1}L(f,\mathcal{D}_1)\leq\inf_{\mathcal{D}_2}U(f,\mathcal{D}_2)\Rightarrow I_\asterisk(f)\leq I^\asterisk(f)\]
Hence,
\[(b-a)\inf_{[a,b]}f(x)\leq I_\asterisk(f)\leq I^\asterisk(f)\leq(b-a)\sup_{[a,b]}f(x)\]
Now we formally define the integral as follows.
\begin{definition}
    A bounded function \(f:[a,b]\to\mathbb{R}\) is \emph{Riemann integrable} (integrable) if 
    \[I^\asterisk(f)=I_\asterisk(f)\]
    Then we define 
    \[\int_a^bf(x)dx=I^\asterisk(f)=I_\asterisk(f)=\int_a^bf\]
\end{definition}
\begin{example}
    Consider function \(f:[0,1]\to\mathbb{R}\), \(x\mapsto x\). Let 
    \[\mathcal{D}_k=\left\{0,\frac 1k,\ldots,\frac{k-1}k,1\right\}\]
    (uniform dissection). Then,
    \[U(f,\mathcal{D}_k)=\sum_{j=1}^{k}\left(\frac jk-\frac{(j-1)}{k}\right)\sup_{\left[\frac{j-1}{k},\frac jk\right]}x=\sum_{j=1}^{k}\frac 1k\frac jk=\frac 1{k^2}\frac 12k(k+1)=\frac 12+\frac 1{2k}\]
    Similarly,
    \[L(f,\mathcal{D}_k)=\frac 12-\frac 1{2k}\]
    Therefore,
    \[I^\asterisk(f)=\inf_{\mathcal{D}}U(f,\mathcal{D})\leq\inf_{\mathcal{D}_k}U(f,\mathcal{D}_k)=\frac 12\]
    and 
    \[I_\asterisk(f)=\sup{\mathcal{D}}L(f,\mathcal{D})\geq\sup_{\mathcal{D}_k}L(f,\mathcal{D}_k)=\frac 12\]
    But \(I_\asterisk(f)\leq I^\asterisk(f)\) so \(I_\asterisk(f)= I^\asterisk(f)=1/2\). Thus \(f\) is integrable and 
    \[\int_0^1xdx=\frac 12\]
\end{example}
\begin{example}
    Consider \(f:[0,1]\to\mathbb{R}\), 
    \[x\mapsto\begin{cases}
        1 & x\in\mathbb{Q} \\
        0 & x\notin\mathbb{Q}
    \end{cases}\]
    This time, \(f\) is not Riemann integrable. For any dissection \(\mathcal{D}\),
    \[U(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})\sup_{[x_{j-1},x_j]}f=\sum_{j=1}^{n}(x_j-x_{j-1})=1\]
    and
    \[L(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})\inf_{[x_{j-1},x_j]}f=0\]
    Thus, \(I_\asterisk(f)\neq I^\asterisk(f)\) and \(f\) is not Riemann integrable.
\end{example}
\begin{theorem}
    (\emph{Cauchy Criterion for Integrability}) A bounded function \(f:[a,b]\to\mathbb{R}\) is integrable if and only if for all \(\epsilon>0\) there exists a dissection \(\mathcal{D}\) with 
    \[U(f,\mathcal{D})-L(f,\mathcal{D})<\epsilon\]
    \label{thm:cauchy_criterion_integral}
\end{theorem}
\begin{proof}
    For any dissection, we have 
    \[0\leq I^\asterisk(f)- I_\asterisk(f)\leq  U(f,\mathcal{D})-L(f,\mathcal{D})<\epsilon\]
    If the criterion holds, then 
    \[0\leq I^\asterisk(f)- I_\asterisk(f)<\epsilon\]
    for all \(\epsilon>0\). So \(I^\asterisk(f)=I_\asterisk(f)\) and \(f\) is integrable.

    Conversely, suppose \(f\) is integrable and fix \(\epsilon>0\). It follows from definition of supremum and infimum that there exist \(\mathcal{D}_1\), \(\mathcal{D}_2\) with 
    \[U(f,\mathcal{D}_1)\leq I^\asterisk(f)+\epsilon/2\]
    and 
    \[L(f,\mathcal{D}_2)\geq I_\asterisk(f)-\epsilon/2\]
    Let \(\mathcal{D}=\mathcal{D}_1\cup\mathcal{D}_2\). Then,
    \[U(f,\mathcal{D})\leq U(f,\mathcal{D}_1),\]
    \[L(f,\mathcal{D})\geq L(f,\mathcal{D}_2)\]
    and we can find
    \begin{align*}
        0\leq U(f,\mathcal{D})-L(f,\mathcal{D})&\leq U(f,\mathcal{D}_1)-L(f,\mathcal{D}_2) \\
        &\leq I^\asterisk(f)+\epsilon/2-I_\asterisk(f)+\epsilon/2=\epsilon
    \end{align*}
\end{proof}
This criterion (Theorem \ref{thm:cauchy_criterion_integral}) can be used to show monotone functions and continuous functions are integrable.

Observe that if \(f:[a,b]\to\mathbb{R}\) is monotone, it is bounded by \(f(a)\) and \(f(b)\).
\begin{theorem}
    Suppose \(f:[a,b]\to\mathbb{R}\) is monotone. Then \(f\) is integrable.
    \label{thm:int_monotone}
\end{theorem}
\begin{proof}
    Suppose \(f\) is increasing. Then \(\sup_{[x_{j-1},x_j]}f=f(x_j)\) and \(\inf_{[x_{j-1},x_j]}f=f(x_{j-1})\). Thus for any dissection \(\mathcal{D}\), 
    \[U(f,\mathcal{D})-L(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})[f(x_j)-f(x_{j-1})]\]
    Now choose a uniform dissection into \(n\) pieces, i.e. 
    \[\mathcal{D}_n=\left\{a,a+\frac{(b-a)}{n}+a+\frac{2(b-a)}{n},\ldots,a+\frac{n-1}{n}(b-a),b\right\}\]
    Then,
    \begin{align*}
        U(f,\mathcal{D}_n)-L(f,\mathcal{D}_n)&=\sum_{j=1}^{n}\frac{(b-a)}{n}\left[f\left(a+\frac{j(b-a)}{b}\right)-f\left(a+\frac{(j-1)}{n}(b-a)\right)\right]\\&=\frac{(b-a)}{n}(f(b)-f(a))        
    \end{align*}
    Taking \(n\) sufficiently large, for any \(\epsilon>0\), we can find \(\mathcal{D}=\mathcal{D}_n\) such that 
    \[U(f,\mathcal{D})-L(f,\mathcal{D})<\epsilon\]
    Hence \(f\) is integrable by Theorem \ref{thm:cauchy_criterion_integral}.
\end{proof}
If \(f:[a,b]\to\mathbb{R}\) is continuous, then \(f\) is bounded by the extreme value theorem (Theorem \ref{thm:evt}).
\begin{theorem}
    Suppose \(f:[a,b]\to\mathbb{R}\) is continuous. Then \(f\) is integrable.
    \label{thm:int_cont}
\end{theorem}
\begin{proof}
    We prove the contrapositive, i.e. if \(f\) is not integrable, then \(f\) is not continuous. Suppose \(f\) is not integrable; then by Theorem \ref{thm:cauchy_criterion_integral}, there exists \(\epsilon_0>0\) such that, for all dissections \(\mathcal{D}\),
    \[U(f,\mathcal{D})-L(f,\mathcal{D})>\epsilon_0\]
    Since
    \[U(f,\mathcal{D})-L(f,\mathcal{D})=\sum_{j=1}^{n}(x_j-x_{j-1})[f(x_j)-f(x_{j-1})]\]
    it follows that for any dissection there is a \(j\) with 
    \[\sup_{[x_{j-1},x_j]}f-\inf_{[x_{j-1},x_j]}f>\frac{\epsilon_0}{b-a}\]
    otherwise
    \[U(f,\mathcal{D})-L(f,\mathcal{D})\leq\sum_{j=1}^{n}(x_j-x_{j-1})\frac{\epsilon_0}{b-a}=\epsilon_0\]
    In particular, we can find \(y,z\in[x_{j-1},x_j]\) with 
    \[f(y)-f(z)>\frac{\epsilon_0}{b-a}\]
    Now let \(\mathcal{D}_n\) be the uniform dissection into \(n\) equal intervals:
    \[\mathcal{D}_n=\left\{a,a+\frac{(b-a)}{n}+a+\frac{2(b-a)}{n},\ldots,a+\frac{n-1}{n}(b-a),b\right\}\]
    Applying the argument above to \(\mathcal{D}_n\), there must exist \(y_n\), \(z_n\) in the same subinterval so that \(|y_n-z_n|<(b-a)/n\), with 
    \[f(y_n)-f(z_n)>\frac{\epsilon_0}{b-a}\]
    \((y_n)\) is bounded by construction, so by Bolzano-Weierstrass theorem we can take a convergent subsequence \(y_{n_k}\to\eta\) for some \(\eta\in[a,b]\). Moreover, since
    \[|y_{n_k}-z_{n_k}|<\frac{b-a}{n_k}\leq\frac{b-a}{k}\]
    we have \(z_{n_k}\to\eta\) also. But 
    \[f(y_{n_k})-f(z_{n_k})>\frac{\epsilon_0}{b-a}>0\]
    implies \(f(y_{n_k})\) and \(f(z_{n_k})\) cannot both converges to the same limit. So \(f\) is not continuous at \(\eta\) (Theorem \ref{thm:contd}).
\end{proof}
However, a function not being continuous nor monotone does not suggest that function is not integrable. Between monotone and continuous functions, we have a large class of integrable functions, e.g. \emph{Thomae's function}.\footnote{Moreover, this function is continuous at each irrational, and discontinuous at each rational.}
% \begin{example}
%     (\emph{Thomae's Function}) Consider \(f:[0,1]\to\mathbb{R}\),
%     \[f(x)=\begin{cases}
%         1/q & x=p/q \text{ where \(p,q\) are coprime integers;}\\
%         0 & \text{ otherwise.} 
%     \end{cases}\]
%     We claim \(f\) is integrable. Note that for any dissection \(\mathcal{D}\), \(L(f,\mathcal{D})=0\). It is enough to show that for any \(\epsilon>0\) we can find a \(U(f,\mathcal{D})<\epsilon\). Pick \(N\in\mathbb{N}\) such that \(1/N<\epsilon/2\). Now consider 
%     \[P=\{x\in[0,1]\:|\:f(x)\geq 1/N\}=\left\{\left.\frac pq\:\right|\:0\leq q\leq N,1\leq p\leq q\right\}\]
%     \(P\) is a finite set:
% \end{example}
\subsection{Elementary Properties of the Integral}
Before establishing various properties of the integral, we first give some properties of infimum and supremum.
\begin{lemma}
    Suppose \(I=[a,b]\) and \(f,g:I\to\mathbb{R}\) are bounded. Then,
    \begin{enumerate}
        \item If \(f(x)\leq g(x)\) for all \(x\in I\), 
        \[\sup_If\leq\sup_Ig\text{  and  }\inf_If\leq\inf_Ig\]
        \item \(\sup_I(-f)=-\inf_If\).
        \item If \(\lambda>0\), then \[\sup_I(\lambda f)=\lambda\sup_If\text{  and  }\inf_I(\lambda f)=\lambda\inf_If\]
        \item \[\sup_I(f+g)\leq\sup_If+\sup_Ig\]
        \[\inf_I(f+g)\geq\inf_If+\inf_Ig\]
        \item \(\sup_I|f|-\inf_I|f|\leq\sup_If-\inf_If\).
        \item \(\sup_If^2-\inf_If^2\leq 2\sup_I|f|(\sup_If-\inf_If)\).
    \end{enumerate}
    \label{lemma:supinf_property}
\end{lemma}
\begin{proof}
    We will only prove (4)-(6).
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item We have \(f(x)\leq\sup_If\), \(g(x)\leq\sup_Ig\) for all \(x\in I\). Hence 
        \[f(x)+g(x)\leq\sup_If+\sup_Ig\quad\forall x\in I\]
        and 
        \[\sup_I(f+g)\leq\sup_If+\sup_Ig\]
        Proof is similar for \(\inf\).
        \item \begin{itemize}
            \item If \(f(x)\geq 0\) for all \(x\), then \(|f|=f\) and 
            \[\sup_I|f|-\inf_I|f|=\sup_If-\inf_If\]
            \item If \(f(x)\leq 0\) for all \(x\), then \(|f|=-f\) and 
            \[\sup_I|f|-\inf_I|f|=\sup_I(-f)-\inf_I(-f)=-\inf_If+\sup_If\]
            by (2).
            \item If \(\inf_If<0<\sup_If\), then 
            \begin{align*}
                \sup_I|f|-\inf_I|f|&=\sup_I|f|=\max\{\sup_If,\sup_I(-f)\} \\
                &\leq\sup_If+\sup_I(-f) \\
                &=\sup_If-\inf_If 
            \end{align*}
        \end{itemize}
        \item From \[f(x)^2-f(y)^2=(f(x)+f(y))(f(x)-f(y))\leq 2\sup_I|f|(\sup_If-\inf_If)\]
        we take supremum over \(x\) and \(y\) for the result.
    \end{enumerate}
\end{proof}
\begin{corollary}
    For any dissection \(\mathcal{D}\) of \([a,b]\), and bounded functions \(f,g:[a,b]\to\mathbb{R}\),
    \begin{enumerate}
        \item If \(f(x)\leq g(x)\) for all \(x\in[a,b]\), 
        \[U(f,\mathcal{D})\leq U(g,\mathcal{D})\text{  and  }L(f,\mathcal{D})\leq L(g,\mathcal{D})\]
        \item \(L(-f,\mathcal{D})=-U(f,\mathcal{D})\).
        \item If \(\lambda>0\),
        \[U(\lambda f,\mathcal{D})=\lambda U(f,\mathcal{D})\text{  and  }L(\lambda f,\mathcal{D})=\lambda L(f,\mathcal{D})\]
        \item \[U(f+g,\mathcal{D})\leq U(f,\mathcal{D})+U(g,\mathcal{D})\]
        \[L(f+g,\mathcal{D})\leq L(f,\mathcal{D})+L(g,\mathcal{D})\]
        \item \(U(|f|,\mathcal{D})-L(|f|,\mathcal{D})\leq U(f,\mathcal{D})-L(f,\mathcal{D})\).
        \item \(U(f^2,\mathcal{D})-L(f^2,\mathcal{D})\leq 2\sup_{[a,b]}|f|(U(f,\mathcal{D})-L(f,\mathcal{D}))\).
    \end{enumerate}
    \label{coro:uplowsum_property}
\end{corollary}
\begin{proof}
    Recall the definition of upper/lower sum and results follow from Lemma \ref{lemma:supinf_property}. For (6) we additionally need that 
    \[\sup_{[x_{j-1},x_j]}|f|\leq\sup_{[a,b]}|f|\]
\end{proof}
\begin{theorem}
    Let \(f\), \(g\) be bounded and integrable on \([a,b]\). Then,
    \begin{enumerate}
        \item If \(f(x)\leq g(x)\) for all \(x\in[a,b]\),
        \[\int_a^bf(x)dx\leq\int_a^bg(x)dx\]
        \item If \(\lambda\in\mathbb{R}\), \(\lambda f\) is integrable, and 
        \[\int_a^b\lambda f(x)dx=\lambda\int_a^bf(x)dx\]
        \item \(f+g\) is integrable, and 
        \[\int_a^b(f+g)(x)dx=\int_a^bf(x)dx+\int_a^bg(x)dx\]
        \item \(|f|\) is integrable, and 
        \[\left|\int_a^bf(x)dx\right|\leq\int_a^b|f(x)|dx\]
        \item The product \(fg\) is integrable.
    \end{enumerate}
    \label{thm:integral_property}
\end{theorem}
\begin{proof} \item[]
    \begin{enumerate}
        \item For any dissection \(\mathcal{D}\), we have 
        \[L(f,\mathcal{D})\leq L(g,\mathcal{D})\leq I_\asterisk(g)\]
        Hence \(I_\asterisk(f)\leq I_\asterisk(g)\). But \(f\), \(g\) integrable, so 
        \[\int_a^bf(x)dx\leq\int_a^bg(x)dx\]
        \item First consider \(\lambda>0\). Since \(f\) is integrable, \(\forall\epsilon>0\), \(\exists\mathcal{D}\) such that 
        \[U(f,\mathcal{D})\leq\int_a^bf(x)dx+\epsilon,\quad L(f,\mathcal{D})\geq\int_a^bf(x)dx-\epsilon\]
        Then, by Corollary \ref{coro:uplowsum_property} (3), 
        \begin{align*}
            \lambda\int_a^bf(x)dx-\lambda\epsilon&\leq\lambda L(f,\mathcal{D})=L(\lambda f,\mathcal{D})\leq I_\asterisk(\lambda f) \\
            &\leq I^\asterisk(\lambda f)\leq U(\lambda f,\mathcal{D})=\lambda U(f,\mathcal{D})\leq\lambda\int_a^b f(x)dx+\lambda\epsilon
        \end{align*}
        But \(\epsilon\) is arbitrary so
        \[I_\asterisk(\lambda f)=I^\asterisk(\lambda f)=\lambda\int_a^bf(x)dx\]
        
        Now consider \(\lambda=-1\), \(\mathcal{D}\) as above. Then,
        \[\int_a^bf(x)dx-\epsilon\leq L(f,\mathcal{D})=-U(-f,\mathcal{D})\]
        and 
        \[\int_a^bf(x)dx+\epsilon\geq U(f,\mathcal{D})=-L(-f,\mathcal{D})\]
        Therefore 
        \[-\int_a^bf(x)dx-\epsilon\leq L(-f,\mathcal{D})\leq I_\asterisk(-f)\leq I^\asterisk(-f)\leq U(-f,\mathcal{D})\leq-\int_a^bf(x)dx+\epsilon\]
        and 
        \[I_\asterisk(-f)=I^\asterisk(-f)=-\int_a^bf(x)dx\]
        since \(\epsilon\) arbitrary. And we can combine the two results above to get desired for all \(\lambda\in\mathbb{R}\).
        \item Since \(f,g\) integrable, \(\forall\epsilon>0\) there exist \(\mathcal{D}_1,\mathcal{D}_2\) such that
        \[\int_a^bf(x)dx-\epsilon\leq L(f,\mathcal{D}_1)\leq U(f,\mathcal{D}_1)\leq\int_a^bf(x)dx+\epsilon\]
        \[\int_a^bg(x)dx-\epsilon\leq L(g,\mathcal{D}_2)\leq U(g,\mathcal{D}_2)\leq\int_a^bg(x)dx+\epsilon\]
        Now let \(\mathcal{D}=\mathcal{D}_1\cup\mathcal{D}_2\). Then, by Corollary \ref{coro:uplowsum_property} (4),
        \begin{align*}
            \int_a^bf(x)dx+\int_a^bg(x)dx-2\epsilon&\leq L(f,\mathcal{D}_1)+L(g,\mathcal{D}_2) \\
            &\leq L(f,\mathcal{D})+L(g,\mathcal{D}) \\
            &\leq L(f+g,\mathcal{D}) 
        \end{align*}
        Similarly,
        \begin{align*}
            \int_a^bf(x)dx+\int_a^bg(x)dx+2\epsilon&\geq U(f,\mathcal{D}_1)+U(g,\mathcal{D}_2) \\
            &\geq U(f,\mathcal{D})+U(g,\mathcal{D}) \\
            &\geq U(f+g,\mathcal{D}) 
        \end{align*}
        Combining two, we obtain 
        \[\int_a^bf(x)dx+\int_a^bg(x)dx-2\epsilon\leq I_\asterisk(f+g)\leq I^\asterisk(f+g)\leq\int_a^bf(x)dx+\int_a^bg(x)dx+2\epsilon\]
        Since \(\epsilon\) arbitrary, \(f+g\) is integrable and 
        \[\int_a^bf(x)dx+\int_a^bg(x)dx=\int_a^b(f+g)(x)dx\]
        \item By Theorem \ref{thm:cauchy_criterion_integral} and Corollary \ref{coro:uplowsum_property} (5), \(\forall\epsilon>0\) \(\exists\mathcal{D}\) such that 
        \[\epsilon>U(f,\mathcal{D})-L(f,\mathcal{D})\geq U(|f|,\mathcal{D})-L(|f|,\mathcal{D})\]
        We immediately see that \(|f|\) is integrable by Theorem \ref{thm:cauchy_criterion_integral}. Also, 
        \[-|f(x)|\leq f(x)\leq|f(x)|\quad\forall x\]
        so by (1),
        \[-\int_a^b|f(x)|dx\leq\int_a^bf(x)dx\leq\int_a^b|f(x)|dx\]
        \item Noting
        \[fg=\frac 14\left[(f+g)^2-(f-g)^2\right]\tag{\(\dagger\)}\]
        it is sufficient to show \(f^2\) is integrable. Suppose \(|f(x)|\leq K\) \(\forall x\in[a,b]\). Then given \(\epsilon>0\), there exists \(\mathcal{D}\) such that 
        \[U(f,\mathcal{D})-L(f,\mathcal{D})<\frac{\epsilon}{2K}\]
        By Corollary \ref{coro:uplowsum_property} (6),
        \[U(f^2,\mathcal{D})-L(f^2,\mathcal{D})\leq 2\sup_{[a,b]}|f|(U(f,\mathcal{D})-L(f,\mathcal{D}))<\epsilon\]
        Hence \(f^2\) is integrable, and consequently \(fg\) is integrable by (\(\dagger\)).
    \end{enumerate}
\end{proof}
\begin{theorem}
    (\emph{Additivity of the Integral}) Suppose \(f:[a,b]\to\mathbb{R}\) and let \(c\in(a,b)\). Then \(f\) is integrable if and only if \(\left. f\right|_{[a,c]}\) and \(\left. f\right|_{[c,b]}\) are integrable, and 
    \[\int_a^bf(x)dx=\int_a^cf(x)dx+\int_c^bf(x)dx\]
    \label{thm:integral_add}
\end{theorem}
\begin{proof}
    First, suppose \(f:[a,b]\to\mathbb{R}\) is integrable. Let \(\epsilon>0\). By Theorem \ref{thm:cauchy_criterion_integral}, \(\exists\mathcal{D}\), a dissection of \([a,b]\), such that 
    \[U(f,\mathcal{D})-L(f,\mathcal{D})<\epsilon\]
    By considering \(\mathcal{D}\cup\{c\}\) if necessary, we can assume \(\mathcal{D}=\{x_0,\ldots,x_n\}\) and \(x_l=c\) for some \(l\). Let \(\mathcal{D}_L=\{x_0,\ldots,x_l\}\) and \(\mathcal{D}_R=\{x_l,\ldots,x_n\}\), which are dissections of \([a,c]\) and \([c,b]\) respectively. Then, from
    \[L(f,\mathcal{D})=L(\left. f\right|_{[a,c]},\mathcal{D}_L)+L(\left. f\right|_{[c,b]},\mathcal{D}_R)\]
    \[U(f,\mathcal{D})=U(\left. f\right|_{[a,c]},\mathcal{D}_L)+U(\left. f\right|_{[c,b]},\mathcal{D}_R)\]
    we have 
    \[\left[U(\left. f\right|_{[a,c]},\mathcal{D}_R)-L(\left. f\right|_{[a,c]},\mathcal{D}_R)\right]+\left[U(\left. f\right|_{[c,b]},\mathcal{D}_R)-L(\left. f\right|_{[c,b]},\mathcal{D}_R)\right]<\epsilon\]
    Both terms in square brackets are non-negative, so 
    \[U(\left. f\right|_{[a,c]},\mathcal{D}_R)-L(\left. f\right|_{[a,c]},\mathcal{D}_R)<\epsilon\]
    and 
    \[U(\left. f\right|_{[c,b]},\mathcal{D}_R)-L(\left. f\right|_{[c,b]},\mathcal{D}_R)<\epsilon\]
    Therefore \(\left. f\right|_{[a,c]}\) and \(\left. f\right|_{[c,b]}\) are integrable.

    Conversely, suppose \(\left. f\right|_{[a,c]}\) and \(\left. f\right|_{[c,b]}\) are integrable. Theorem \ref{thm:cauchy_criterion_integral} says that \(\exists\mathcal{D}_L,\mathcal{D}_R\) such that 
    \[U(\left. f\right|_{[a,c]},\mathcal{D}_R)-L(\left. f\right|_{[a,c]},\mathcal{D}_R)<\epsilon\]
    \[U(\left. f\right|_{[c,b]},\mathcal{D}_R)-L(\left. f\right|_{[c,b]},\mathcal{D}_R)<\epsilon\]
    But if we let \(\mathcal{D}=\mathcal{D}_L\cup\mathcal{D}_R\), we have 
    \[U(f,\mathcal{D})-L(f,\mathcal{D})<2\epsilon\]
    Hence \(f\) is integrable.

    Finally, we deduce that 
    \[\int_a^bf(x)dx\geq L(f,\mathcal{D})=L(\left. f\right|_{[a,c]},\mathcal{D}_L)+L(\left. f\right|_{[c,b]},\mathcal{D}_R)\geq\int_a^cf(x)dx-\epsilon+\int_c^bf(x)dx-\epsilon\]
    Similarly,
    \[\int_a^bf(x)dx\leq U(f,\mathcal{D})=U(\left. f\right|_{[a,c]},\mathcal{D}_L)+U(\left. f\right|_{[c,b]},\mathcal{D}_R)\leq\int_a^cf(x)dx+\epsilon+\int_c^bf(x)dx+\epsilon\]
    Therefore,
    \[\left|\int_a^bf(x)dx-\int_a^cf(x)dx-\int_c^bf(x)dx\right|\leq 2\epsilon\]
    for arbitrary \(\epsilon\), completing the proof.
\end{proof}
Finally, we introduce a convention that if \(a>b\), 
\[\int_a^bf(x)dx=-\int_b^af(x)dx\]
and if \(a=b\)
\[\int_a^af=0\]
With this convention, it follows that if \(|f|\leq K\), 
\[\left|\int_a^bf(x)dx\right|\leq K|b-a|\]
\subsection{Piecewise Continuous Functions}
\begin{definition}
    A bounded function \(f:[a,b]\to\mathbb{R}\) is \emph{piecewise continuous} if ther exists a dissection \(\mathcal{D}\) of \([a,b]\) such that for each \(i=1,2,\ldots,n\), if we define \(f_i:(x_{i-1},x_i)\to\mathbb{R}\), \(x\mapsto f(x)\), then \(f_i\) is continuous and has a limit as \(x\to x_{i-1}\) and \(x\to x_{i}\). I.e. the function \(\bar{f}_i:[x_{i-1},x_i]\to\mathbb{R}\) given by 
    \[\bar{f}_i(x)=\begin{cases}
        \lim_{x\to x_{i-1}}f_i(x) & x=x_{i-1} \\
        f_i(x) & x\in(x_{i-1},x_i) \\
        \lim_{x\to x_i} f_i(x) & x=x_{i+1}
    \end{cases}\] 
    is continuous (hence integrable).
    \label{def:piecewise_cont}
\end{definition}
Consequently, from the observation obove, together with Theorem \ref{thm:integral_add}, piecewise continuous function is integrable. Furthermore,\footnote{Left as an exercise.} if \(f:[a,b]\to\mathbb{R}\) is integrable, and \(g:[a,b]\to\mathbb{R}\) is bounded, with \(g(x)=f(x)\) \(\forall x\in[a,b]\backslash\{y_1,\ldots,y_N\}\), then \(g\) is integrable and 
\[\int_a^bf(x)dx=\int_a^bg(x)dx\]
\subsection{The Fundamental Theorem of Calculus} 
Suppose \(f:[a,b]\to\mathbb{R}\) is integrable (hence bounded). Let 
\[F(x)=\int_a^xf(t)dt\]
for \(x\in[a,b]\).
\begin{theorem}
    \(F\) is continuous.
\end{theorem}
\begin{proof}
    Suppose \(|f|\leq K\) and assume \(x,x+h\in[a,b]\). Then 
    \[F(x+h)-F(x)=\int_x^{x+h}f(t)dt\]
    gives 
    \[|F(x+h)-F(x)|=\left|\int_x^{x+h}f(t)dt\right|\leq K|h|\to 0\]
    as \(h\to 0\). Therefore, \(\lim_{h\to 0}(F(x+h)-F(x))=0\Rightarrow\lim_{h\to 0}F(x+h)=F(x)\) and \(F\) is continuous.
\end{proof}
\begin{theorem}
    (\emph{Fundamental Theorem of Calculus I}, FTC 1) If in addition \(f\) is continuous at \(x\), then \(F\) is differentiable at \(x\), and 
    \[F^\prime(x)=f(x)\]
    \label{thm:ftc1}
\end{theorem}
\begin{proof}
    We need to estimate 
    \[\left|\frac{F(x+h)-F(x)}{h}-f(x)\right|=\left|\frac 1h\int_x^{x+h}f(t)dt-f(x)\right|=\frac 1{|h|}\left|\int_x^{x+h}(f(t)-f(x))dt\right|\]
    Now, given \(\epsilon>0\) \(\exists\delta>0\) such that 
    \[|t-x|<\delta\Rightarrow|f(t)-f(x)|<\epsilon\]
    since \(f\) is continuous. Suppose \(|h|<\delta\). Then \(|f(t)-f(x)|<\epsilon\) for all \(t\) between \(x\) and \(x+h\). Therefore, 
    \[\left|\frac{F(x+h)-F(x)}{h}-f(x)\right|\leq\frac 1{|h|}\epsilon|h|=\epsilon\]
    i.e.
    \[\lim_{h\to 0}\frac{F(x+h)-F(x)}{h}=f(x)\]
\end{proof}
Note that for Theorem \ref{thm:ftc1} to hold, the condition \(f\) is continuous is necessary. For instance, consider 
\[f(x)=\begin{cases}
    -1 & x\in[-1,0] \\
    1 & x\in (0,1]
\end{cases}\]
Although \(f\) is montone and thus integrable, 
\[F(x)=\begin{cases}
    -x-1 & x\leq 0 \\
    x-1 & x\geq 0
\end{cases}\]
i.e. \(F(x)=-1+|x|\) is not differentiable at \(x=0\).
\begin{corollary}
    (\emph{Integration is Inverse of Differentiation}) If \(f=g^\prime\) is continuous on \([a,b]\), then 
    \[F(x)=\int_a^xf(t)dt=g(x)-g(a)\]
    \label{coro:intdiffrel}
\end{corollary}
\begin{proof}
    \(F-g\) has zero derivative on \([a,b]\) by Theorem \ref{thm:ftc1}, and \(F(a)=0\). Hence \((F-g)(a)=-g(a)\). So by Corollary \ref{coro:inc}, 
    \[(F-g)(x)=-g(a)\quad\forall x\]
    and \(F(x)=g(x)-g(a)\).
\end{proof}
Note that all continuous functions have an \emph{indefinite integral}, or \emph{anti-derivative}:
\[\int f(x)dx=\int_a^xf(t)dt\]
where \(a\) arbitrary.

\begin{theorem}
    (\emph{Fundamental Theorem of Calculus II}, FTC 2)
    Suppose that \(f:[a,b]\to\mathbb{R}\) is continuous on \([a,b]\), differentiable on \((a,b)\) and that \(f^\prime\) is integrable. Then
    \[\int_a^bf^\prime(x)dx=f(b)-f(a)\]
    \label{thm:ftc2}
\end{theorem}
N.b. Theorem \ref{thm:ftc2} is stronger than Corollary \ref{coro:intdiffrel} since it does not require \(f^\prime\) from Theorem \ref{thm:ftc2} to be continuous.
\begin{proof}
    Let \(\mathcal{D}\) be any dissection of \([a,b]\). Applying the mean value theorem (Theorem \ref{thm:mvt}) to \(f\) on \([x_{j-1},x_j]\), \(\exists\xi_j\in(x_{j-1},x_j)\) such that 
    \[f^\prime(\xi_j)(x_j-x_{j-1})=f(x_j)-f(x_{j-1})\]
    This gives
    \[\sum_{j=1}^{n}f^\prime(\xi_j)(x_j-x_{j-1})=f(b)-f(a)\]
    But 
    \[\sum_{j=1}^{n}(x_j-x_{j-1})\inf_{[x_{j-1},x_j]}f^\prime\leq\sum_{j=1}^{n}(x_j-x_{j-1})f^\prime(\xi_j)\leq \sum_{j=1}^{n}(x_j-x_{j-1})\sup_{[x_{j-1},x_j]}f^\prime\]
    So
    \[L(f^\prime,\mathcal{D})\leq f(b)-f(a)\leq U(f^\prime,\mathcal{D})\Rightarrow I_\asterisk(f^\prime)\leq f(b)-f(a)\leq I^\asterisk(f^\prime)\]
    But because \(f^\prime\) is integrable,
    \[I_\asterisk(f^\prime)=I^\asterisk(f^\prime)=\int_a^bf^\prime(x)dx=f(b)-f(a)\]
\end{proof}
Following are the important corollarys of fundamental theorem of calculus.
\begin{corollary}
    (\emph{Integration by Parts}) Suppose \(f^\prime\) and \(g^\prime\) exist and are continuous on \([a,b]\). Then
    \[\int_a^bf^\prime(x)g(x)dx=f(b)g(b)-f(a)g(a)-\int_a^bf(x)g^\prime(x)dx\]
\end{corollary}
\begin{proof}
    By the product rule and Corollary \ref{coro:intdiffrel}, 
    \begin{align*}
        \int_a^bf^\prime(x)g(x)dx&=\int_a^b((fg)^\prime(x)-f(x)g^\prime(x))dx=\int_a^b(fg)^\prime(x)dx-\int_a^bf(x)g^\prime(x)dx \\
        &=f(b)g(b)-f(a)g(a)-\int_a^bf(x)g^\prime(x)dx
    \end{align*}
\end{proof}
\begin{corollary}
    (\emph{Integration by Substitution}) Let \(g:[\alpha,\beta]\to[a,b]\) with \(g(\alpha)=a\), \(g(\beta)=b\) and suppose \(g^\prime\) exists and is continuous on \([\alpha,\beta]\). Let \(f:[a,b]\to\mathbb{R}\) be continuous. Then 
    \[\int_a^bf(x)dx=\int_\alpha^\beta f(g(t))g^\prime(t)dt\]
\end{corollary}
\begin{proof}
    Set \(F(x)=\int_a^xf(t)dt\) as before. Let \(h(t)=F(g(t))\) which is well defined for \(t\in[\alpha,\beta]\) as \(g\) takes value in \([a,b]\). Then,
    \begin{align*}
        \int_\alpha^\beta f(g(t))g^\prime(t)dt&=\int_\alpha^\beta F^\prime(g(t))g^\prime(t)dt \\
        &=\int_\alpha^\beta h^\prime(t)dt \\
        &=h(\beta)-h(\alpha) \\
        &=F(g(\beta))-F(g(\alpha)) \\
        &=F(b)-F(a)=\int_a^bf(t)dt
    \end{align*}
\end{proof}
\begin{theorem}
    (\emph{Taylor's Theorem with Integral Remainder})
    Suppose \(f\) and its first \(n\) derivatives exist, and are continuous for \(x\in[0,h]\). Then,
    \[f(h)=f(0)+hf^\prime(0)+\cdots+\frac{h^{n-1}f^{(n-1)}(0)}{(n-1)!}+R_n\]
    where 
    \[R_n=\frac{h^n}{(n-1)!}\int_0^1(1-t)^{n-1}f^{(n)}(th)dt\]
    \label{thm:taylor_integral}
\end{theorem}
\begin{proof}
    By Theorem \ref{thm:ftc2},
    \begin{align*}
        f(h)&=f(0)+\int_0^hf^\prime(u)du \\
        &=f(0)-\left[(h-u)f^\prime(u)\right]_0^h+\int_0^h(h-u)f^\pprime(u)du \\
        &=f(0)+hf^\prime(0)+\int_0^h\left(-\frac d{du}\frac{(h-u)^2}{2}\right)f^\pprime(u)du
    \end{align*}
    Keep integrating by parts to get 
    \[f(h)=f(0)+hf^\prime(0)+\cdots+\frac{h^{n-1}f^{(n-1)}(0)}{(n-1)!}+\underbrace{\int_0^h\frac{(h-u)^{n-1}}{(n-1)!}f^{(n)}(u)du}_{R_n}\]
    Substitution \(u=th\) gives the desired
    \[R_n=\frac{h^n}{(n-1)!}\int_0^1(1-t)^{n-1}f^{(n)}(th)dt\] 
\end{proof}
\begin{remark}
    Note we assume \(f^{(n)}\) is continuous but in previous versions of the Taylor's theorem we just assumed \(f^{(n)}\) exists. If we make this additional assumption, we can recover Cauchy and Lagrange form of remainder.
\end{remark}
\begin{theorem}
    Suppose \(f,g:[a,b]\to\mathbb{R}\) are continuous and \(g(x)\neq 0\) for all \(x\in(a,b)\). Then \(\exists c\in(a,b)\) such that 
    \[\int_a^bf(x)g(x)dx=f(c)\int_a^bg(x)dx\]
    \label{thm:mvt_integral}
\end{theorem}
N.b. if \(g(x)=1\), we get \(\int_a^bf(x)dx=f(c)(b-a)\).
\begin{proof}
    Apply Cauchy's mean value theorem (Theorem \ref{thm:mvt_cauchy}) to
    \[F(x)=\int_a^x(fg)(x)dx\text{  and  }G(x)=\int_a^xg(x)dx\]
    to deduce that there exists \(c\in(a,b)\) such that 
    \[(F(b)-F(a))G^\prime(c)=F^\prime(c)(G(b)-G(a))\Rightarrow\left(\int_a^b(fg)(x)dx\right)g(c)=f(c)g(c)\int_a^bg(x)dx\]
    \(g(c)\neq 0\) so we can cancel out \(g(c)\) to obtain the desired result.
\end{proof}
Now consider 
\[R_n=\frac{h^n}{(n-1)!}\int_0^1(1-t)^{n-1}f^{(n)}(th)dt\] 
To obtain the Cauchy remainder, apply Theorem \ref{thm:mvt_integral} with \(\tilde{g}=1\) and \(\tilde{f}(t)=(1-t)^{n-1}f^{(n)}(th)\) to get \(\exists\theta\in(0,1)\) such that 
\[\int_0^1\tilde{f}(t)dt=\tilde{f}(\theta)\Rightarrow R_n=\frac{h^n}{(n-1)!}(1-\theta)^{n-1}f^{(n)}(\theta h)\]
Alternatively, split integrands as 
\[\underbrace{\left((1-t)^{n-1}\right)}_{\tilde{g}}\underbrace{\left(f^{(n)}(th)\right)}_{\tilde{f}}\] to find
\[\int_0^1(1-t)^{n-1}f^{(n)}(th)dt=f^{(n)}(\theta h)\int_0^1(1-t)^{n-1}dt\]
for some \(\theta\in(0,1)\), by theorem \ref{thm:mvt_integral}. But \(\int_0^1(1-t)^{n-1}dt=1/n\), so we obtain the Lagrange remainder
\[R_n=\frac{h^n}{n!}f^{(n)}(\theta h)\]

Finally, we will point out that it is necessary to include the assumption that \(f^\prime\) is integrable in the hypotheses of Theorem \ref{thm:ftc2}. For example, consider \(f:[-1,1]\to\mathbb{R}\), given by 
\[f(x)=\begin{cases}
    |x|^{3/2}\sin\frac 1x & x\neq 0 \\
    0 & x=0
\end{cases}\]
satisfies that \(f\) is continuous on \([-1,1]\), differentiable on \((-1,1)\), but \(f^\prime\) is unbounded hence not integrable.
\subsection{Improper Integrals}
The theory of integration we have developed so far applies to bounded functions defined on bounded intervals. For a full treatment for functions whose domain or image is unbounded, we have to wait for the Lebesgue integral.\footnote{See Probability and Measure, Part II.} Note that content of this subsection, Riemann integral, is a partial resolution.
\subsubsection{Integrals on an infinite domain}
Suppose \(f:[a,\infty)\to\mathbb{R}\) is integrable on each interval \([a,R]\) (\(R>a\)) and 
\[\int_a^Rf(x)dx\to l\]
as \(R\to\infty\). Then we say 
\(\int_a^\infty f(x)dx\)
exists, or converges, and 
\[\int_a^\infty f(x)dx=l\] 
Otherwise, if \(\int_a^Rf(x)dx\) has no limit, we say \(\int_a^\infty f(x)dx\) \emph{diverges}. A similar definition applies to \(\int_{-\infty}^{a}f(x)dx\) for \(f:(-\infty,a]\to\mathbb{R}\). 

Furthermore, if \(\int_{-\infty}^a f(x)dx=l_1\) and \(\int_a^\infty f(x)dx=l_2\) we say \(\int_{-\infty}^\infty f(x)dx\) exists, and 
\[\int_{-\infty}^\infty f(x)dx=\int_{-\infty}^a f(x)dx+\int_a^\infty f(x)dx\]
independent of \(a\).\footnote{This needs check.} Be careful that this is not the same as 
\[\int_{-R}^Rf(x)dx\]
converging. For instance, \(\int_{-R}^Rxdx=0\) but \(\int_0^\infty xdx\) does not converge.
\subsubsection{Integrands with an isolated singularity}
Suppose \(f:(b,c]\to\mathbb{R}\) is integrable on each \([b+\delta,c]\) for \(0<\delta<c-b\). Then if 
\[\int_{b+\delta}^cf(x)dx\to l\]
as \(\delta\to 0\), we say \(\int_b^cf(x)dx\) exists or converges and equals \(l\); and it is similarly defined for \(f:[a,b)\to\mathbb{R}\) integrable on \([a,b-\delta]\) (\(0<\delta<b-a\)).

If \(f:[a,c]\backslash\{b\}\to\mathbb{R}\) and 
\[\int_a^bf(x)dx,\quad\int_b^cf(x)dx\]
exist, we say \(\int_a^cf(x)dx\) exists, and 
\[\int_a^cf(x)dx=\int_a^bf(x)dx+\int_b^cf(x)dx\]
\subsubsection{Properties and examples of improper integral}
For example,
\[\int_1^\infty\frac{dx}{x^k}\] converges if and only if \(k>1\), and 
\[\int_0^1\frac{dx}{x^k}\] converges if and only if \(k<1\), since (\(k\neq 1\))
\[\int_0^R\frac{dx}{x^k}=\left[\frac{x^{1-k}}{1-k}\right]_1^R=\frac{R^{1-k}-1}{1-k}\]
\begin{itemize}
    \item converges as \(R\to\infty\) if \(1-k<0\), not if \(1-k>0\);
    \item converges as \(R\to 0\) if \(1-k>0\), not if \(1-k<0\);
\end{itemize}
and because if \(k=1\),
\[\int_1^R\frac{dx}{x}=\left[\ln x\right]_1^R=\ln R\]
does not converge as \(R\to\infty\) or \(R\to 0\).
\begin{lemma}
    Suppose \(f,g:[a,\infty)\to\mathbb{R}\) are integrable on each \([a,R]\), \(R>a\). If \(0\leq f(x)\leq g(x)\) for all \(x\geq a\), then 
    \[\int_a^\infty g(x)dx\text{  converges }\Rightarrow\int_a^\infty f(x)dx\text{  converges }\]
\end{lemma}
\begin{proof}
    Note that 
    \[R\mapsto\int_a^Rf(x)dx\]
    is increasing as \(f(x)\geq 0\), and 
    \[\int_a^Rf(x)dx\leq\int_a^Rg(x)dx\leq\int_a^\infty g(x)dx\]
    Hence \(R\mapsto\int_a^Rf(x)dx\) is increasing and bounded above. Let 
    \[l=\sup_{R\geq a}\int_a^Rf(x)dx\]
    and claim 
    \[l=\lim_{R\to\infty}\int_a^Rf(x)dx\]
    To see this, let \(\epsilon>0\). Then from definition of supremum, \(\exists R_0\) such that 
    \[\int_a^{R_0}f(x)dx\geq l-\epsilon\]
    So if \(R\geq R_0\),
    \[l-\epsilon\leq\int_a^{R_0}f(x)dx\leq\int_a^Rf(x)dx\leq l\]
\end{proof}
\begin{example}
    Consider 
    \[\int_0^\infty e^{-x^2/2}dx\]
    For \(x>1\), \(e^{-x^2/2}\leq e^{-x/2}\), and
    \[\int_1^Re^{-x/2}dx=2(e^{-1/2}-e^{-R/2})\to 2e^{-1/2}\]
    as \(R\to\infty\).
    Hence \(\int_1^\infty e^{-x^2/2}dx\) converges, and therefore 
\[\int_0^\infty e^{-x^2/2}dx\] converges because from
\[\int_0^Re^{-x^2/2}dx=\int_0^1e^{-x^2/2}dx+\int_1^Re^{-x^2/2}dx\]
left hand side converges as \(R\to\infty\) if and only if \(\int_1^Re^{-x^2/2}dx\) does.
\end{example}
However, be careful that, unlike the situation with series,
\[\int_0^\infty f(x)dx\text{  converges }\nRightarrow f(x)\to 0\text{ as }x\to\infty\]
\subsubsection{Integral test}
\begin{theorem}
    (\emph{Integral Test}) Suppose \(f:[1,\infty)\to\mathbb{R}\) is positive and decreasing. Then,
    \begin{enumerate}
        \item the integral \(\int_1^\infty f(x)dx\) converges if and only if the sum \(\sum_{n=1}^\infty f(n)\) converges.
        \item as \(n\to\infty\),
        \[\sum_{r=1}^{n}f(r)-\int_1^nf(x)dx\to l\]
        for some \(l\) with \(0\leq l\leq f(1)\).
    \end{enumerate}
    \label{thm:integral_test}
\end{theorem}
Note that (2) of Theorem \ref{thm:integral_test} implies (1) of that. Also \(f\) decreasing from the hypotheses of that implies \(f\) integrable on \([1,R]\) (\(R>1\)) by Theorem \ref{thm:int_monotone}.
\begin{proof} If \(n-1\leq x\leq n\),
        \[f(n-1)\geq f(x)\geq f(n)\Rightarrow f(n-1)\geq\int_{n-1}^nf(x)dx\geq f(n)\]
        Adding, we have 
        \[\sum_{r=1}^{n-1}f(r)\geq\int_1^nf(x)dx\geq\sum_{r=2}^{n}f(r)\] From here, claim (1) is clear since \(\int_1^Rf(x)dx\) is monotonically increasing, as is \(\sum_{r=1}^nf(r)\).

        Let 
        \[\phi(n)=\sum_{r=1}^{n}f(r)-\int_1^nf(x)dx\]
        Then,
        \[\phi(n)-\phi(n-1)=f(n)-\int_{n-1}^nf(x)dx\leq 0\]
        and 
        \[\phi(n)=f(n)+\sum_{r=1}^{n-1}f(r)-\int_1^nf(x)dx\geq f(n)\geq 0\]
        So \(\phi(n)\) is decreasing and bounded below. Hence, from monotone convergence theorem, \(\phi(n)\to l\) with \(0\leq l\leq\phi(1)=f(1)\).
\end{proof}
\begin{example} \item[]
    \begin{enumerate}
        \item \(\sum_{n=1}^\infty 1/n^k\) converges if \(k>1\). We saw \(\int_1^\infty(dx/x^k)\) converges if \(k>1\). So integral test gives result.
        \item Consider 
        \[\sum_{n=2}^{\infty}\frac{1}{n\ln n}\]
        Let \(f(x)=1/x\ln x\) for \(x\geq 2\). Then,
        \[\int_2^R\frac{dx}{x\ln x}=\left[\ln(\ln x)\right]_2^R=\ln(\ln R)-\ln(\ln 2)\to\infty\]
        as \(R\to \infty\), and the corresponding sum diverges by integral test.
    \end{enumerate}
\end{example}
\begin{corollary}
    (\emph{Euler-Mascheroni Constant}) As \(n\to\infty\),
    \[1+\frac 12+\frac 13+\cdots+\frac 1n-\ln n\to\gamma\]
    with \(0\leq\gamma\leq 1\).\footnote{Question: is \(\gamma\) irrational?}
\end{corollary}
\begin{proof}
    Set \(f(x)=1/x\) in Theorem \ref{thm:integral_test} (2).
\end{proof}
\subsection{Lebesgue's Criterion for Riemann Integrability}
\begin{theorem}
    (\emph{Lebesgue's Criterion}) If \(f:[a,b]\to\mathbb{R}\) is bounded, then \(f\) is Riemann integral if and only if 
    \[\{x\:|\:f\text{  discontinuous at  }x\}\]
    has \emph{measure zero}.
    \label{thm:lebesgue_criterion}
\end{theorem}
\begin{definition}
    For an interval \(I\), let \(|I|\) denote its length. A subset \(A\subset\mathbb{R}\) has \emph{measure zero} if \(\forall \epsilon>0\) there exists a countable collection of intervals \(I_j\) such that 
    \[A\subset\bigcup_{j=1}^\infty I_j\text{  and  }\sum_{j=1}^{\infty}|I_j|<\epsilon\]
    i.e. ``can cover \(A\) with countable numbers of infinitesimal intervals.''
    \label{def:measure_zero}
\end{definition}
\begin{lemma} \item 
    \begin{enumerate}
        \item If \(B\) has measure zero and \(A\subset B\), then \(A\) has measure zero.
        \item If \(A_k\) has measure zero for each \(k\in\mathbb{N}\), then \(\bigcup_{k\in\mathbb{N}}A_k\) has measure zero.
    \end{enumerate}
\end{lemma}
\begin{proof} \item[]
    \begin{enumerate}
        \item Obvious from definition.
        \item Fix \(\epsilon>0\). For each \(k\), pick \(I_j^k\) (\(j=1,2,\ldots\)) such that 
        \[A_k\subset\bigcup_{j=1}^\infty I_j^k\text{  and  }\sum_{j=1}^{\infty}|I_j^k|<\epsilon 2^{-k}\]
        Then consider \(\{I_j^h\}_{j,h=1}^\infty\). 
    \end{enumerate}
\end{proof}
\textcolor{red}{\textbf{Will return}}.
\newpage
\section{Example Sheets}
\subsection{Sheet 1}
\end{document}